{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7a5be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea3d29a",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d341698",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Shape:  (69999, 172)\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Dataframe Info: \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69999 entries, 0 to 69998\n",
      "Data columns (total 172 columns):\n",
      " #    Column                    Dtype  \n",
      "---   ------                    -----  \n",
      " 0    id                        int64  \n",
      " 1    circle_id                 int64  \n",
      " 2    loc_og_t2o_mou            float64\n",
      " 3    std_og_t2o_mou            float64\n",
      " 4    loc_ic_t2o_mou            float64\n",
      " 5    last_date_of_month_6      object \n",
      " 6    last_date_of_month_7      object \n",
      " 7    last_date_of_month_8      object \n",
      " 8    arpu_6                    float64\n",
      " 9    arpu_7                    float64\n",
      " 10   arpu_8                    float64\n",
      " 11   onnet_mou_6               float64\n",
      " 12   onnet_mou_7               float64\n",
      " 13   onnet_mou_8               float64\n",
      " 14   offnet_mou_6              float64\n",
      " 15   offnet_mou_7              float64\n",
      " 16   offnet_mou_8              float64\n",
      " 17   roam_ic_mou_6             float64\n",
      " 18   roam_ic_mou_7             float64\n",
      " 19   roam_ic_mou_8             float64\n",
      " 20   roam_og_mou_6             float64\n",
      " 21   roam_og_mou_7             float64\n",
      " 22   roam_og_mou_8             float64\n",
      " 23   loc_og_t2t_mou_6          float64\n",
      " 24   loc_og_t2t_mou_7          float64\n",
      " 25   loc_og_t2t_mou_8          float64\n",
      " 26   loc_og_t2m_mou_6          float64\n",
      " 27   loc_og_t2m_mou_7          float64\n",
      " 28   loc_og_t2m_mou_8          float64\n",
      " 29   loc_og_t2f_mou_6          float64\n",
      " 30   loc_og_t2f_mou_7          float64\n",
      " 31   loc_og_t2f_mou_8          float64\n",
      " 32   loc_og_t2c_mou_6          float64\n",
      " 33   loc_og_t2c_mou_7          float64\n",
      " 34   loc_og_t2c_mou_8          float64\n",
      " 35   loc_og_mou_6              float64\n",
      " 36   loc_og_mou_7              float64\n",
      " 37   loc_og_mou_8              float64\n",
      " 38   std_og_t2t_mou_6          float64\n",
      " 39   std_og_t2t_mou_7          float64\n",
      " 40   std_og_t2t_mou_8          float64\n",
      " 41   std_og_t2m_mou_6          float64\n",
      " 42   std_og_t2m_mou_7          float64\n",
      " 43   std_og_t2m_mou_8          float64\n",
      " 44   std_og_t2f_mou_6          float64\n",
      " 45   std_og_t2f_mou_7          float64\n",
      " 46   std_og_t2f_mou_8          float64\n",
      " 47   std_og_t2c_mou_6          float64\n",
      " 48   std_og_t2c_mou_7          float64\n",
      " 49   std_og_t2c_mou_8          float64\n",
      " 50   std_og_mou_6              float64\n",
      " 51   std_og_mou_7              float64\n",
      " 52   std_og_mou_8              float64\n",
      " 53   isd_og_mou_6              float64\n",
      " 54   isd_og_mou_7              float64\n",
      " 55   isd_og_mou_8              float64\n",
      " 56   spl_og_mou_6              float64\n",
      " 57   spl_og_mou_7              float64\n",
      " 58   spl_og_mou_8              float64\n",
      " 59   og_others_6               float64\n",
      " 60   og_others_7               float64\n",
      " 61   og_others_8               float64\n",
      " 62   total_og_mou_6            float64\n",
      " 63   total_og_mou_7            float64\n",
      " 64   total_og_mou_8            float64\n",
      " 65   loc_ic_t2t_mou_6          float64\n",
      " 66   loc_ic_t2t_mou_7          float64\n",
      " 67   loc_ic_t2t_mou_8          float64\n",
      " 68   loc_ic_t2m_mou_6          float64\n",
      " 69   loc_ic_t2m_mou_7          float64\n",
      " 70   loc_ic_t2m_mou_8          float64\n",
      " 71   loc_ic_t2f_mou_6          float64\n",
      " 72   loc_ic_t2f_mou_7          float64\n",
      " 73   loc_ic_t2f_mou_8          float64\n",
      " 74   loc_ic_mou_6              float64\n",
      " 75   loc_ic_mou_7              float64\n",
      " 76   loc_ic_mou_8              float64\n",
      " 77   std_ic_t2t_mou_6          float64\n",
      " 78   std_ic_t2t_mou_7          float64\n",
      " 79   std_ic_t2t_mou_8          float64\n",
      " 80   std_ic_t2m_mou_6          float64\n",
      " 81   std_ic_t2m_mou_7          float64\n",
      " 82   std_ic_t2m_mou_8          float64\n",
      " 83   std_ic_t2f_mou_6          float64\n",
      " 84   std_ic_t2f_mou_7          float64\n",
      " 85   std_ic_t2f_mou_8          float64\n",
      " 86   std_ic_t2o_mou_6          float64\n",
      " 87   std_ic_t2o_mou_7          float64\n",
      " 88   std_ic_t2o_mou_8          float64\n",
      " 89   std_ic_mou_6              float64\n",
      " 90   std_ic_mou_7              float64\n",
      " 91   std_ic_mou_8              float64\n",
      " 92   total_ic_mou_6            float64\n",
      " 93   total_ic_mou_7            float64\n",
      " 94   total_ic_mou_8            float64\n",
      " 95   spl_ic_mou_6              float64\n",
      " 96   spl_ic_mou_7              float64\n",
      " 97   spl_ic_mou_8              float64\n",
      " 98   isd_ic_mou_6              float64\n",
      " 99   isd_ic_mou_7              float64\n",
      " 100  isd_ic_mou_8              float64\n",
      " 101  ic_others_6               float64\n",
      " 102  ic_others_7               float64\n",
      " 103  ic_others_8               float64\n",
      " 104  total_rech_num_6          int64  \n",
      " 105  total_rech_num_7          int64  \n",
      " 106  total_rech_num_8          int64  \n",
      " 107  total_rech_amt_6          int64  \n",
      " 108  total_rech_amt_7          int64  \n",
      " 109  total_rech_amt_8          int64  \n",
      " 110  max_rech_amt_6            int64  \n",
      " 111  max_rech_amt_7            int64  \n",
      " 112  max_rech_amt_8            int64  \n",
      " 113  date_of_last_rech_6       object \n",
      " 114  date_of_last_rech_7       object \n",
      " 115  date_of_last_rech_8       object \n",
      " 116  last_day_rch_amt_6        int64  \n",
      " 117  last_day_rch_amt_7        int64  \n",
      " 118  last_day_rch_amt_8        int64  \n",
      " 119  date_of_last_rech_data_6  object \n",
      " 120  date_of_last_rech_data_7  object \n",
      " 121  date_of_last_rech_data_8  object \n",
      " 122  total_rech_data_6         float64\n",
      " 123  total_rech_data_7         float64\n",
      " 124  total_rech_data_8         float64\n",
      " 125  max_rech_data_6           float64\n",
      " 126  max_rech_data_7           float64\n",
      " 127  max_rech_data_8           float64\n",
      " 128  count_rech_2g_6           float64\n",
      " 129  count_rech_2g_7           float64\n",
      " 130  count_rech_2g_8           float64\n",
      " 131  count_rech_3g_6           float64\n",
      " 132  count_rech_3g_7           float64\n",
      " 133  count_rech_3g_8           float64\n",
      " 134  av_rech_amt_data_6        float64\n",
      " 135  av_rech_amt_data_7        float64\n",
      " 136  av_rech_amt_data_8        float64\n",
      " 137  vol_2g_mb_6               float64\n",
      " 138  vol_2g_mb_7               float64\n",
      " 139  vol_2g_mb_8               float64\n",
      " 140  vol_3g_mb_6               float64\n",
      " 141  vol_3g_mb_7               float64\n",
      " 142  vol_3g_mb_8               float64\n",
      " 143  arpu_3g_6                 float64\n",
      " 144  arpu_3g_7                 float64\n",
      " 145  arpu_3g_8                 float64\n",
      " 146  arpu_2g_6                 float64\n",
      " 147  arpu_2g_7                 float64\n",
      " 148  arpu_2g_8                 float64\n",
      " 149  night_pck_user_6          float64\n",
      " 150  night_pck_user_7          float64\n",
      " 151  night_pck_user_8          float64\n",
      " 152  monthly_2g_6              int64  \n",
      " 153  monthly_2g_7              int64  \n",
      " 154  monthly_2g_8              int64  \n",
      " 155  sachet_2g_6               int64  \n",
      " 156  sachet_2g_7               int64  \n",
      " 157  sachet_2g_8               int64  \n",
      " 158  monthly_3g_6              int64  \n",
      " 159  monthly_3g_7              int64  \n",
      " 160  monthly_3g_8              int64  \n",
      " 161  sachet_3g_6               int64  \n",
      " 162  sachet_3g_7               int64  \n",
      " 163  sachet_3g_8               int64  \n",
      " 164  fb_user_6                 float64\n",
      " 165  fb_user_7                 float64\n",
      " 166  fb_user_8                 float64\n",
      " 167  aon                       int64  \n",
      " 168  aug_vbc_3g                float64\n",
      " 169  jul_vbc_3g                float64\n",
      " 170  jun_vbc_3g                float64\n",
      " 171  churn_probability         int64  \n",
      "dtypes: float64(135), int64(28), object(9)\n",
      "memory usage: 91.9+ MB\n",
      "-------------------------------------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>date_of_last_rech_data_6</th>\n",
       "      <th>date_of_last_rech_data_7</th>\n",
       "      <th>date_of_last_rech_data_8</th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <th>count_rech_3g_8</th>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <th>av_rech_amt_data_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <th>arpu_3g_7</th>\n",
       "      <th>arpu_3g_8</th>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <th>night_pck_user_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>31.277</td>\n",
       "      <td>87.009</td>\n",
       "      <td>7.527</td>\n",
       "      <td>48.58</td>\n",
       "      <td>124.38</td>\n",
       "      <td>1.29</td>\n",
       "      <td>32.24</td>\n",
       "      <td>96.68</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.29</td>\n",
       "      <td>16.04</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.53</td>\n",
       "      <td>16.04</td>\n",
       "      <td>2.61</td>\n",
       "      <td>46.34</td>\n",
       "      <td>124.38</td>\n",
       "      <td>1.01</td>\n",
       "      <td>18.75</td>\n",
       "      <td>80.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.09</td>\n",
       "      <td>204.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.21</td>\n",
       "      <td>221.68</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.68</td>\n",
       "      <td>7.79</td>\n",
       "      <td>0.83</td>\n",
       "      <td>21.08</td>\n",
       "      <td>16.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.26</td>\n",
       "      <td>24.76</td>\n",
       "      <td>24.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>7.46</td>\n",
       "      <td>19.96</td>\n",
       "      <td>14.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.46</td>\n",
       "      <td>27.58</td>\n",
       "      <td>15.18</td>\n",
       "      <td>11.84</td>\n",
       "      <td>53.04</td>\n",
       "      <td>40.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>6/22/2014</td>\n",
       "      <td>7/10/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>122.787</td>\n",
       "      <td>42.953</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.99</td>\n",
       "      <td>30.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.01</td>\n",
       "      <td>29.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.73</td>\n",
       "      <td>31.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.73</td>\n",
       "      <td>31.66</td>\n",
       "      <td>1.68</td>\n",
       "      <td>19.09</td>\n",
       "      <td>10.53</td>\n",
       "      <td>1.41</td>\n",
       "      <td>18.68</td>\n",
       "      <td>11.09</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.44</td>\n",
       "      <td>39.44</td>\n",
       "      <td>25.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.44</td>\n",
       "      <td>39.44</td>\n",
       "      <td>25.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>50</td>\n",
       "      <td>6/12/2014</td>\n",
       "      <td>7/10/2014</td>\n",
       "      <td>8/26/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/8/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>352.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>60.806</td>\n",
       "      <td>103.176</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.53</td>\n",
       "      <td>15.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53.99</td>\n",
       "      <td>82.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>12.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.64</td>\n",
       "      <td>12.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.94</td>\n",
       "      <td>82.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.94</td>\n",
       "      <td>84.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.49</td>\n",
       "      <td>99.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.51</td>\n",
       "      <td>6.16</td>\n",
       "      <td>6.49</td>\n",
       "      <td>89.86</td>\n",
       "      <td>25.18</td>\n",
       "      <td>23.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94.38</td>\n",
       "      <td>31.34</td>\n",
       "      <td>30.01</td>\n",
       "      <td>11.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.21</td>\n",
       "      <td>2.48</td>\n",
       "      <td>6.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>6.38</td>\n",
       "      <td>124.29</td>\n",
       "      <td>33.83</td>\n",
       "      <td>36.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>6/11/2014</td>\n",
       "      <td>7/22/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>156.362</td>\n",
       "      <td>205.260</td>\n",
       "      <td>111.095</td>\n",
       "      <td>7.26</td>\n",
       "      <td>16.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68.76</td>\n",
       "      <td>78.48</td>\n",
       "      <td>50.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>6.99</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.91</td>\n",
       "      <td>44.89</td>\n",
       "      <td>23.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.03</td>\n",
       "      <td>44.91</td>\n",
       "      <td>48.84</td>\n",
       "      <td>23.63</td>\n",
       "      <td>0.26</td>\n",
       "      <td>12.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.33</td>\n",
       "      <td>25.93</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.16</td>\n",
       "      <td>37.99</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.95</td>\n",
       "      <td>9.13</td>\n",
       "      <td>25.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.03</td>\n",
       "      <td>95.98</td>\n",
       "      <td>53.84</td>\n",
       "      <td>24.98</td>\n",
       "      <td>4.84</td>\n",
       "      <td>23.88</td>\n",
       "      <td>53.99</td>\n",
       "      <td>44.23</td>\n",
       "      <td>57.14</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86.21</td>\n",
       "      <td>49.89</td>\n",
       "      <td>81.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.81</td>\n",
       "      <td>95.11</td>\n",
       "      <td>50.18</td>\n",
       "      <td>83.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>240</td>\n",
       "      <td>130</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>6/15/2014</td>\n",
       "      <td>7/21/2014</td>\n",
       "      <td>8/25/2014</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>240.708</td>\n",
       "      <td>128.191</td>\n",
       "      <td>101.565</td>\n",
       "      <td>21.28</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.13</td>\n",
       "      <td>56.99</td>\n",
       "      <td>38.11</td>\n",
       "      <td>9.63</td>\n",
       "      <td>53.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.16</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.13</td>\n",
       "      <td>36.74</td>\n",
       "      <td>19.88</td>\n",
       "      <td>4.61</td>\n",
       "      <td>11.99</td>\n",
       "      <td>1.23</td>\n",
       "      <td>5.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58.91</td>\n",
       "      <td>25.94</td>\n",
       "      <td>15.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.26</td>\n",
       "      <td>42.94</td>\n",
       "      <td>15.76</td>\n",
       "      <td>5.44</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.66</td>\n",
       "      <td>10.58</td>\n",
       "      <td>4.33</td>\n",
       "      <td>19.49</td>\n",
       "      <td>5.51</td>\n",
       "      <td>3.63</td>\n",
       "      <td>6.14</td>\n",
       "      <td>21.54</td>\n",
       "      <td>9.36</td>\n",
       "      <td>28.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.54</td>\n",
       "      <td>9.36</td>\n",
       "      <td>28.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>290</td>\n",
       "      <td>136</td>\n",
       "      <td>122</td>\n",
       "      <td>50</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/26/2014</td>\n",
       "      <td>8/30/2014</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/23/2014</td>\n",
       "      <td>8/20/2014</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>390.8</td>\n",
       "      <td>308.89</td>\n",
       "      <td>213.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0   0        109             0.0             0.0             0.0   \n",
       "1   1        109             0.0             0.0             0.0   \n",
       "2   2        109             0.0             0.0             0.0   \n",
       "3   3        109             0.0             0.0             0.0   \n",
       "4   4        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8   arpu_6  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   31.277   \n",
       "1            6/30/2014            7/31/2014            8/31/2014    0.000   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   60.806   \n",
       "3            6/30/2014            7/31/2014            8/31/2014  156.362   \n",
       "4            6/30/2014            7/31/2014            8/31/2014  240.708   \n",
       "\n",
       "    arpu_7   arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  offnet_mou_6  \\\n",
       "0   87.009    7.527        48.58       124.38         1.29         32.24   \n",
       "1  122.787   42.953         0.00         0.00         0.00          0.00   \n",
       "2  103.176    0.000         0.53        15.93         0.00         53.99   \n",
       "3  205.260  111.095         7.26        16.01         0.00         68.76   \n",
       "4  128.191  101.565        21.28         4.83         6.13         56.99   \n",
       "\n",
       "   offnet_mou_7  offnet_mou_8  roam_ic_mou_6  roam_ic_mou_7  roam_ic_mou_8  \\\n",
       "0         96.68          2.33           0.00            0.0            0.0   \n",
       "1         25.99         30.89           0.00            0.0            0.0   \n",
       "2         82.05          0.00           0.00            0.0            0.0   \n",
       "3         78.48         50.23           0.00            0.0            0.0   \n",
       "4         38.11          9.63          53.64            0.0            0.0   \n",
       "\n",
       "   roam_og_mou_6  roam_og_mou_7  roam_og_mou_8  loc_og_t2t_mou_6  \\\n",
       "0           0.00            0.0           0.00              2.23   \n",
       "1           0.00            0.0           0.00              0.00   \n",
       "2           0.00            0.0           0.00              0.53   \n",
       "3           0.00            0.0           1.63              6.99   \n",
       "4          15.73            0.0           0.00             10.16   \n",
       "\n",
       "   loc_og_t2t_mou_7  loc_og_t2t_mou_8  loc_og_t2m_mou_6  loc_og_t2m_mou_7  \\\n",
       "0              0.00              0.28              5.29             16.04   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2             12.98              0.00             24.11              0.00   \n",
       "3              3.94              0.00             37.91             44.89   \n",
       "4              4.83              6.13             36.74             19.88   \n",
       "\n",
       "   loc_og_t2m_mou_8  loc_og_t2f_mou_6  loc_og_t2f_mou_7  loc_og_t2f_mou_8  \\\n",
       "0              2.33              0.00              0.00              0.00   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3             23.63              0.00              0.00              0.00   \n",
       "4              4.61             11.99              1.23              5.01   \n",
       "\n",
       "   loc_og_t2c_mou_6  loc_og_t2c_mou_7  loc_og_t2c_mou_8  loc_og_mou_6  \\\n",
       "0              0.00              0.00              0.00          7.53   \n",
       "1              0.00             22.01             29.79          0.00   \n",
       "2              2.14              0.00              0.00         24.64   \n",
       "3              0.00              0.00              8.03         44.91   \n",
       "4              0.00              9.85              0.00         58.91   \n",
       "\n",
       "   loc_og_mou_7  loc_og_mou_8  std_og_t2t_mou_6  std_og_t2t_mou_7  \\\n",
       "0         16.04          2.61             46.34            124.38   \n",
       "1          0.00          0.00              0.00              0.00   \n",
       "2         12.98          0.00              0.00              2.94   \n",
       "3         48.84         23.63              0.26             12.06   \n",
       "4         25.94         15.76              0.00              0.00   \n",
       "\n",
       "   std_og_t2t_mou_8  std_og_t2m_mou_6  std_og_t2m_mou_7  std_og_t2m_mou_8  \\\n",
       "0              1.01             18.75             80.61               0.0   \n",
       "1              0.00              0.00              0.00               0.0   \n",
       "2              0.00             28.94             82.05               0.0   \n",
       "3              0.00             15.33             25.93               4.6   \n",
       "4              0.00              4.35              0.00               0.0   \n",
       "\n",
       "   std_og_t2f_mou_6  std_og_t2f_mou_7  std_og_t2f_mou_8  std_og_t2c_mou_6  \\\n",
       "0              0.00               0.0               0.0               0.0   \n",
       "1              0.00               0.0               0.0               0.0   \n",
       "2              0.00               0.0               0.0               0.0   \n",
       "3              0.56               0.0               0.0               0.0   \n",
       "4              0.00               0.0               0.0               0.0   \n",
       "\n",
       "   std_og_t2c_mou_7  std_og_t2c_mou_8  std_og_mou_6  std_og_mou_7  \\\n",
       "0               0.0               0.0         65.09        204.99   \n",
       "1               0.0               0.0          0.00          0.00   \n",
       "2               0.0               0.0         28.94         84.99   \n",
       "3               0.0               0.0         16.16         37.99   \n",
       "4               0.0               0.0          4.35          0.00   \n",
       "\n",
       "   std_og_mou_8  isd_og_mou_6  isd_og_mou_7  isd_og_mou_8  spl_og_mou_6  \\\n",
       "0          1.01           0.0           0.0           0.0          8.20   \n",
       "1          0.00           0.0           0.0           0.0          0.00   \n",
       "2          0.00           0.0           0.0           0.0          2.89   \n",
       "3          4.60           0.0           0.0           0.0         14.95   \n",
       "4          0.00           0.0           0.0           0.0          0.00   \n",
       "\n",
       "   spl_og_mou_7  spl_og_mou_8  og_others_6  og_others_7  og_others_8  \\\n",
       "0          0.63          0.00         0.38          0.0          0.0   \n",
       "1         30.73         31.66         0.00          0.0          0.0   \n",
       "2          1.38          0.00         0.00          0.0          0.0   \n",
       "3          9.13         25.61         0.00          0.0          0.0   \n",
       "4         17.00          0.00         0.00          0.0          0.0   \n",
       "\n",
       "   total_og_mou_6  total_og_mou_7  total_og_mou_8  loc_ic_t2t_mou_6  \\\n",
       "0           81.21          221.68            3.63              2.43   \n",
       "1            0.00           30.73           31.66              1.68   \n",
       "2           56.49           99.36            0.00              4.51   \n",
       "3           76.03           95.98           53.84             24.98   \n",
       "4           63.26           42.94           15.76              5.44   \n",
       "\n",
       "   loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  \\\n",
       "0              3.68              7.79              0.83             21.08   \n",
       "1             19.09             10.53              1.41             18.68   \n",
       "2              6.16              6.49             89.86             25.18   \n",
       "3              4.84             23.88             53.99             44.23   \n",
       "4              1.39              2.66             10.58              4.33   \n",
       "\n",
       "   loc_ic_t2m_mou_8  loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  \\\n",
       "0             16.91              0.00              0.00              0.00   \n",
       "1             11.09              0.35              1.66              3.40   \n",
       "2             23.51              0.00              0.00              0.00   \n",
       "3             57.14              7.23              0.81              0.00   \n",
       "4             19.49              5.51              3.63              6.14   \n",
       "\n",
       "   loc_ic_mou_6  loc_ic_mou_7  loc_ic_mou_8  std_ic_t2t_mou_6  \\\n",
       "0          3.26         24.76         24.71              0.00   \n",
       "1          3.44         39.44         25.03              0.00   \n",
       "2         94.38         31.34         30.01             11.69   \n",
       "3         86.21         49.89         81.03              0.00   \n",
       "4         21.54          9.36         28.31              0.00   \n",
       "\n",
       "   std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2m_mou_6  std_ic_t2m_mou_7  \\\n",
       "0              7.61              0.21              7.46             19.96   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2              0.00              0.00             18.21              2.48   \n",
       "3              0.00              0.00              8.89              0.28   \n",
       "4              0.00              0.00              0.00              0.00   \n",
       "\n",
       "   std_ic_t2m_mou_8  std_ic_t2f_mou_6  std_ic_t2f_mou_7  std_ic_t2f_mou_8  \\\n",
       "0             14.96               0.0               0.0               0.0   \n",
       "1              0.00               0.0               0.0               0.0   \n",
       "2              6.38               0.0               0.0               0.0   \n",
       "3              2.81               0.0               0.0               0.0   \n",
       "4              0.00               0.0               0.0               0.0   \n",
       "\n",
       "   std_ic_t2o_mou_6  std_ic_t2o_mou_7  std_ic_t2o_mou_8  std_ic_mou_6  \\\n",
       "0               0.0               0.0               0.0          7.46   \n",
       "1               0.0               0.0               0.0          0.00   \n",
       "2               0.0               0.0               0.0         29.91   \n",
       "3               0.0               0.0               0.0          8.89   \n",
       "4               0.0               0.0               0.0          0.00   \n",
       "\n",
       "   std_ic_mou_7  std_ic_mou_8  total_ic_mou_6  total_ic_mou_7  total_ic_mou_8  \\\n",
       "0         27.58         15.18           11.84           53.04           40.56   \n",
       "1          0.00          0.00            3.44           39.44           25.04   \n",
       "2          2.48          6.38          124.29           33.83           36.64   \n",
       "3          0.28          2.81           95.11           50.18           83.84   \n",
       "4          0.00          0.00           21.54            9.36           28.31   \n",
       "\n",
       "   spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  isd_ic_mou_6  isd_ic_mou_7  \\\n",
       "0           0.0           0.0          0.66           0.0           0.0   \n",
       "1           0.0           0.0          0.01           0.0           0.0   \n",
       "2           0.0           0.0          0.00           0.0           0.0   \n",
       "3           0.0           0.0          0.00           0.0           0.0   \n",
       "4           0.0           0.0          0.00           0.0           0.0   \n",
       "\n",
       "   isd_ic_mou_8  ic_others_6  ic_others_7  ic_others_8  total_rech_num_6  \\\n",
       "0           0.0         1.11         0.69         0.00                 3   \n",
       "1           0.0         0.00         0.00         0.00                 3   \n",
       "2           0.0         0.00         0.00         0.25                 2   \n",
       "3           0.0         0.00         0.00         0.00                 2   \n",
       "4           0.0         0.00         0.00         0.00                13   \n",
       "\n",
       "   total_rech_num_7  total_rech_num_8  total_rech_amt_6  total_rech_amt_7  \\\n",
       "0                 2                 2                77                65   \n",
       "1                 4                 5                 0               145   \n",
       "2                 4                 2                70               120   \n",
       "3                 4                 3               160               240   \n",
       "4                10                 8               290               136   \n",
       "\n",
       "   total_rech_amt_8  max_rech_amt_6  max_rech_amt_7  max_rech_amt_8  \\\n",
       "0                10              65              65              10   \n",
       "1                50               0             145              50   \n",
       "2                 0              70              70               0   \n",
       "3               130             110             110              50   \n",
       "4               122              50              41              30   \n",
       "\n",
       "  date_of_last_rech_6 date_of_last_rech_7 date_of_last_rech_8  \\\n",
       "0           6/22/2014           7/10/2014           8/24/2014   \n",
       "1           6/12/2014           7/10/2014           8/26/2014   \n",
       "2           6/11/2014           7/22/2014           8/24/2014   \n",
       "3           6/15/2014           7/21/2014           8/25/2014   \n",
       "4           6/25/2014           7/26/2014           8/30/2014   \n",
       "\n",
       "   last_day_rch_amt_6  last_day_rch_amt_7  last_day_rch_amt_8  \\\n",
       "0                  65                  65                   0   \n",
       "1                   0                   0                   0   \n",
       "2                  70                  50                   0   \n",
       "3                 110                 110                  50   \n",
       "4                  25                  10                  30   \n",
       "\n",
       "  date_of_last_rech_data_6 date_of_last_rech_data_7 date_of_last_rech_data_8  \\\n",
       "0                      NaN                      NaN                      NaN   \n",
       "1                      NaN                 7/8/2014                      NaN   \n",
       "2                      NaN                      NaN                      NaN   \n",
       "3                      NaN                      NaN                      NaN   \n",
       "4                6/25/2014                7/23/2014                8/20/2014   \n",
       "\n",
       "   total_rech_data_6  total_rech_data_7  total_rech_data_8  max_rech_data_6  \\\n",
       "0                NaN                NaN                NaN              NaN   \n",
       "1                NaN                1.0                NaN              NaN   \n",
       "2                NaN                NaN                NaN              NaN   \n",
       "3                NaN                NaN                NaN              NaN   \n",
       "4                7.0                7.0                6.0             25.0   \n",
       "\n",
       "   max_rech_data_7  max_rech_data_8  count_rech_2g_6  count_rech_2g_7  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1            145.0              NaN              NaN              0.0   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4             41.0             25.0              7.0              6.0   \n",
       "\n",
       "   count_rech_2g_8  count_rech_3g_6  count_rech_3g_7  count_rech_3g_8  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              1.0              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              6.0              0.0              1.0              0.0   \n",
       "\n",
       "   av_rech_amt_data_6  av_rech_amt_data_7  av_rech_amt_data_8  vol_2g_mb_6  \\\n",
       "0                 NaN                 NaN                 NaN          0.0   \n",
       "1                 NaN               145.0                 NaN          0.0   \n",
       "2                 NaN                 NaN                 NaN          0.0   \n",
       "3                 NaN                 NaN                 NaN          0.0   \n",
       "4               175.0               191.0               142.0        390.8   \n",
       "\n",
       "   vol_2g_mb_7  vol_2g_mb_8  vol_3g_mb_6  vol_3g_mb_7  vol_3g_mb_8  arpu_3g_6  \\\n",
       "0         0.00         0.00          0.0         0.00          0.0        NaN   \n",
       "1       352.91         0.00          0.0         3.96          0.0        NaN   \n",
       "2         0.00         0.00          0.0         0.00          0.0        NaN   \n",
       "3         0.00         0.00          0.0         0.00          0.0        NaN   \n",
       "4       308.89       213.47          0.0         0.00          0.0        0.0   \n",
       "\n",
       "   arpu_3g_7  arpu_3g_8  arpu_2g_6  arpu_2g_7  arpu_2g_8  night_pck_user_6  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "1     122.07        NaN        NaN     122.08        NaN               NaN   \n",
       "2        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "3        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "4      35.00        0.0        0.0      35.12        0.0               0.0   \n",
       "\n",
       "   night_pck_user_7  night_pck_user_8  monthly_2g_6  monthly_2g_7  \\\n",
       "0               NaN               NaN             0             0   \n",
       "1               0.0               NaN             0             0   \n",
       "2               NaN               NaN             0             0   \n",
       "3               NaN               NaN             0             0   \n",
       "4               0.0               0.0             0             0   \n",
       "\n",
       "   monthly_2g_8  sachet_2g_6  sachet_2g_7  sachet_2g_8  monthly_3g_6  \\\n",
       "0             0            0            0            0             0   \n",
       "1             0            0            0            0             0   \n",
       "2             0            0            0            0             0   \n",
       "3             0            0            0            0             0   \n",
       "4             0            7            6            6             0   \n",
       "\n",
       "   monthly_3g_7  monthly_3g_8  sachet_3g_6  sachet_3g_7  sachet_3g_8  \\\n",
       "0             0             0            0            0            0   \n",
       "1             1             0            0            0            0   \n",
       "2             0             0            0            0            0   \n",
       "3             0             0            0            0            0   \n",
       "4             0             0            0            1            0   \n",
       "\n",
       "   fb_user_6  fb_user_7  fb_user_8   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \\\n",
       "0        NaN        NaN        NaN  1958         0.0         0.0         0.0   \n",
       "1        NaN        1.0        NaN   710         0.0         0.0         0.0   \n",
       "2        NaN        NaN        NaN   882         0.0         0.0         0.0   \n",
       "3        NaN        NaN        NaN   982         0.0         0.0         0.0   \n",
       "4        1.0        1.0        1.0   647         0.0         0.0         0.0   \n",
       "\n",
       "   churn_probability  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "print('Dataframe Shape: ', data.shape); print('-'*80, '\\n');\n",
    "print(\"Dataframe Info: \\n\"); data.info(verbose=True); print('-'*80, '\\n')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d98e09fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rech=data.total_rech_amt_6+data.total_rech_amt_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b05cd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "740.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_rech.quantile(0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f5921d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    69999.000000\n",
       "mean       650.516150\n",
       "std        752.345306\n",
       "min          0.000000\n",
       "25%        230.000000\n",
       "50%        458.000000\n",
       "75%        839.500000\n",
       "max      75525.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_rech.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13167338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=data[data.total_rech_amt_6+data.total_rech_amt_7>740]\n",
    "#data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8fcf2b",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799b40a3",
   "metadata": {},
   "source": [
    "### Identify columns that have no variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99c51b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "data_unique_count = data.nunique().sort_values(ascending=False)\n",
    "\n",
    "# Find columns with all NULL entries\n",
    "data_unique_count_is_zero = data_unique_count[data_unique_count == 0]\n",
    "print(data_unique_count_is_zero.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f91e5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "# Find columns with all same entries\n",
    "data_unique_count_is_one = data_unique_count[data_unique_count == 1]\n",
    "print(data_unique_count_is_one.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f71f843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "std_ic_t2o_mou_8        1\n",
       "std_ic_t2o_mou_7        1\n",
       "circle_id               1\n",
       "std_og_t2c_mou_8        1\n",
       "std_og_t2c_mou_7        1\n",
       "std_og_t2c_mou_6        1\n",
       "last_date_of_month_8    1\n",
       "last_date_of_month_7    1\n",
       "last_date_of_month_6    1\n",
       "loc_ic_t2o_mou          1\n",
       "std_og_t2o_mou          1\n",
       "loc_og_t2o_mou          1\n",
       "std_ic_t2o_mou_6        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unique_count_is_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f95ec860",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop columns with single value in all rows\n",
    "\n",
    "drop_no_varience_columns = list(data_unique_count_is_one.index)\n",
    "data.drop(drop_no_varience_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0134afd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 159)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5c851d",
   "metadata": {},
   "source": [
    "### Check for Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44a43f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with all NULL values = 0\n"
     ]
    }
   ],
   "source": [
    "# Check how many rows have all missing values\n",
    "print(\"Rows with all NULL values =\",  data.isnull().all(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2e99d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMissingValues(missingCutoff):\n",
    "    # Function to retun the columns with more than missingCutoff% missing values.\n",
    "    missing = round(100*(data.isnull().sum()/data.shape[0]))\n",
    "    print(\"There are {} features having more than {}% missing values/entries\".format(len(missing.loc[missing > missingCutoff]),missingCutoff))\n",
    "    return missing.loc[missing > missingCutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b7eed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeNan(data, imputeColList=False, missingColList=False):\n",
    "    # Function impute the nan with 0\n",
    "    if imputeColList:\n",
    "        for col in [y + s for s in ['_6','_7','_8'] for y in imputeColList]:\n",
    "            data[col].fillna(0, inplace=True)\n",
    "    else:    \n",
    "        for col in missingColList:\n",
    "            data[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7efe61d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 30 features having more than 50% missing values/entries\n"
     ]
    }
   ],
   "source": [
    "# Missing values per column expressed as % of total number of values\n",
    "high_missing_cols=getMissingValues(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54775200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_of_last_rech_data_6', 'date_of_last_rech_data_7',\n",
       "       'date_of_last_rech_data_8', 'total_rech_data_6', 'total_rech_data_7',\n",
       "       'total_rech_data_8', 'max_rech_data_6', 'max_rech_data_7',\n",
       "       'max_rech_data_8', 'count_rech_2g_6', 'count_rech_2g_7',\n",
       "       'count_rech_2g_8', 'count_rech_3g_6', 'count_rech_3g_7',\n",
       "       'count_rech_3g_8', 'av_rech_amt_data_6', 'av_rech_amt_data_7',\n",
       "       'av_rech_amt_data_8', 'arpu_3g_6', 'arpu_3g_7', 'arpu_3g_8',\n",
       "       'arpu_2g_6', 'arpu_2g_7', 'arpu_2g_8', 'night_pck_user_6',\n",
       "       'night_pck_user_7', 'night_pck_user_8', 'fb_user_6', 'fb_user_7',\n",
       "       'fb_user_8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_missing_cols.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "772a0c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(high_missing_cols.index,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4f7a4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 129)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a66dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "439e14c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='total_rech_amt_8', ylabel='Density'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(data.total_rech_amt_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ab3f18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 features having more than 50% missing values/entries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMissingValues(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f705745",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 84 features having more than 0% missing values/entries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "onnet_mou_6            4.0\n",
       "onnet_mou_7            4.0\n",
       "onnet_mou_8            5.0\n",
       "offnet_mou_6           4.0\n",
       "offnet_mou_7           4.0\n",
       "offnet_mou_8           5.0\n",
       "roam_ic_mou_6          4.0\n",
       "roam_ic_mou_7          4.0\n",
       "roam_ic_mou_8          5.0\n",
       "roam_og_mou_6          4.0\n",
       "roam_og_mou_7          4.0\n",
       "roam_og_mou_8          5.0\n",
       "loc_og_t2t_mou_6       4.0\n",
       "loc_og_t2t_mou_7       4.0\n",
       "loc_og_t2t_mou_8       5.0\n",
       "loc_og_t2m_mou_6       4.0\n",
       "loc_og_t2m_mou_7       4.0\n",
       "loc_og_t2m_mou_8       5.0\n",
       "loc_og_t2f_mou_6       4.0\n",
       "loc_og_t2f_mou_7       4.0\n",
       "loc_og_t2f_mou_8       5.0\n",
       "loc_og_t2c_mou_6       4.0\n",
       "loc_og_t2c_mou_7       4.0\n",
       "loc_og_t2c_mou_8       5.0\n",
       "loc_og_mou_6           4.0\n",
       "loc_og_mou_7           4.0\n",
       "loc_og_mou_8           5.0\n",
       "std_og_t2t_mou_6       4.0\n",
       "std_og_t2t_mou_7       4.0\n",
       "std_og_t2t_mou_8       5.0\n",
       "std_og_t2m_mou_6       4.0\n",
       "std_og_t2m_mou_7       4.0\n",
       "std_og_t2m_mou_8       5.0\n",
       "std_og_t2f_mou_6       4.0\n",
       "std_og_t2f_mou_7       4.0\n",
       "std_og_t2f_mou_8       5.0\n",
       "std_og_mou_6           4.0\n",
       "std_og_mou_7           4.0\n",
       "std_og_mou_8           5.0\n",
       "isd_og_mou_6           4.0\n",
       "isd_og_mou_7           4.0\n",
       "isd_og_mou_8           5.0\n",
       "spl_og_mou_6           4.0\n",
       "spl_og_mou_7           4.0\n",
       "spl_og_mou_8           5.0\n",
       "og_others_6            4.0\n",
       "og_others_7            4.0\n",
       "og_others_8            5.0\n",
       "loc_ic_t2t_mou_6       4.0\n",
       "loc_ic_t2t_mou_7       4.0\n",
       "loc_ic_t2t_mou_8       5.0\n",
       "loc_ic_t2m_mou_6       4.0\n",
       "loc_ic_t2m_mou_7       4.0\n",
       "loc_ic_t2m_mou_8       5.0\n",
       "loc_ic_t2f_mou_6       4.0\n",
       "loc_ic_t2f_mou_7       4.0\n",
       "loc_ic_t2f_mou_8       5.0\n",
       "loc_ic_mou_6           4.0\n",
       "loc_ic_mou_7           4.0\n",
       "loc_ic_mou_8           5.0\n",
       "std_ic_t2t_mou_6       4.0\n",
       "std_ic_t2t_mou_7       4.0\n",
       "std_ic_t2t_mou_8       5.0\n",
       "std_ic_t2m_mou_6       4.0\n",
       "std_ic_t2m_mou_7       4.0\n",
       "std_ic_t2m_mou_8       5.0\n",
       "std_ic_t2f_mou_6       4.0\n",
       "std_ic_t2f_mou_7       4.0\n",
       "std_ic_t2f_mou_8       5.0\n",
       "std_ic_mou_6           4.0\n",
       "std_ic_mou_7           4.0\n",
       "std_ic_mou_8           5.0\n",
       "spl_ic_mou_6           4.0\n",
       "spl_ic_mou_7           4.0\n",
       "spl_ic_mou_8           5.0\n",
       "isd_ic_mou_6           4.0\n",
       "isd_ic_mou_7           4.0\n",
       "isd_ic_mou_8           5.0\n",
       "ic_others_6            4.0\n",
       "ic_others_7            4.0\n",
       "ic_others_8            5.0\n",
       "date_of_last_rech_6    2.0\n",
       "date_of_last_rech_7    2.0\n",
       "date_of_last_rech_8    4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMissingValues(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfff5eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 129)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b7c582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_vars = [\"date_of_last_rech_6\", \"date_of_last_rech_7\", \"date_of_last_rech_8\"]\n",
    "\n",
    "data.drop(date_vars, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4556287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['churn_probability'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[data.nunique()==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbb6cfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 126)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67bdb83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b5e2370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 125)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ed8c30",
   "metadata": {},
   "source": [
    "## Modelling Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ec7e171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[data.columns[~data.columns.isin(['churn_probability'])]]\n",
    "Y = data['churn_probability']\n",
    "numeric_cols=X.columns[X.nunique()!=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2cbccad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_impute=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dacbbd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "if zero_impute==0:\n",
    "    orig_cols=X.columns    \n",
    "    simple_imtr = SimpleImputer(strategy='median')\n",
    "    X = pd.DataFrame(simple_imtr.fit_transform(X))\n",
    "    X.columns=orig_cols\n",
    "else :\n",
    "    X=X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1342f085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 124)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_columns=X.columns\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "X_std= pd.DataFrame(X_std)\n",
    "X_std.columns=orig_columns\n",
    "X_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6f8707f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std,Y, train_size=0.7,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7f66e6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['arpu_6', 'arpu_7', 'arpu_8', 'onnet_mou_6', 'onnet_mou_7',\n",
       "       'onnet_mou_8', 'offnet_mou_6', 'offnet_mou_7', 'offnet_mou_8',\n",
       "       'roam_ic_mou_6',\n",
       "       ...\n",
       "       'monthly_3g_6', 'monthly_3g_7', 'monthly_3g_8', 'sachet_3g_6',\n",
       "       'sachet_3g_7', 'sachet_3g_8', 'aon', 'aug_vbc_3g', 'jul_vbc_3g',\n",
       "       'jun_vbc_3g'],\n",
       "      dtype='object', length=124)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f7e10ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size (48999, 124)\n",
      "Training dataset target size (48999,)\n",
      "Test dataset size (21000, 124)\n",
      "Test dataset target size (21000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training dataset size\",X_train.shape)\n",
    "print(\"Training dataset target size\",y_train.shape)\n",
    "print(\"Test dataset size\",X_test.shape)\n",
    "print(\"Test dataset target size\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f4972160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imbalance, counts of label '1': 4977\n",
      "Data imbalance, counts of label '0': 44022 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Data imbalance, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Data imbalance, counts of label '0': {} \\n\".format(sum(y_train==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46aa758",
   "metadata": {},
   "source": [
    "### Using SMOTE to correct data imbalance\n",
    "## class weights giving better results - using class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2ea0e80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After update, the shape of train_X: (48999, 124)\n",
      "After update, the shape of train_y: (48999,) \n",
      "\n",
      "After update, counts of label '1': 4977\n",
      "After update, counts of label '0': 44022\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "#X_train_smote, y_train_smote= sm.fit_resample(X_train, y_train)\n",
    "X_train_smote = X_train\n",
    "y_train_smote = y_train\n",
    "\n",
    "count_class_1 = y_train.value_counts()[0]\n",
    "count_class_2 = y_train.value_counts()[1]\n",
    "ratio = count_class_1/count_class_2\n",
    "\n",
    "print('After update, the shape of train_X: {}'.format(X_train_smote.shape))\n",
    "print('After update, the shape of train_y: {} \\n'.format(y_train_smote.shape))\n",
    "\n",
    "print(\"After update, counts of label '1': {}\".format(sum(y_train_smote==1)))\n",
    "print(\"After update, counts of label '0': {}\".format(sum(y_train_smote==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0082f4",
   "metadata": {},
   "source": [
    "## PCA Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4ee8f080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA object with default parameter\n",
    "pca = PCA(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5f122369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(random_state=42)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Doing PCA on the train data\n",
    "pca.fit(X_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6a8d419e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.74251175e-01  1.80525332e-01  1.71742889e-01 ...  4.43083434e-02\n",
      "   4.22535512e-02  3.98259206e-02]\n",
      " [-4.36200672e-02 -5.75469839e-02 -4.89945514e-02 ...  4.84325918e-02\n",
      "   4.86422990e-02  4.74457646e-02]\n",
      " [ 9.56575136e-02  9.73915670e-02  1.00299806e-01 ...  2.37744552e-01\n",
      "   2.37871168e-01  2.28866910e-01]\n",
      " ...\n",
      " [-6.47648950e-07  7.00617806e-08  1.75717210e-07 ...  1.50975662e-07\n",
      "  -3.36736950e-09  6.95204576e-08]\n",
      " [-4.74181172e-08  1.84299491e-07  1.65052897e-07 ...  4.14637319e-08\n",
      "   9.08402823e-08 -1.33196446e-08]\n",
      " [-6.35577851e-08 -5.50815223e-08 -2.34927270e-07 ... -9.49849448e-08\n",
      "   1.02307801e-07 -1.14802072e-08]]\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "[1.32067162e-01 7.75317415e-02 5.14015797e-02 4.51354322e-02\n",
      " 3.61614332e-02 3.23002044e-02 2.77552900e-02 2.60567084e-02\n",
      " 2.51607158e-02 2.44716784e-02 2.33572775e-02 2.32536136e-02\n",
      " 2.17276582e-02 2.08195001e-02 1.94752958e-02 1.78448184e-02\n",
      " 1.75314774e-02 1.64891593e-02 1.46225540e-02 1.45394009e-02\n",
      " 1.34954209e-02 1.28652543e-02 1.26444168e-02 1.07422581e-02\n",
      " 1.05766293e-02 1.02079588e-02 9.63549414e-03 9.51016055e-03\n",
      " 8.83187875e-03 8.45444428e-03 8.28530047e-03 8.08225373e-03\n",
      " 7.89061253e-03 7.43487039e-03 7.04219772e-03 6.86561100e-03\n",
      " 6.78275696e-03 6.54567448e-03 6.26957568e-03 6.19453831e-03\n",
      " 5.77432006e-03 5.65821777e-03 5.50729792e-03 5.28117409e-03\n",
      " 4.70606769e-03 4.59936190e-03 4.50609773e-03 4.31850641e-03\n",
      " 4.28485180e-03 4.19879321e-03 4.03160715e-03 3.89903394e-03\n",
      " 3.87158284e-03 3.84651224e-03 3.63309718e-03 3.59058365e-03\n",
      " 3.51075123e-03 3.39411614e-03 3.13479680e-03 2.98691574e-03\n",
      " 2.95504335e-03 2.87956592e-03 2.83011708e-03 2.73234943e-03\n",
      " 2.68754432e-03 2.64598908e-03 2.61134297e-03 2.55573177e-03\n",
      " 2.52465272e-03 2.39509705e-03 2.32524984e-03 2.30758113e-03\n",
      " 2.25216094e-03 2.21498005e-03 2.17295490e-03 2.13647839e-03\n",
      " 2.02756061e-03 1.97181468e-03 1.90720394e-03 1.88495973e-03\n",
      " 1.85669351e-03 1.75788933e-03 1.71073379e-03 1.62640414e-03\n",
      " 1.56777907e-03 1.50261626e-03 1.43095905e-03 1.36800483e-03\n",
      " 1.29659372e-03 1.20454221e-03 1.07073117e-03 1.05103802e-03\n",
      " 9.67641744e-04 7.26482344e-04 6.64639179e-04 4.00172832e-04\n",
      " 2.53203281e-04 2.47262406e-04 2.02616436e-04 1.77175133e-04\n",
      " 6.01952510e-05 2.72941653e-05 1.23048300e-05 3.27179934e-06\n",
      " 9.66849304e-07 7.17505317e-07 1.44316782e-11 6.55404205e-12\n",
      " 6.34041304e-12 5.33119855e-12 3.33761064e-12 3.14201039e-12\n",
      " 2.82380417e-12 2.19303989e-12 2.09616973e-12 2.02477529e-12\n",
      " 1.34046569e-12 1.29659656e-12 1.23618593e-12 7.84471766e-13\n",
      " 6.73715588e-13 4.39360977e-13 3.15012256e-13 2.92535937e-13]\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "[0.13206716 0.2095989  0.26100048 0.30613592 0.34229735 0.37459755\n",
      " 0.40235284 0.42840955 0.45357027 0.47804195 0.50139922 0.52465284\n",
      " 0.54638049 0.56719999 0.58667529 0.60452011 0.62205159 0.63854075\n",
      " 0.6531633  0.6677027  0.68119812 0.69406338 0.70670779 0.71745005\n",
      " 0.72802668 0.73823464 0.74787013 0.75738029 0.76621217 0.77466662\n",
      " 0.78295192 0.79103417 0.79892478 0.80635965 0.81340185 0.82026746\n",
      " 0.82705022 0.83359589 0.83986547 0.84606001 0.85183433 0.85749255\n",
      " 0.86299984 0.86828102 0.87298709 0.87758645 0.88209254 0.88641105\n",
      " 0.8906959  0.8948947  0.8989263  0.90282534 0.90669692 0.91054343\n",
      " 0.91417653 0.91776711 0.92127786 0.92467198 0.92780678 0.93079369\n",
      " 0.93374874 0.9366283  0.93945842 0.94219077 0.94487831 0.9475243\n",
      " 0.95013565 0.95269138 0.95521603 0.95761113 0.95993638 0.96224396\n",
      " 0.96449612 0.9667111  0.96888405 0.97102053 0.97304809 0.97501991\n",
      " 0.97692711 0.97881207 0.98066876 0.98242665 0.98413739 0.98576379\n",
      " 0.98733157 0.98883419 0.99026515 0.99163315 0.99292974 0.99413429\n",
      " 0.99520502 0.99625606 0.9972237  0.99795018 0.99861482 0.99901499\n",
      " 0.9992682  0.99951546 0.99971807 0.99989525 0.99995544 0.99998274\n",
      " 0.99999504 0.99999832 0.99999928 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(pca.components_)\n",
    "print('-'*80, '\\n');\n",
    "print(pca.explained_variance_ratio_)\n",
    "print('-'*80, '\\n');\n",
    "print(pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3c21f92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Making the screeplot - plotting the cumulative variance against the number of components\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7e699f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48999, 60)\n",
      "(21000, 60)\n"
     ]
    }
   ],
   "source": [
    "#pick the number of components explaining max variance\n",
    "pca_X= PCA(n_components=60)\n",
    "\n",
    "df_train_pca_X = pca_X.fit_transform(X_train_smote)\n",
    "print(df_train_pca_X.shape)\n",
    "df_test_pca_X = pca_X.transform(X_test)\n",
    "print(df_test_pca_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a54018",
   "metadata": {},
   "source": [
    "## Logistic Regression with PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e25b3d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run the model using the selected variables\n",
    "LR = LogisticRegression(class_weight='balanced')\n",
    "LR.fit(df_train_pca_X, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b045285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Accuracy Score: 0.7849139778362824\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87     44022\n",
      "           1       0.30      0.85      0.45      4977\n",
      "\n",
      "    accuracy                           0.78     48999\n",
      "   macro avg       0.64      0.82      0.66     48999\n",
      "weighted avg       0.91      0.78      0.82     48999\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Confusion Matrix:\n",
      "[[34213  9809]\n",
      " [  730  4247]]\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "roc_auc_score: 0.82\n"
     ]
    }
   ],
   "source": [
    "#Predicted probabilities\n",
    "y_pred_train = LR.predict(df_train_pca_X)\n",
    "\n",
    "#Printing results\n",
    "print(\"Train data results\")\n",
    "print('-'*80, '\\n');\n",
    "print(\"Accuracy Score:\",accuracy_score(y_train_smote,y_pred_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train_smote, y_pred_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train_smote,y_pred_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"roc_auc_score: {:2.2}\".format(metrics.roc_auc_score(y_train_smote, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e5429545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Accuracy Score: 0.7862380952380953\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87     18845\n",
      "           1       0.31      0.88      0.46      2155\n",
      "\n",
      "    accuracy                           0.79     21000\n",
      "   macro avg       0.65      0.83      0.66     21000\n",
      "weighted avg       0.91      0.79      0.82     21000\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Confusion Matrix:\n",
      "[[14625  4220]\n",
      " [  269  1886]]\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "roc_auc_score: 0.83\n"
     ]
    }
   ],
   "source": [
    "#Predicted probabilities\n",
    "y_pred_test = LR.predict(df_test_pca_X)\n",
    "\n",
    "#Printing results\n",
    "print(\"Test data results\");\n",
    "print('-'*80, '\\n');\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test,y_pred_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,y_pred_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"roc_auc_score: {:2.2}\".format(metrics.roc_auc_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9505f9",
   "metadata": {},
   "source": [
    "## Trying Random Forest without PCA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cdafc98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, n_jobs=-1,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, n_jobs=-1,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced_subsample', n_jobs=-1,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the random forest with default parameters.\n",
    "rfc = RandomForestClassifier( random_state=42,n_jobs=-1,\n",
    "                             class_weight='balanced_subsample',                             \n",
    "                            )\n",
    "\n",
    "#fit\n",
    "rfc.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "dfe900d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Accuracy Score: 0.9999795914202331\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     44022\n",
      "           1       1.00      1.00      1.00      4977\n",
      "\n",
      "    accuracy                           1.00     48999\n",
      "   macro avg       1.00      1.00      1.00     48999\n",
      "weighted avg       1.00      1.00      1.00     48999\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Confusion Matrix:\n",
      "[[44022     0]\n",
      " [    1  4976]]\n"
     ]
    }
   ],
   "source": [
    "predictions_train = rfc.predict(X_train_smote)\n",
    "print (\"Train data results\")\n",
    "print('-'*80, '\\n');\n",
    "print(\"Accuracy Score:\", accuracy_score(y_train_smote, predictions_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train_smote, predictions_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train_smote, predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cbeba904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Accuracy Score: 0.941047619047619\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97     18845\n",
      "           1       0.79      0.58      0.67      2155\n",
      "\n",
      "    accuracy                           0.94     21000\n",
      "   macro avg       0.87      0.78      0.82     21000\n",
      "weighted avg       0.94      0.94      0.94     21000\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Confusion Matrix:\n",
      "[[18521   324]\n",
      " [  914  1241]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Test data results\")\n",
    "print('-'*80, '\\n');\n",
    "predictions_test = rfc.predict(X_test)\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, predictions_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "id": "dff4262d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colName</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.109493</td>\n",
       "      <td>loc_ic_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068447</td>\n",
       "      <td>total_ic_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.066395</td>\n",
       "      <td>loc_ic_t2m_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054789</td>\n",
       "      <td>loc_ic_t2t_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051492</td>\n",
       "      <td>loc_og_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.048427</td>\n",
       "      <td>total_og_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.039900</td>\n",
       "      <td>offnet_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.039590</td>\n",
       "      <td>loc_og_t2m_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.038743</td>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.036352</td>\n",
       "      <td>roam_og_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.033812</td>\n",
       "      <td>loc_og_t2t_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.030159</td>\n",
       "      <td>total_rech_amt_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.022655</td>\n",
       "      <td>roam_ic_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.021271</td>\n",
       "      <td>arpu_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.020263</td>\n",
       "      <td>loc_ic_t2f_mou_8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     colName               value\n",
       "0   0.109493        loc_ic_mou_8\n",
       "1   0.068447      total_ic_mou_8\n",
       "2   0.066395    loc_ic_t2m_mou_8\n",
       "3   0.054789    loc_ic_t2t_mou_8\n",
       "4   0.051492        loc_og_mou_8\n",
       "5   0.048427      total_og_mou_8\n",
       "6   0.039900        offnet_mou_8\n",
       "7   0.039590    loc_og_t2m_mou_8\n",
       "8   0.038743  last_day_rch_amt_8\n",
       "9   0.036352       roam_og_mou_8\n",
       "10  0.033812    loc_og_t2t_mou_8\n",
       "11  0.030159    total_rech_amt_8\n",
       "12  0.022655       roam_ic_mou_8\n",
       "13  0.021271              arpu_8\n",
       "14  0.020263    loc_ic_t2f_mou_8"
      ]
     },
     "execution_count": 902,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = rfc.feature_importances_\n",
    "col_names =  X.columns\n",
    "\n",
    "RF_feature_importance = pd.DataFrame(sorted(zip(importances, list(col_names)), reverse=True),columns=['colName','value'])\n",
    "RF_feature_importance.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "76aadb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1475,
   "id": "236831f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': [5,10,15,20,25,30],\n",
    "    'min_samples_leaf': [2,5,10],\n",
    "    'min_samples_split': [10,20,30]\n",
    "}\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1,verbose=1,class_weight='balanced_subsample')\n",
    "grid_search = GridSearchCV(estimator=rf,\n",
    "                           param_grid=params,\n",
    "                           cv = 4,\n",
    "                           n_jobs=-1, verbose=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1476,
   "id": "8a77eaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 54 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-213 {color: black;background-color: white;}#sk-container-id-213 pre{padding: 0;}#sk-container-id-213 div.sk-toggleable {background-color: white;}#sk-container-id-213 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-213 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-213 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-213 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-213 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-213 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-213 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-213 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-213 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-213 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-213 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-213 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-213 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-213 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-213 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-213 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-213 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-213 div.sk-item {position: relative;z-index: 1;}#sk-container-id-213 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-213 div.sk-item::before, #sk-container-id-213 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-213 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-213 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-213 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-213 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-213 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-213 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-213 div.sk-label-container {text-align: center;}#sk-container-id-213 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-213 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-213\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;,\n",
       "                                              n_jobs=-1, random_state=42,\n",
       "                                              verbose=1),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [5, 10, 15, 20, 25, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [2, 5, 10],\n",
       "                         &#x27;min_samples_split&#x27;: [10, 20, 30]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-221\" type=\"checkbox\" ><label for=\"sk-estimator-id-221\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;,\n",
       "                                              n_jobs=-1, random_state=42,\n",
       "                                              verbose=1),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [5, 10, 15, 20, 25, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [2, 5, 10],\n",
       "                         &#x27;min_samples_split&#x27;: [10, 20, 30]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-222\" type=\"checkbox\" ><label for=\"sk-estimator-id-222\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, n_jobs=-1,\n",
       "                       random_state=42, verbose=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-223\" type=\"checkbox\" ><label for=\"sk-estimator-id-223\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, n_jobs=-1,\n",
       "                       random_state=42, verbose=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=RandomForestClassifier(class_weight='balanced_subsample',\n",
       "                                              n_jobs=-1, random_state=42,\n",
       "                                              verbose=1),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': [5, 10, 15, 20, 25, 30],\n",
       "                         'min_samples_leaf': [2, 5, 10],\n",
       "                         'min_samples_split': [10, 20, 30]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 1476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "grid_search.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1477,
   "id": "2fd3184a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-214 {color: black;background-color: white;}#sk-container-id-214 pre{padding: 0;}#sk-container-id-214 div.sk-toggleable {background-color: white;}#sk-container-id-214 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-214 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-214 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-214 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-214 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-214 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-214 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-214 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-214 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-214 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-214 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-214 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-214 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-214 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-214 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-214 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-214 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-214 div.sk-item {position: relative;z-index: 1;}#sk-container-id-214 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-214 div.sk-item::before, #sk-container-id-214 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-214 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-214 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-214 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-214 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-214 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-214 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-214 div.sk-label-container {text-align: center;}#sk-container-id-214 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-214 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-214\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, max_depth=25,\n",
       "                       min_samples_leaf=2, min_samples_split=10, n_jobs=-1,\n",
       "                       random_state=42, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-224\" type=\"checkbox\" checked><label for=\"sk-estimator-id-224\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, max_depth=25,\n",
       "                       min_samples_leaf=2, min_samples_split=10, n_jobs=-1,\n",
       "                       random_state=42, verbose=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced_subsample', max_depth=25,\n",
       "                       min_samples_leaf=2, min_samples_split=10, n_jobs=-1,\n",
       "                       random_state=42, verbose=1)"
      ]
     },
     "execution_count": 1477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "69d6ccc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, max_depth=25,\n",
       "                       min_samples_leaf=2, min_samples_split=10, n_jobs=-1,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, max_depth=25,\n",
       "                       min_samples_leaf=2, min_samples_split=10, n_jobs=-1,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced_subsample', max_depth=25,\n",
       "                       min_samples_leaf=2, min_samples_split=10, n_jobs=-1,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_best = RandomForestClassifier( random_state=42,n_jobs=-1,\n",
    "                             class_weight='balanced_subsample',\n",
    "                             max_depth=25,\n",
    "                             min_samples_leaf=2,\n",
    "                             min_samples_split=10,\n",
    "                            )\n",
    "rfc_best.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e8c81fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Accuracy Score: 0.9821833098634666\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     44022\n",
      "           1       0.86      0.99      0.92      4977\n",
      "\n",
      "    accuracy                           0.98     48999\n",
      "   macro avg       0.93      0.99      0.95     48999\n",
      "weighted avg       0.98      0.98      0.98     48999\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Confusion Matrix:\n",
      "[[43199   823]\n",
      " [   50  4927]]\n"
     ]
    }
   ],
   "source": [
    "predictions_train = rfc_best.predict(X_train_smote)\n",
    "print (\"Train data results\")\n",
    "print('-'*80, '\\n');\n",
    "print(\"Accuracy Score:\", accuracy_score(y_train_smote, predictions_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train_smote, predictions_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train_smote, predictions_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "db467eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Accuracy Score: 0.9412857142857143\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97     18845\n",
      "           1       0.74      0.65      0.70      2155\n",
      "\n",
      "    accuracy                           0.94     21000\n",
      "   macro avg       0.85      0.81      0.83     21000\n",
      "weighted avg       0.94      0.94      0.94     21000\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Confusion Matrix:\n",
      "[[43199   823]\n",
      " [   50  4927]]\n",
      "roc_auc_score: 0.81\n"
     ]
    }
   ],
   "source": [
    "print (\"Test data results\")\n",
    "print('-'*80, '\\n');\n",
    "predictions_test = rfc_best.predict(X_test)\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, predictions_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train_smote, predictions_train))\n",
    "print(\"roc_auc_score: {:2.2}\".format(metrics.roc_auc_score(y_test, predictions_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f80b8691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colName</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.078141</td>\n",
       "      <td>loc_ic_t2m_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.073607</td>\n",
       "      <td>loc_ic_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060785</td>\n",
       "      <td>total_ic_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045371</td>\n",
       "      <td>loc_og_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041016</td>\n",
       "      <td>offnet_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.039500</td>\n",
       "      <td>loc_ic_t2t_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.038456</td>\n",
       "      <td>total_og_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.033456</td>\n",
       "      <td>loc_og_t2m_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.029052</td>\n",
       "      <td>roam_og_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.026197</td>\n",
       "      <td>loc_og_t2t_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.024652</td>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.021595</td>\n",
       "      <td>total_rech_amt_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.021172</td>\n",
       "      <td>roam_ic_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.020274</td>\n",
       "      <td>loc_ic_t2f_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.017428</td>\n",
       "      <td>arpu_8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     colName               value\n",
       "0   0.078141    loc_ic_t2m_mou_8\n",
       "1   0.073607        loc_ic_mou_8\n",
       "2   0.060785      total_ic_mou_8\n",
       "3   0.045371        loc_og_mou_8\n",
       "4   0.041016        offnet_mou_8\n",
       "5   0.039500    loc_ic_t2t_mou_8\n",
       "6   0.038456      total_og_mou_8\n",
       "7   0.033456    loc_og_t2m_mou_8\n",
       "8   0.029052       roam_og_mou_8\n",
       "9   0.026197    loc_og_t2t_mou_8\n",
       "10  0.024652  last_day_rch_amt_8\n",
       "11  0.021595    total_rech_amt_8\n",
       "12  0.021172       roam_ic_mou_8\n",
       "13  0.020274    loc_ic_t2f_mou_8\n",
       "14  0.017428              arpu_8"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = rfc_best.feature_importances_\n",
    "col_names =  X.columns\n",
    "\n",
    "RF_feature_importance = pd.DataFrame(sorted(zip(importances, list(col_names)), reverse=True),columns=['colName','value'])\n",
    "RF_feature_importance.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36720e77",
   "metadata": {},
   "source": [
    "## Trying with XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d8e7e530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Running the random forest with default parameters.\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "#fit\n",
    "xgb.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "330e21ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "accuracy score: 0.9764076817894243\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     44022\n",
      "           1       0.91      0.85      0.88      4977\n",
      "\n",
      "    accuracy                           0.98     48999\n",
      "   macro avg       0.95      0.92      0.93     48999\n",
      "weighted avg       0.98      0.98      0.98     48999\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "confusion matrix:\n",
      "[[43596   426]\n",
      " [  730  4247]]\n"
     ]
    }
   ],
   "source": [
    "predictions_train = xgb.predict(X_train_smote)\n",
    "print (\"Train data results\")\n",
    "print('-'*80, '\\n');\n",
    "print(\"accuracy score:\", accuracy_score(y_train_smote, predictions_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"classification report:\")\n",
    "print(classification_report(y_train_smote, predictions_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_train_smote, predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3112b3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "accuracy score: 0.9407619047619048\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     18845\n",
      "           1       0.75      0.63      0.69      2155\n",
      "\n",
      "    accuracy                           0.94     21000\n",
      "   macro avg       0.85      0.80      0.83     21000\n",
      "weighted avg       0.94      0.94      0.94     21000\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "confusion matrix:\n",
      "[[18394   451]\n",
      " [  793  1362]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Test data results\")\n",
    "print('-'*80, '\\n');\n",
    "predictions_test = xgb.predict(X_test)\n",
    "print(\"accuracy score:\", accuracy_score(y_test, predictions_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"classification report:\")\n",
    "print(classification_report(y_test, predictions_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e1d5de6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=42, reg_alpha=None,\n",
       "                                     reg_lambda=None, ...),\n",
       "             n_jobs=-1, param_grid={&#x27;max_depth&#x27;: [2, 3, 4, 5, 6, 7]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=42, reg_alpha=None,\n",
       "                                     reg_lambda=None, ...),\n",
       "             n_jobs=-1, param_grid={&#x27;max_depth&#x27;: [2, 3, 4, 5, 6, 7]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=42,\n",
       "              reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=42,\n",
       "              reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=42, reg_alpha=None,\n",
       "                                     reg_lambda=None, ...),\n",
       "             n_jobs=-1, param_grid={'max_depth': [2, 3, 4, 5, 6, 7]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': [2,3,4,5,6,7]\n",
    "    \n",
    "}\n",
    "\n",
    "xgbc =  XGBClassifier(random_state=42)\n",
    "grid_search_xgb = GridSearchCV(estimator=xgbc,\n",
    "                           param_grid=params,\n",
    "                           cv = 4,\n",
    "                           n_jobs=-1, verbose=3, scoring=\"accuracy\")\n",
    "grid_search_xgb.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "742530d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ac1efbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;background-color: white;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Running the random forest with default parameters.\n",
    "xgb_best = XGBClassifier(random_state=42,max_depth= 3)\n",
    "\n",
    "#fit\n",
    "xgb_best.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "24d1e49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "accuracy score: 0.9481417988122206\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     44022\n",
      "           1       0.79      0.67      0.72      4977\n",
      "\n",
      "    accuracy                           0.95     48999\n",
      "   macro avg       0.88      0.82      0.85     48999\n",
      "weighted avg       0.95      0.95      0.95     48999\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "confusion matrix:\n",
      "[[43128   894]\n",
      " [ 1647  3330]]\n"
     ]
    }
   ],
   "source": [
    "predictions_train = xgb_best.predict(X_train_smote)\n",
    "print (\"Train data results\")\n",
    "print('-'*80, '\\n');\n",
    "print(\"accuracy score:\", accuracy_score(y_train_smote, predictions_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"classification report:\")\n",
    "print(classification_report(y_train_smote, predictions_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_train_smote, predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9b7aaa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "accuracy score: 0.942047619047619\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     18845\n",
      "           1       0.75      0.65      0.70      2155\n",
      "\n",
      "    accuracy                           0.94     21000\n",
      "   macro avg       0.86      0.81      0.83     21000\n",
      "weighted avg       0.94      0.94      0.94     21000\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "confusion matrix:\n",
      "[[18390   455]\n",
      " [  762  1393]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Test data results\")\n",
    "print('-'*80, '\\n');\n",
    "predictions_test = xgb_best.predict(X_test)\n",
    "print(\"accuracy score:\", accuracy_score(y_test, predictions_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"classification report:\")\n",
    "print(classification_report(y_test, predictions_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5ca54160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colName</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.369198</td>\n",
       "      <td>total_ic_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.136596</td>\n",
       "      <td>loc_ic_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020714</td>\n",
       "      <td>roam_og_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018916</td>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018403</td>\n",
       "      <td>arpu_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.018390</td>\n",
       "      <td>vol_3g_mb_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.015534</td>\n",
       "      <td>total_rech_amt_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.013479</td>\n",
       "      <td>vol_2g_mb_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.013425</td>\n",
       "      <td>loc_og_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.012953</td>\n",
       "      <td>loc_ic_mou_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.012659</td>\n",
       "      <td>spl_ic_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010702</td>\n",
       "      <td>loc_ic_t2f_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.010633</td>\n",
       "      <td>std_og_mou_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010366</td>\n",
       "      <td>onnet_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.009903</td>\n",
       "      <td>loc_og_t2f_mou_8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     colName               value\n",
       "0   0.369198      total_ic_mou_8\n",
       "1   0.136596        loc_ic_mou_8\n",
       "2   0.020714       roam_og_mou_8\n",
       "3   0.018916  last_day_rch_amt_8\n",
       "4   0.018403              arpu_8\n",
       "5   0.018390         vol_3g_mb_8\n",
       "6   0.015534    total_rech_amt_8\n",
       "7   0.013479         vol_2g_mb_8\n",
       "8   0.013425        loc_og_mou_8\n",
       "9   0.012953        loc_ic_mou_7\n",
       "10  0.012659        spl_ic_mou_8\n",
       "11  0.010702    loc_ic_t2f_mou_8\n",
       "12  0.010633        std_og_mou_7\n",
       "13  0.010366         onnet_mou_8\n",
       "14  0.009903    loc_og_t2f_mou_8"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = xgb_best.feature_importances_\n",
    "col_names =  X.columns\n",
    "\n",
    "RF_feature_importance = pd.DataFrame(sorted(zip(importances, list(col_names)), reverse=True),columns=['colName','value'])\n",
    "RF_feature_importance.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43a9188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7d19a55",
   "metadata": {},
   "source": [
    "### Evaluating Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6d279656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000, 124)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3f36e125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Shape:  (30000, 171)\n",
      "-------------------------------------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>date_of_last_rech_data_6</th>\n",
       "      <th>date_of_last_rech_data_7</th>\n",
       "      <th>date_of_last_rech_data_8</th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <th>count_rech_3g_8</th>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <th>av_rech_amt_data_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <th>arpu_3g_7</th>\n",
       "      <th>arpu_3g_8</th>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <th>night_pck_user_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69999</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>91.882</td>\n",
       "      <td>65.330</td>\n",
       "      <td>64.445</td>\n",
       "      <td>31.78</td>\n",
       "      <td>20.23</td>\n",
       "      <td>23.11</td>\n",
       "      <td>60.16</td>\n",
       "      <td>32.16</td>\n",
       "      <td>34.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.88</td>\n",
       "      <td>20.23</td>\n",
       "      <td>21.06</td>\n",
       "      <td>18.13</td>\n",
       "      <td>10.89</td>\n",
       "      <td>8.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>43.01</td>\n",
       "      <td>44.71</td>\n",
       "      <td>29.43</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.05</td>\n",
       "      <td>42.03</td>\n",
       "      <td>7.68</td>\n",
       "      <td>26.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.93</td>\n",
       "      <td>7.68</td>\n",
       "      <td>28.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.94</td>\n",
       "      <td>52.39</td>\n",
       "      <td>57.94</td>\n",
       "      <td>30.33</td>\n",
       "      <td>37.56</td>\n",
       "      <td>21.98</td>\n",
       "      <td>10.21</td>\n",
       "      <td>4.59</td>\n",
       "      <td>9.53</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.81</td>\n",
       "      <td>42.16</td>\n",
       "      <td>31.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.04</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.04</td>\n",
       "      <td>4.34</td>\n",
       "      <td>41.73</td>\n",
       "      <td>43.56</td>\n",
       "      <td>36.26</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>6/21/2014</td>\n",
       "      <td>7/26/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1692</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70000</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>414.168</td>\n",
       "      <td>515.568</td>\n",
       "      <td>360.868</td>\n",
       "      <td>75.51</td>\n",
       "      <td>41.21</td>\n",
       "      <td>19.84</td>\n",
       "      <td>474.34</td>\n",
       "      <td>621.84</td>\n",
       "      <td>394.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75.51</td>\n",
       "      <td>41.21</td>\n",
       "      <td>19.84</td>\n",
       "      <td>473.61</td>\n",
       "      <td>598.08</td>\n",
       "      <td>377.26</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>549.86</td>\n",
       "      <td>639.29</td>\n",
       "      <td>397.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.76</td>\n",
       "      <td>17.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.76</td>\n",
       "      <td>17.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>549.86</td>\n",
       "      <td>663.06</td>\n",
       "      <td>415.59</td>\n",
       "      <td>19.99</td>\n",
       "      <td>26.95</td>\n",
       "      <td>2.61</td>\n",
       "      <td>160.19</td>\n",
       "      <td>122.29</td>\n",
       "      <td>184.81</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>181.69</td>\n",
       "      <td>149.24</td>\n",
       "      <td>187.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>296.33</td>\n",
       "      <td>339.64</td>\n",
       "      <td>281.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>114.63</td>\n",
       "      <td>177.88</td>\n",
       "      <td>94.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>6/19/2014</td>\n",
       "      <td>7/16/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2533</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70001</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>329.844</td>\n",
       "      <td>434.884</td>\n",
       "      <td>746.239</td>\n",
       "      <td>7.54</td>\n",
       "      <td>7.86</td>\n",
       "      <td>8.40</td>\n",
       "      <td>16.98</td>\n",
       "      <td>45.81</td>\n",
       "      <td>45.04</td>\n",
       "      <td>22.81</td>\n",
       "      <td>103.38</td>\n",
       "      <td>26.08</td>\n",
       "      <td>24.53</td>\n",
       "      <td>53.68</td>\n",
       "      <td>54.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>6/29/2014</td>\n",
       "      <td>7/27/2014</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277</td>\n",
       "      <td>525.61</td>\n",
       "      <td>758.41</td>\n",
       "      <td>241.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70002</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>43.550</td>\n",
       "      <td>171.390</td>\n",
       "      <td>24.400</td>\n",
       "      <td>5.31</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.04</td>\n",
       "      <td>205.01</td>\n",
       "      <td>24.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.94</td>\n",
       "      <td>98.61</td>\n",
       "      <td>20.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.26</td>\n",
       "      <td>98.61</td>\n",
       "      <td>22.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.09</td>\n",
       "      <td>94.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.09</td>\n",
       "      <td>96.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.03</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.36</td>\n",
       "      <td>207.18</td>\n",
       "      <td>24.01</td>\n",
       "      <td>58.11</td>\n",
       "      <td>54.64</td>\n",
       "      <td>23.04</td>\n",
       "      <td>487.94</td>\n",
       "      <td>449.83</td>\n",
       "      <td>506.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.64</td>\n",
       "      <td>546.06</td>\n",
       "      <td>504.86</td>\n",
       "      <td>531.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.63</td>\n",
       "      <td>11.88</td>\n",
       "      <td>8.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.63</td>\n",
       "      <td>16.14</td>\n",
       "      <td>8.83</td>\n",
       "      <td>555.69</td>\n",
       "      <td>522.44</td>\n",
       "      <td>549.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.43</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/30/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70003</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>306.854</td>\n",
       "      <td>406.289</td>\n",
       "      <td>413.329</td>\n",
       "      <td>450.93</td>\n",
       "      <td>609.03</td>\n",
       "      <td>700.68</td>\n",
       "      <td>60.94</td>\n",
       "      <td>23.84</td>\n",
       "      <td>74.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.78</td>\n",
       "      <td>14.56</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.66</td>\n",
       "      <td>10.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.84</td>\n",
       "      <td>3.44</td>\n",
       "      <td>25.51</td>\n",
       "      <td>450.48</td>\n",
       "      <td>608.24</td>\n",
       "      <td>686.11</td>\n",
       "      <td>58.54</td>\n",
       "      <td>21.18</td>\n",
       "      <td>63.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>509.03</td>\n",
       "      <td>629.43</td>\n",
       "      <td>749.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>5.39</td>\n",
       "      <td>4.96</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>514.79</td>\n",
       "      <td>638.28</td>\n",
       "      <td>779.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>9.91</td>\n",
       "      <td>10.13</td>\n",
       "      <td>9.23</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.13</td>\n",
       "      <td>9.59</td>\n",
       "      <td>17.61</td>\n",
       "      <td>29.71</td>\n",
       "      <td>92.36</td>\n",
       "      <td>107.39</td>\n",
       "      <td>13.88</td>\n",
       "      <td>13.96</td>\n",
       "      <td>32.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.59</td>\n",
       "      <td>106.33</td>\n",
       "      <td>141.48</td>\n",
       "      <td>53.73</td>\n",
       "      <td>115.93</td>\n",
       "      <td>159.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>356</td>\n",
       "      <td>490</td>\n",
       "      <td>546</td>\n",
       "      <td>90</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>6/29/2014</td>\n",
       "      <td>7/29/2014</td>\n",
       "      <td>8/30/2014</td>\n",
       "      <td>50</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>462</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0  69999        109             0.0             0.0             0.0   \n",
       "1  70000        109             0.0             0.0             0.0   \n",
       "2  70001        109             0.0             0.0             0.0   \n",
       "3  70002        109             0.0             0.0             0.0   \n",
       "4  70003        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8   arpu_6  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   91.882   \n",
       "1            6/30/2014            7/31/2014            8/31/2014  414.168   \n",
       "2            6/30/2014            7/31/2014            8/31/2014  329.844   \n",
       "3            6/30/2014            7/31/2014            8/31/2014   43.550   \n",
       "4            6/30/2014            7/31/2014            8/31/2014  306.854   \n",
       "\n",
       "    arpu_7   arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  offnet_mou_6  \\\n",
       "0   65.330   64.445        31.78        20.23        23.11         60.16   \n",
       "1  515.568  360.868        75.51        41.21        19.84        474.34   \n",
       "2  434.884  746.239         7.54         7.86         8.40         16.98   \n",
       "3  171.390   24.400         5.31         2.16         0.00         40.04   \n",
       "4  406.289  413.329       450.93       609.03       700.68         60.94   \n",
       "\n",
       "   offnet_mou_7  offnet_mou_8  roam_ic_mou_6  roam_ic_mou_7  roam_ic_mou_8  \\\n",
       "0         32.16         34.83           0.00           0.00           0.00   \n",
       "1        621.84        394.94           0.00           0.00           0.00   \n",
       "2         45.81         45.04          22.81         103.38          26.08   \n",
       "3        205.01         24.01           0.00           0.00           0.00   \n",
       "4         23.84         74.16           0.00           0.00           0.00   \n",
       "\n",
       "   roam_og_mou_6  roam_og_mou_7  roam_og_mou_8  loc_og_t2t_mou_6  \\\n",
       "0           0.00           0.00           0.00             24.88   \n",
       "1           0.00           0.00           0.00             75.51   \n",
       "2          24.53          53.68          54.44              0.00   \n",
       "3           0.00           0.00           0.00              5.31   \n",
       "4           0.00           0.00           0.00              0.45   \n",
       "\n",
       "   loc_og_t2t_mou_7  loc_og_t2t_mou_8  loc_og_t2m_mou_6  loc_og_t2m_mou_7  \\\n",
       "0             20.23             21.06             18.13             10.89   \n",
       "1             41.21             19.84            473.61            598.08   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3              0.00              0.00              2.94             98.61   \n",
       "4              0.78             14.56              2.39              2.66   \n",
       "\n",
       "   loc_og_t2m_mou_8  loc_og_t2f_mou_6  loc_og_t2f_mou_7  loc_og_t2f_mou_8  \\\n",
       "0              8.36              0.00             13.58              0.00   \n",
       "1            377.26              0.73              0.00              0.00   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3             20.51              0.00              0.00              2.35   \n",
       "4             10.94              0.00              0.00              0.00   \n",
       "\n",
       "   loc_og_t2c_mou_6  loc_og_t2c_mou_7  loc_og_t2c_mou_8  loc_og_mou_6  \\\n",
       "0               0.0              0.00              0.03         43.01   \n",
       "1               0.0              0.00              0.00        549.86   \n",
       "2               0.0              0.00              0.00          0.00   \n",
       "3               0.0              6.18              0.00          8.26   \n",
       "4               0.0              0.00              0.00          2.84   \n",
       "\n",
       "   loc_og_mou_7  loc_og_mou_8  std_og_t2t_mou_6  std_og_t2t_mou_7  \\\n",
       "0         44.71         29.43              6.90              0.00   \n",
       "1        639.29        397.11              0.00              0.00   \n",
       "2          0.00          0.00              0.00              0.00   \n",
       "3         98.61         22.86              0.00              2.16   \n",
       "4          3.44         25.51            450.48            608.24   \n",
       "\n",
       "   std_og_t2t_mou_8  std_og_t2m_mou_6  std_og_t2m_mou_7  std_og_t2m_mou_8  \\\n",
       "0              2.05             42.03              7.68             26.43   \n",
       "1              0.00              0.00             23.76             17.68   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3              0.00             37.09             94.36              0.00   \n",
       "4            686.11             58.54             21.18             63.18   \n",
       "\n",
       "   std_og_t2f_mou_6  std_og_t2f_mou_7  std_og_t2f_mou_8  std_og_t2c_mou_6  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   std_og_t2c_mou_7  std_og_t2c_mou_8  std_og_mou_6  std_og_mou_7  \\\n",
       "0               0.0               0.0         48.93          7.68   \n",
       "1               0.0               0.0          0.00         23.76   \n",
       "2               0.0               0.0          0.00          0.00   \n",
       "3               0.0               0.0         37.09         96.53   \n",
       "4               0.0               0.0        509.03        629.43   \n",
       "\n",
       "   std_og_mou_8  isd_og_mou_6  isd_og_mou_7  isd_og_mou_8  spl_og_mou_6  \\\n",
       "0         28.48           0.0           0.0           0.0          0.00   \n",
       "1         17.68           0.0           0.0           0.8          0.00   \n",
       "2          0.00           0.0           0.0           0.0          0.00   \n",
       "3          0.00           0.0           0.0           0.0          0.00   \n",
       "4        749.29           0.0           0.0           0.0          0.71   \n",
       "\n",
       "   spl_og_mou_7  spl_og_mou_8  og_others_6  og_others_7  og_others_8  \\\n",
       "0          0.00          0.03          0.0          0.0          0.0   \n",
       "1          0.00          0.00          0.0          0.0          0.0   \n",
       "2          0.00          0.00          0.0          0.0          0.0   \n",
       "3         12.03          1.15          0.0          0.0          0.0   \n",
       "4          5.39          4.96          2.2          0.0          0.0   \n",
       "\n",
       "   total_og_mou_6  total_og_mou_7  total_og_mou_8  loc_ic_t2t_mou_6  \\\n",
       "0           91.94           52.39           57.94             30.33   \n",
       "1          549.86          663.06          415.59             19.99   \n",
       "2            0.00            0.00            0.00              0.00   \n",
       "3           45.36          207.18           24.01             58.11   \n",
       "4          514.79          638.28          779.78              0.00   \n",
       "\n",
       "   loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  \\\n",
       "0             37.56             21.98             10.21              4.59   \n",
       "1             26.95              2.61            160.19            122.29   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3             54.64             23.04            487.94            449.83   \n",
       "4              0.36              9.91             10.13              9.23   \n",
       "\n",
       "   loc_ic_t2m_mou_8  loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  \\\n",
       "0              9.53              0.26              0.00              0.00   \n",
       "1            184.81              1.49              0.00              0.00   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3            506.94              0.00              0.38              1.64   \n",
       "4              7.69              0.00              0.00              0.00   \n",
       "\n",
       "   loc_ic_mou_6  loc_ic_mou_7  loc_ic_mou_8  std_ic_t2t_mou_6  \\\n",
       "0         40.81         42.16         31.51              0.00   \n",
       "1        181.69        149.24        187.43              0.00   \n",
       "2          0.00          0.00          0.00              0.00   \n",
       "3        546.06        504.86        531.64              0.00   \n",
       "4         10.13          9.59         17.61             29.71   \n",
       "\n",
       "   std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2m_mou_6  std_ic_t2m_mou_7  \\\n",
       "0              0.00              0.00              0.36              1.04   \n",
       "1              0.00              0.00              0.00             12.51   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3              4.26              0.00              9.63             11.88   \n",
       "4             92.36            107.39             13.88             13.96   \n",
       "\n",
       "   std_ic_t2m_mou_8  std_ic_t2f_mou_6  std_ic_t2f_mou_7  std_ic_t2f_mou_8  \\\n",
       "0              4.34               0.0               0.0              0.00   \n",
       "1              0.00               0.0               0.0              0.00   \n",
       "2              0.00               0.0               0.0              0.00   \n",
       "3              8.83               0.0               0.0              0.00   \n",
       "4             32.46               0.0               0.0              1.61   \n",
       "\n",
       "   std_ic_t2o_mou_6  std_ic_t2o_mou_7  std_ic_t2o_mou_8  std_ic_mou_6  \\\n",
       "0               0.0               0.0               0.0          0.36   \n",
       "1               0.0               0.0               0.0          0.00   \n",
       "2               0.0               0.0               0.0          0.00   \n",
       "3               0.0               0.0               0.0          9.63   \n",
       "4               0.0               0.0               0.0         43.59   \n",
       "\n",
       "   std_ic_mou_7  std_ic_mou_8  total_ic_mou_6  total_ic_mou_7  total_ic_mou_8  \\\n",
       "0          1.04          4.34           41.73           43.56           36.26   \n",
       "1         12.51          0.00          296.33          339.64          281.66   \n",
       "2          0.00          0.00            0.00            0.00            0.00   \n",
       "3         16.14          8.83          555.69          522.44          549.13   \n",
       "4        106.33        141.48           53.73          115.93          159.26   \n",
       "\n",
       "   spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  isd_ic_mou_6  isd_ic_mou_7  \\\n",
       "0          0.54          0.34          0.39          0.00          0.00   \n",
       "1          0.00          0.00          0.00        114.63        177.88   \n",
       "2          0.00          0.00          0.00          0.00          0.00   \n",
       "3          0.00          0.00          0.00          0.00          1.43   \n",
       "4          0.00          0.00          0.00          0.00          0.00   \n",
       "\n",
       "   isd_ic_mou_8  ic_others_6  ic_others_7  ic_others_8  total_rech_num_6  \\\n",
       "0          0.00          0.0          0.0         0.00                 5   \n",
       "1         94.23          0.0          0.0         0.00                 5   \n",
       "2          0.00          0.0          0.0         0.00                 6   \n",
       "3          8.65          0.0          0.0         0.00                 3   \n",
       "4          0.00          0.0          0.0         0.16                11   \n",
       "\n",
       "   total_rech_num_7  total_rech_num_8  total_rech_amt_6  total_rech_amt_7  \\\n",
       "0                 5                 4               103                90   \n",
       "1                 4                 5               500               500   \n",
       "2                 9                 5               500              1000   \n",
       "3                 5                 2               110               260   \n",
       "4                 7                 8               356               490   \n",
       "\n",
       "   total_rech_amt_8  max_rech_amt_6  max_rech_amt_7  max_rech_amt_8  \\\n",
       "0                60              50              30              30   \n",
       "1               500             250             250             250   \n",
       "2              1000             300             500             500   \n",
       "3                 0             110             150               0   \n",
       "4               546              90             130             130   \n",
       "\n",
       "  date_of_last_rech_6 date_of_last_rech_7 date_of_last_rech_8  \\\n",
       "0           6/21/2014           7/26/2014           8/24/2014   \n",
       "1           6/19/2014           7/16/2014           8/24/2014   \n",
       "2           6/29/2014           7/27/2014           8/28/2014   \n",
       "3           6/25/2014           7/30/2014           8/24/2014   \n",
       "4           6/29/2014           7/29/2014           8/30/2014   \n",
       "\n",
       "   last_day_rch_amt_6  last_day_rch_amt_7  last_day_rch_amt_8  \\\n",
       "0                  30                  30                   0   \n",
       "1                 250                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                 110                 150                   0   \n",
       "4                  50                 130                 130   \n",
       "\n",
       "  date_of_last_rech_data_6 date_of_last_rech_data_7 date_of_last_rech_data_8  \\\n",
       "0                      NaN                      NaN                      NaN   \n",
       "1                      NaN                      NaN                      NaN   \n",
       "2                      NaN                      NaN                      NaN   \n",
       "3                      NaN                      NaN                      NaN   \n",
       "4                      NaN                      NaN                      NaN   \n",
       "\n",
       "   total_rech_data_6  total_rech_data_7  total_rech_data_8  max_rech_data_6  \\\n",
       "0                NaN                NaN                NaN              NaN   \n",
       "1                NaN                NaN                NaN              NaN   \n",
       "2                NaN                NaN                NaN              NaN   \n",
       "3                NaN                NaN                NaN              NaN   \n",
       "4                NaN                NaN                NaN              NaN   \n",
       "\n",
       "   max_rech_data_7  max_rech_data_8  count_rech_2g_6  count_rech_2g_7  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   count_rech_2g_8  count_rech_3g_6  count_rech_3g_7  count_rech_3g_8  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   av_rech_amt_data_6  av_rech_amt_data_7  av_rech_amt_data_8  vol_2g_mb_6  \\\n",
       "0                 NaN                 NaN                 NaN          0.0   \n",
       "1                 NaN                 NaN                 NaN          0.0   \n",
       "2                 NaN                 NaN                 NaN          0.0   \n",
       "3                 NaN                 NaN                 NaN          0.0   \n",
       "4                 NaN                 NaN                 NaN          0.0   \n",
       "\n",
       "   vol_2g_mb_7  vol_2g_mb_8  vol_3g_mb_6  vol_3g_mb_7  vol_3g_mb_8  arpu_3g_6  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0        NaN   \n",
       "1          0.0          0.0          0.0          0.0          0.0        NaN   \n",
       "2          0.0          0.0          0.0          0.0          0.0        NaN   \n",
       "3          0.0          0.0          0.0          0.0          0.0        NaN   \n",
       "4          0.0          0.0          0.0          0.0          0.0        NaN   \n",
       "\n",
       "   arpu_3g_7  arpu_3g_8  arpu_2g_6  arpu_2g_7  arpu_2g_8  night_pck_user_6  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "1        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "2        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "3        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "4        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "\n",
       "   night_pck_user_7  night_pck_user_8  monthly_2g_6  monthly_2g_7  \\\n",
       "0               NaN               NaN             0             0   \n",
       "1               NaN               NaN             0             0   \n",
       "2               NaN               NaN             0             0   \n",
       "3               NaN               NaN             0             0   \n",
       "4               NaN               NaN             0             0   \n",
       "\n",
       "   monthly_2g_8  sachet_2g_6  sachet_2g_7  sachet_2g_8  monthly_3g_6  \\\n",
       "0             0            0            0            0             0   \n",
       "1             0            0            0            0             0   \n",
       "2             0            0            0            0             0   \n",
       "3             0            0            0            0             0   \n",
       "4             0            0            0            0             0   \n",
       "\n",
       "   monthly_3g_7  monthly_3g_8  sachet_3g_6  sachet_3g_7  sachet_3g_8  \\\n",
       "0             0             0            0            0            0   \n",
       "1             0             0            0            0            0   \n",
       "2             0             0            0            0            0   \n",
       "3             0             0            0            0            0   \n",
       "4             0             0            0            0            0   \n",
       "\n",
       "   fb_user_6  fb_user_7  fb_user_8   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \n",
       "0        NaN        NaN        NaN  1692        0.00        0.00        0.00  \n",
       "1        NaN        NaN        NaN  2533        0.00        0.00        0.00  \n",
       "2        NaN        NaN        NaN   277      525.61      758.41      241.84  \n",
       "3        NaN        NaN        NaN  1244        0.00        0.00        0.00  \n",
       "4        NaN        NaN        NaN   462        0.00        0.00        0.00  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print('Dataframe Shape: ', test_data.shape); print('-'*80, '\\n');\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "67cec423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 158)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_no_varience_columns = list(data_unique_count_is_one.index)\n",
    "test_data.drop(drop_no_varience_columns, axis=1, inplace=True)\n",
    "\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "17fc4228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 128)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_data.drop(high_missing_cols.index, axis=1, inplace=True)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4129be40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 125)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.drop(date_vars, axis=1, inplace=True)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2a885d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "id=test_data.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2475b7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 124)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.drop(\"id\", axis=1, inplace=True)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "07c09d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Missing%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>loc_ic_t2f_mou_8</td>\n",
       "      <td>5.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>og_others_8</td>\n",
       "      <td>5.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>std_og_t2m_mou_8</td>\n",
       "      <td>5.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>std_og_t2t_mou_8</td>\n",
       "      <td>5.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>std_og_mou_8</td>\n",
       "      <td>5.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>loc_og_mou_8</td>\n",
       "      <td>5.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>isd_og_mou_8</td>\n",
       "      <td>5.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>std_ic_mou_8</td>\n",
       "      <td>5.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>loc_og_t2c_mou_8</td>\n",
       "      <td>5.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>std_ic_t2m_mou_8</td>\n",
       "      <td>5.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  Missing%\n",
       "62  loc_ic_t2f_mou_8  5.583333\n",
       "50       og_others_8  5.583333\n",
       "35  std_og_t2m_mou_8  5.583333\n",
       "32  std_og_t2t_mou_8  5.583333\n",
       "41      std_og_mou_8  5.583333\n",
       "29      loc_og_mou_8  5.583333\n",
       "44      isd_og_mou_8  5.583333\n",
       "77      std_ic_mou_8  5.583333\n",
       "26  loc_og_t2c_mou_8  5.583333\n",
       "71  std_ic_t2m_mou_8  5.583333"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = pd.DataFrame((test_data.isnull().sum()/len(test_data))*100).reset_index().rename(columns = {'index': 'feature', 0: 'Missing%'}).sort_values('Missing%',ascending = False)\n",
    "missing_values.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9e3bd349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 124)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3026540c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.882</td>\n",
       "      <td>65.330</td>\n",
       "      <td>64.445</td>\n",
       "      <td>31.78</td>\n",
       "      <td>20.23</td>\n",
       "      <td>23.11</td>\n",
       "      <td>60.16</td>\n",
       "      <td>32.16</td>\n",
       "      <td>34.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.88</td>\n",
       "      <td>20.23</td>\n",
       "      <td>21.06</td>\n",
       "      <td>18.13</td>\n",
       "      <td>10.89</td>\n",
       "      <td>8.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>43.01</td>\n",
       "      <td>44.71</td>\n",
       "      <td>29.43</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.05</td>\n",
       "      <td>42.03</td>\n",
       "      <td>7.68</td>\n",
       "      <td>26.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.93</td>\n",
       "      <td>7.68</td>\n",
       "      <td>28.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.94</td>\n",
       "      <td>52.39</td>\n",
       "      <td>57.94</td>\n",
       "      <td>30.33</td>\n",
       "      <td>37.56</td>\n",
       "      <td>21.98</td>\n",
       "      <td>10.21</td>\n",
       "      <td>4.59</td>\n",
       "      <td>9.53</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.81</td>\n",
       "      <td>42.16</td>\n",
       "      <td>31.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.04</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.04</td>\n",
       "      <td>4.34</td>\n",
       "      <td>41.73</td>\n",
       "      <td>43.56</td>\n",
       "      <td>36.26</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1692</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>414.168</td>\n",
       "      <td>515.568</td>\n",
       "      <td>360.868</td>\n",
       "      <td>75.51</td>\n",
       "      <td>41.21</td>\n",
       "      <td>19.84</td>\n",
       "      <td>474.34</td>\n",
       "      <td>621.84</td>\n",
       "      <td>394.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75.51</td>\n",
       "      <td>41.21</td>\n",
       "      <td>19.84</td>\n",
       "      <td>473.61</td>\n",
       "      <td>598.08</td>\n",
       "      <td>377.26</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>549.86</td>\n",
       "      <td>639.29</td>\n",
       "      <td>397.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.76</td>\n",
       "      <td>17.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.76</td>\n",
       "      <td>17.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>549.86</td>\n",
       "      <td>663.06</td>\n",
       "      <td>415.59</td>\n",
       "      <td>19.99</td>\n",
       "      <td>26.95</td>\n",
       "      <td>2.61</td>\n",
       "      <td>160.19</td>\n",
       "      <td>122.29</td>\n",
       "      <td>184.81</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>181.69</td>\n",
       "      <td>149.24</td>\n",
       "      <td>187.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>296.33</td>\n",
       "      <td>339.64</td>\n",
       "      <td>281.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>114.63</td>\n",
       "      <td>177.88</td>\n",
       "      <td>94.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2533</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>329.844</td>\n",
       "      <td>434.884</td>\n",
       "      <td>746.239</td>\n",
       "      <td>7.54</td>\n",
       "      <td>7.86</td>\n",
       "      <td>8.40</td>\n",
       "      <td>16.98</td>\n",
       "      <td>45.81</td>\n",
       "      <td>45.04</td>\n",
       "      <td>22.81</td>\n",
       "      <td>103.38</td>\n",
       "      <td>26.08</td>\n",
       "      <td>24.53</td>\n",
       "      <td>53.68</td>\n",
       "      <td>54.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>525.61</td>\n",
       "      <td>758.41</td>\n",
       "      <td>241.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.550</td>\n",
       "      <td>171.390</td>\n",
       "      <td>24.400</td>\n",
       "      <td>5.31</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.04</td>\n",
       "      <td>205.01</td>\n",
       "      <td>24.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.94</td>\n",
       "      <td>98.61</td>\n",
       "      <td>20.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.26</td>\n",
       "      <td>98.61</td>\n",
       "      <td>22.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.09</td>\n",
       "      <td>94.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.09</td>\n",
       "      <td>96.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.03</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.36</td>\n",
       "      <td>207.18</td>\n",
       "      <td>24.01</td>\n",
       "      <td>58.11</td>\n",
       "      <td>54.64</td>\n",
       "      <td>23.04</td>\n",
       "      <td>487.94</td>\n",
       "      <td>449.83</td>\n",
       "      <td>506.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.64</td>\n",
       "      <td>546.06</td>\n",
       "      <td>504.86</td>\n",
       "      <td>531.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.63</td>\n",
       "      <td>11.88</td>\n",
       "      <td>8.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.63</td>\n",
       "      <td>16.14</td>\n",
       "      <td>8.83</td>\n",
       "      <td>555.69</td>\n",
       "      <td>522.44</td>\n",
       "      <td>549.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.43</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306.854</td>\n",
       "      <td>406.289</td>\n",
       "      <td>413.329</td>\n",
       "      <td>450.93</td>\n",
       "      <td>609.03</td>\n",
       "      <td>700.68</td>\n",
       "      <td>60.94</td>\n",
       "      <td>23.84</td>\n",
       "      <td>74.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.78</td>\n",
       "      <td>14.56</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.66</td>\n",
       "      <td>10.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.84</td>\n",
       "      <td>3.44</td>\n",
       "      <td>25.51</td>\n",
       "      <td>450.48</td>\n",
       "      <td>608.24</td>\n",
       "      <td>686.11</td>\n",
       "      <td>58.54</td>\n",
       "      <td>21.18</td>\n",
       "      <td>63.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>509.03</td>\n",
       "      <td>629.43</td>\n",
       "      <td>749.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>5.39</td>\n",
       "      <td>4.96</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>514.79</td>\n",
       "      <td>638.28</td>\n",
       "      <td>779.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>9.91</td>\n",
       "      <td>10.13</td>\n",
       "      <td>9.23</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.13</td>\n",
       "      <td>9.59</td>\n",
       "      <td>17.61</td>\n",
       "      <td>29.71</td>\n",
       "      <td>92.36</td>\n",
       "      <td>107.39</td>\n",
       "      <td>13.88</td>\n",
       "      <td>13.96</td>\n",
       "      <td>32.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>43.59</td>\n",
       "      <td>106.33</td>\n",
       "      <td>141.48</td>\n",
       "      <td>53.73</td>\n",
       "      <td>115.93</td>\n",
       "      <td>159.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>356</td>\n",
       "      <td>490</td>\n",
       "      <td>546</td>\n",
       "      <td>90</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>50</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>462</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    arpu_6   arpu_7   arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  \\\n",
       "0   91.882   65.330   64.445        31.78        20.23        23.11   \n",
       "1  414.168  515.568  360.868        75.51        41.21        19.84   \n",
       "2  329.844  434.884  746.239         7.54         7.86         8.40   \n",
       "3   43.550  171.390   24.400         5.31         2.16         0.00   \n",
       "4  306.854  406.289  413.329       450.93       609.03       700.68   \n",
       "\n",
       "   offnet_mou_6  offnet_mou_7  offnet_mou_8  roam_ic_mou_6  roam_ic_mou_7  \\\n",
       "0         60.16         32.16         34.83           0.00           0.00   \n",
       "1        474.34        621.84        394.94           0.00           0.00   \n",
       "2         16.98         45.81         45.04          22.81         103.38   \n",
       "3         40.04        205.01         24.01           0.00           0.00   \n",
       "4         60.94         23.84         74.16           0.00           0.00   \n",
       "\n",
       "   roam_ic_mou_8  roam_og_mou_6  roam_og_mou_7  roam_og_mou_8  \\\n",
       "0           0.00           0.00           0.00           0.00   \n",
       "1           0.00           0.00           0.00           0.00   \n",
       "2          26.08          24.53          53.68          54.44   \n",
       "3           0.00           0.00           0.00           0.00   \n",
       "4           0.00           0.00           0.00           0.00   \n",
       "\n",
       "   loc_og_t2t_mou_6  loc_og_t2t_mou_7  loc_og_t2t_mou_8  loc_og_t2m_mou_6  \\\n",
       "0             24.88             20.23             21.06             18.13   \n",
       "1             75.51             41.21             19.84            473.61   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3              5.31              0.00              0.00              2.94   \n",
       "4              0.45              0.78             14.56              2.39   \n",
       "\n",
       "   loc_og_t2m_mou_7  loc_og_t2m_mou_8  loc_og_t2f_mou_6  loc_og_t2f_mou_7  \\\n",
       "0             10.89              8.36              0.00             13.58   \n",
       "1            598.08            377.26              0.73              0.00   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3             98.61             20.51              0.00              0.00   \n",
       "4              2.66             10.94              0.00              0.00   \n",
       "\n",
       "   loc_og_t2f_mou_8  loc_og_t2c_mou_6  loc_og_t2c_mou_7  loc_og_t2c_mou_8  \\\n",
       "0              0.00               0.0              0.00              0.03   \n",
       "1              0.00               0.0              0.00              0.00   \n",
       "2              0.00               0.0              0.00              0.00   \n",
       "3              2.35               0.0              6.18              0.00   \n",
       "4              0.00               0.0              0.00              0.00   \n",
       "\n",
       "   loc_og_mou_6  loc_og_mou_7  loc_og_mou_8  std_og_t2t_mou_6  \\\n",
       "0         43.01         44.71         29.43              6.90   \n",
       "1        549.86        639.29        397.11              0.00   \n",
       "2          0.00          0.00          0.00              0.00   \n",
       "3          8.26         98.61         22.86              0.00   \n",
       "4          2.84          3.44         25.51            450.48   \n",
       "\n",
       "   std_og_t2t_mou_7  std_og_t2t_mou_8  std_og_t2m_mou_6  std_og_t2m_mou_7  \\\n",
       "0              0.00              2.05             42.03              7.68   \n",
       "1              0.00              0.00              0.00             23.76   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3              2.16              0.00             37.09             94.36   \n",
       "4            608.24            686.11             58.54             21.18   \n",
       "\n",
       "   std_og_t2m_mou_8  std_og_t2f_mou_6  std_og_t2f_mou_7  std_og_t2f_mou_8  \\\n",
       "0             26.43               0.0               0.0               0.0   \n",
       "1             17.68               0.0               0.0               0.0   \n",
       "2              0.00               0.0               0.0               0.0   \n",
       "3              0.00               0.0               0.0               0.0   \n",
       "4             63.18               0.0               0.0               0.0   \n",
       "\n",
       "   std_og_mou_6  std_og_mou_7  std_og_mou_8  isd_og_mou_6  isd_og_mou_7  \\\n",
       "0         48.93          7.68         28.48           0.0           0.0   \n",
       "1          0.00         23.76         17.68           0.0           0.0   \n",
       "2          0.00          0.00          0.00           0.0           0.0   \n",
       "3         37.09         96.53          0.00           0.0           0.0   \n",
       "4        509.03        629.43        749.29           0.0           0.0   \n",
       "\n",
       "   isd_og_mou_8  spl_og_mou_6  spl_og_mou_7  spl_og_mou_8  og_others_6  \\\n",
       "0           0.0          0.00          0.00          0.03          0.0   \n",
       "1           0.8          0.00          0.00          0.00          0.0   \n",
       "2           0.0          0.00          0.00          0.00          0.0   \n",
       "3           0.0          0.00         12.03          1.15          0.0   \n",
       "4           0.0          0.71          5.39          4.96          2.2   \n",
       "\n",
       "   og_others_7  og_others_8  total_og_mou_6  total_og_mou_7  total_og_mou_8  \\\n",
       "0          0.0          0.0           91.94           52.39           57.94   \n",
       "1          0.0          0.0          549.86          663.06          415.59   \n",
       "2          0.0          0.0            0.00            0.00            0.00   \n",
       "3          0.0          0.0           45.36          207.18           24.01   \n",
       "4          0.0          0.0          514.79          638.28          779.78   \n",
       "\n",
       "   loc_ic_t2t_mou_6  loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  loc_ic_t2m_mou_6  \\\n",
       "0             30.33             37.56             21.98             10.21   \n",
       "1             19.99             26.95              2.61            160.19   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3             58.11             54.64             23.04            487.94   \n",
       "4              0.00              0.36              9.91             10.13   \n",
       "\n",
       "   loc_ic_t2m_mou_7  loc_ic_t2m_mou_8  loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  \\\n",
       "0              4.59              9.53              0.26              0.00   \n",
       "1            122.29            184.81              1.49              0.00   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3            449.83            506.94              0.00              0.38   \n",
       "4              9.23              7.69              0.00              0.00   \n",
       "\n",
       "   loc_ic_t2f_mou_8  loc_ic_mou_6  loc_ic_mou_7  loc_ic_mou_8  \\\n",
       "0              0.00         40.81         42.16         31.51   \n",
       "1              0.00        181.69        149.24        187.43   \n",
       "2              0.00          0.00          0.00          0.00   \n",
       "3              1.64        546.06        504.86        531.64   \n",
       "4              0.00         10.13          9.59         17.61   \n",
       "\n",
       "   std_ic_t2t_mou_6  std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2m_mou_6  \\\n",
       "0              0.00              0.00              0.00              0.36   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3              0.00              4.26              0.00              9.63   \n",
       "4             29.71             92.36            107.39             13.88   \n",
       "\n",
       "   std_ic_t2m_mou_7  std_ic_t2m_mou_8  std_ic_t2f_mou_6  std_ic_t2f_mou_7  \\\n",
       "0              1.04              4.34               0.0               0.0   \n",
       "1             12.51              0.00               0.0               0.0   \n",
       "2              0.00              0.00               0.0               0.0   \n",
       "3             11.88              8.83               0.0               0.0   \n",
       "4             13.96             32.46               0.0               0.0   \n",
       "\n",
       "   std_ic_t2f_mou_8  std_ic_mou_6  std_ic_mou_7  std_ic_mou_8  total_ic_mou_6  \\\n",
       "0              0.00          0.36          1.04          4.34           41.73   \n",
       "1              0.00          0.00         12.51          0.00          296.33   \n",
       "2              0.00          0.00          0.00          0.00            0.00   \n",
       "3              0.00          9.63         16.14          8.83          555.69   \n",
       "4              1.61         43.59        106.33        141.48           53.73   \n",
       "\n",
       "   total_ic_mou_7  total_ic_mou_8  spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  \\\n",
       "0           43.56           36.26          0.54          0.34          0.39   \n",
       "1          339.64          281.66          0.00          0.00          0.00   \n",
       "2            0.00            0.00          0.00          0.00          0.00   \n",
       "3          522.44          549.13          0.00          0.00          0.00   \n",
       "4          115.93          159.26          0.00          0.00          0.00   \n",
       "\n",
       "   isd_ic_mou_6  isd_ic_mou_7  isd_ic_mou_8  ic_others_6  ic_others_7  \\\n",
       "0          0.00          0.00          0.00          0.0          0.0   \n",
       "1        114.63        177.88         94.23          0.0          0.0   \n",
       "2          0.00          0.00          0.00          0.0          0.0   \n",
       "3          0.00          1.43          8.65          0.0          0.0   \n",
       "4          0.00          0.00          0.00          0.0          0.0   \n",
       "\n",
       "   ic_others_8  total_rech_num_6  total_rech_num_7  total_rech_num_8  \\\n",
       "0         0.00                 5                 5                 4   \n",
       "1         0.00                 5                 4                 5   \n",
       "2         0.00                 6                 9                 5   \n",
       "3         0.00                 3                 5                 2   \n",
       "4         0.16                11                 7                 8   \n",
       "\n",
       "   total_rech_amt_6  total_rech_amt_7  total_rech_amt_8  max_rech_amt_6  \\\n",
       "0               103                90                60              50   \n",
       "1               500               500               500             250   \n",
       "2               500              1000              1000             300   \n",
       "3               110               260                 0             110   \n",
       "4               356               490               546              90   \n",
       "\n",
       "   max_rech_amt_7  max_rech_amt_8  last_day_rch_amt_6  last_day_rch_amt_7  \\\n",
       "0              30              30                  30                  30   \n",
       "1             250             250                 250                   0   \n",
       "2             500             500                   0                   0   \n",
       "3             150               0                 110                 150   \n",
       "4             130             130                  50                 130   \n",
       "\n",
       "   last_day_rch_amt_8  vol_2g_mb_6  vol_2g_mb_7  vol_2g_mb_8  vol_3g_mb_6  \\\n",
       "0                   0          0.0          0.0          0.0          0.0   \n",
       "1                   0          0.0          0.0          0.0          0.0   \n",
       "2                   0          0.0          0.0          0.0          0.0   \n",
       "3                   0          0.0          0.0          0.0          0.0   \n",
       "4                 130          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   vol_3g_mb_7  vol_3g_mb_8  monthly_2g_6  monthly_2g_7  monthly_2g_8  \\\n",
       "0          0.0          0.0             0             0             0   \n",
       "1          0.0          0.0             0             0             0   \n",
       "2          0.0          0.0             0             0             0   \n",
       "3          0.0          0.0             0             0             0   \n",
       "4          0.0          0.0             0             0             0   \n",
       "\n",
       "   sachet_2g_6  sachet_2g_7  sachet_2g_8  monthly_3g_6  monthly_3g_7  \\\n",
       "0            0            0            0             0             0   \n",
       "1            0            0            0             0             0   \n",
       "2            0            0            0             0             0   \n",
       "3            0            0            0             0             0   \n",
       "4            0            0            0             0             0   \n",
       "\n",
       "   monthly_3g_8  sachet_3g_6  sachet_3g_7  sachet_3g_8   aon  aug_vbc_3g  \\\n",
       "0             0            0            0            0  1692        0.00   \n",
       "1             0            0            0            0  2533        0.00   \n",
       "2             0            0            0            0   277      525.61   \n",
       "3             0            0            0            0  1244        0.00   \n",
       "4             0            0            0            0   462        0.00   \n",
       "\n",
       "   jul_vbc_3g  jun_vbc_3g  \n",
       "0        0.00        0.00  \n",
       "1        0.00        0.00  \n",
       "2      758.41      241.84  \n",
       "3        0.00        0.00  \n",
       "4        0.00        0.00  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ef056606",
   "metadata": {},
   "outputs": [],
   "source": [
    "if zero_impute==0:\n",
    "    orig_cols=test_data.columns\n",
    "    test_data = pd.DataFrame(simple_imtr.fit_transform(test_data))\n",
    "    test_data.columns=orig_cols\n",
    "else :\n",
    "    test_data=test_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d462749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f3149427",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test=rfc_best.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "21402576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total occurences of \"1\" in array:  2665\n",
      "Total occurences of \"0\" in array:  27335\n"
     ]
    }
   ],
   "source": [
    "count_arr = np.bincount(predictions_test)\n",
    "# Count occurrence of element '1' in numpy array\n",
    "print('Total occurences of \"1\" in array: ', count_arr[1])\n",
    "# Count occurrence of element '0' in numpy array\n",
    "print('Total occurences of \"0\" in array: ', count_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0d773040",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_xgb=xgb_best.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d5e3e82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total occurences of \"1\" in array:  2621\n",
      "Total occurences of \"0\" in array:  27379\n"
     ]
    }
   ],
   "source": [
    "count_arr = np.bincount(predictions_test_xgb)\n",
    "# Count occurrence of element '1' in numpy array\n",
    "print('Total occurences of \"1\" in array: ', count_arr[1])\n",
    "# Count occurrence of element '0' in numpy array\n",
    "print('Total occurences of \"0\" in array: ', count_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "adab6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_df=pd.DataFrame({'id':id,'churn_probability':predictions_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "41c2c5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  churn_probability\n",
       "0  69999                  0\n",
       "1  70000                  0\n",
       "2  70001                  1\n",
       "3  70002                  0\n",
       "4  70003                  0\n",
       "5  70004                  1\n",
       "6  70005                  0\n",
       "7  70006                  0\n",
       "8  70007                  0\n",
       "9  70008                  0"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "770059e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_df.to_csv('solution_rfc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "deb0fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_df_xgb=pd.DataFrame({'id':id,'churn_probability':predictions_test_xgb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0f46153d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  churn_probability\n",
       "0  69999                  0\n",
       "1  70000                  0\n",
       "2  70001                  1\n",
       "3  70002                  0\n",
       "4  70003                  0\n",
       "5  70004                  1\n",
       "6  70005                  0\n",
       "7  70006                  0\n",
       "8  70007                  0\n",
       "9  70008                  1"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution_df_xgb.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2cae7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_df_xgb.to_csv('solution_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eddd152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

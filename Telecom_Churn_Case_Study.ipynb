{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7a5be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA , IncrementalPCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer,KNNImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea3d29a",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d341698",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Shape:  (69999, 172)\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Dataframe Info: \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69999 entries, 0 to 69998\n",
      "Data columns (total 172 columns):\n",
      " #    Column                    Dtype  \n",
      "---   ------                    -----  \n",
      " 0    id                        int64  \n",
      " 1    circle_id                 int64  \n",
      " 2    loc_og_t2o_mou            float64\n",
      " 3    std_og_t2o_mou            float64\n",
      " 4    loc_ic_t2o_mou            float64\n",
      " 5    last_date_of_month_6      object \n",
      " 6    last_date_of_month_7      object \n",
      " 7    last_date_of_month_8      object \n",
      " 8    arpu_6                    float64\n",
      " 9    arpu_7                    float64\n",
      " 10   arpu_8                    float64\n",
      " 11   onnet_mou_6               float64\n",
      " 12   onnet_mou_7               float64\n",
      " 13   onnet_mou_8               float64\n",
      " 14   offnet_mou_6              float64\n",
      " 15   offnet_mou_7              float64\n",
      " 16   offnet_mou_8              float64\n",
      " 17   roam_ic_mou_6             float64\n",
      " 18   roam_ic_mou_7             float64\n",
      " 19   roam_ic_mou_8             float64\n",
      " 20   roam_og_mou_6             float64\n",
      " 21   roam_og_mou_7             float64\n",
      " 22   roam_og_mou_8             float64\n",
      " 23   loc_og_t2t_mou_6          float64\n",
      " 24   loc_og_t2t_mou_7          float64\n",
      " 25   loc_og_t2t_mou_8          float64\n",
      " 26   loc_og_t2m_mou_6          float64\n",
      " 27   loc_og_t2m_mou_7          float64\n",
      " 28   loc_og_t2m_mou_8          float64\n",
      " 29   loc_og_t2f_mou_6          float64\n",
      " 30   loc_og_t2f_mou_7          float64\n",
      " 31   loc_og_t2f_mou_8          float64\n",
      " 32   loc_og_t2c_mou_6          float64\n",
      " 33   loc_og_t2c_mou_7          float64\n",
      " 34   loc_og_t2c_mou_8          float64\n",
      " 35   loc_og_mou_6              float64\n",
      " 36   loc_og_mou_7              float64\n",
      " 37   loc_og_mou_8              float64\n",
      " 38   std_og_t2t_mou_6          float64\n",
      " 39   std_og_t2t_mou_7          float64\n",
      " 40   std_og_t2t_mou_8          float64\n",
      " 41   std_og_t2m_mou_6          float64\n",
      " 42   std_og_t2m_mou_7          float64\n",
      " 43   std_og_t2m_mou_8          float64\n",
      " 44   std_og_t2f_mou_6          float64\n",
      " 45   std_og_t2f_mou_7          float64\n",
      " 46   std_og_t2f_mou_8          float64\n",
      " 47   std_og_t2c_mou_6          float64\n",
      " 48   std_og_t2c_mou_7          float64\n",
      " 49   std_og_t2c_mou_8          float64\n",
      " 50   std_og_mou_6              float64\n",
      " 51   std_og_mou_7              float64\n",
      " 52   std_og_mou_8              float64\n",
      " 53   isd_og_mou_6              float64\n",
      " 54   isd_og_mou_7              float64\n",
      " 55   isd_og_mou_8              float64\n",
      " 56   spl_og_mou_6              float64\n",
      " 57   spl_og_mou_7              float64\n",
      " 58   spl_og_mou_8              float64\n",
      " 59   og_others_6               float64\n",
      " 60   og_others_7               float64\n",
      " 61   og_others_8               float64\n",
      " 62   total_og_mou_6            float64\n",
      " 63   total_og_mou_7            float64\n",
      " 64   total_og_mou_8            float64\n",
      " 65   loc_ic_t2t_mou_6          float64\n",
      " 66   loc_ic_t2t_mou_7          float64\n",
      " 67   loc_ic_t2t_mou_8          float64\n",
      " 68   loc_ic_t2m_mou_6          float64\n",
      " 69   loc_ic_t2m_mou_7          float64\n",
      " 70   loc_ic_t2m_mou_8          float64\n",
      " 71   loc_ic_t2f_mou_6          float64\n",
      " 72   loc_ic_t2f_mou_7          float64\n",
      " 73   loc_ic_t2f_mou_8          float64\n",
      " 74   loc_ic_mou_6              float64\n",
      " 75   loc_ic_mou_7              float64\n",
      " 76   loc_ic_mou_8              float64\n",
      " 77   std_ic_t2t_mou_6          float64\n",
      " 78   std_ic_t2t_mou_7          float64\n",
      " 79   std_ic_t2t_mou_8          float64\n",
      " 80   std_ic_t2m_mou_6          float64\n",
      " 81   std_ic_t2m_mou_7          float64\n",
      " 82   std_ic_t2m_mou_8          float64\n",
      " 83   std_ic_t2f_mou_6          float64\n",
      " 84   std_ic_t2f_mou_7          float64\n",
      " 85   std_ic_t2f_mou_8          float64\n",
      " 86   std_ic_t2o_mou_6          float64\n",
      " 87   std_ic_t2o_mou_7          float64\n",
      " 88   std_ic_t2o_mou_8          float64\n",
      " 89   std_ic_mou_6              float64\n",
      " 90   std_ic_mou_7              float64\n",
      " 91   std_ic_mou_8              float64\n",
      " 92   total_ic_mou_6            float64\n",
      " 93   total_ic_mou_7            float64\n",
      " 94   total_ic_mou_8            float64\n",
      " 95   spl_ic_mou_6              float64\n",
      " 96   spl_ic_mou_7              float64\n",
      " 97   spl_ic_mou_8              float64\n",
      " 98   isd_ic_mou_6              float64\n",
      " 99   isd_ic_mou_7              float64\n",
      " 100  isd_ic_mou_8              float64\n",
      " 101  ic_others_6               float64\n",
      " 102  ic_others_7               float64\n",
      " 103  ic_others_8               float64\n",
      " 104  total_rech_num_6          int64  \n",
      " 105  total_rech_num_7          int64  \n",
      " 106  total_rech_num_8          int64  \n",
      " 107  total_rech_amt_6          int64  \n",
      " 108  total_rech_amt_7          int64  \n",
      " 109  total_rech_amt_8          int64  \n",
      " 110  max_rech_amt_6            int64  \n",
      " 111  max_rech_amt_7            int64  \n",
      " 112  max_rech_amt_8            int64  \n",
      " 113  date_of_last_rech_6       object \n",
      " 114  date_of_last_rech_7       object \n",
      " 115  date_of_last_rech_8       object \n",
      " 116  last_day_rch_amt_6        int64  \n",
      " 117  last_day_rch_amt_7        int64  \n",
      " 118  last_day_rch_amt_8        int64  \n",
      " 119  date_of_last_rech_data_6  object \n",
      " 120  date_of_last_rech_data_7  object \n",
      " 121  date_of_last_rech_data_8  object \n",
      " 122  total_rech_data_6         float64\n",
      " 123  total_rech_data_7         float64\n",
      " 124  total_rech_data_8         float64\n",
      " 125  max_rech_data_6           float64\n",
      " 126  max_rech_data_7           float64\n",
      " 127  max_rech_data_8           float64\n",
      " 128  count_rech_2g_6           float64\n",
      " 129  count_rech_2g_7           float64\n",
      " 130  count_rech_2g_8           float64\n",
      " 131  count_rech_3g_6           float64\n",
      " 132  count_rech_3g_7           float64\n",
      " 133  count_rech_3g_8           float64\n",
      " 134  av_rech_amt_data_6        float64\n",
      " 135  av_rech_amt_data_7        float64\n",
      " 136  av_rech_amt_data_8        float64\n",
      " 137  vol_2g_mb_6               float64\n",
      " 138  vol_2g_mb_7               float64\n",
      " 139  vol_2g_mb_8               float64\n",
      " 140  vol_3g_mb_6               float64\n",
      " 141  vol_3g_mb_7               float64\n",
      " 142  vol_3g_mb_8               float64\n",
      " 143  arpu_3g_6                 float64\n",
      " 144  arpu_3g_7                 float64\n",
      " 145  arpu_3g_8                 float64\n",
      " 146  arpu_2g_6                 float64\n",
      " 147  arpu_2g_7                 float64\n",
      " 148  arpu_2g_8                 float64\n",
      " 149  night_pck_user_6          float64\n",
      " 150  night_pck_user_7          float64\n",
      " 151  night_pck_user_8          float64\n",
      " 152  monthly_2g_6              int64  \n",
      " 153  monthly_2g_7              int64  \n",
      " 154  monthly_2g_8              int64  \n",
      " 155  sachet_2g_6               int64  \n",
      " 156  sachet_2g_7               int64  \n",
      " 157  sachet_2g_8               int64  \n",
      " 158  monthly_3g_6              int64  \n",
      " 159  monthly_3g_7              int64  \n",
      " 160  monthly_3g_8              int64  \n",
      " 161  sachet_3g_6               int64  \n",
      " 162  sachet_3g_7               int64  \n",
      " 163  sachet_3g_8               int64  \n",
      " 164  fb_user_6                 float64\n",
      " 165  fb_user_7                 float64\n",
      " 166  fb_user_8                 float64\n",
      " 167  aon                       int64  \n",
      " 168  aug_vbc_3g                float64\n",
      " 169  jul_vbc_3g                float64\n",
      " 170  jun_vbc_3g                float64\n",
      " 171  churn_probability         int64  \n",
      "dtypes: float64(135), int64(28), object(9)\n",
      "memory usage: 91.9+ MB\n",
      "-------------------------------------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>date_of_last_rech_data_6</th>\n",
       "      <th>date_of_last_rech_data_7</th>\n",
       "      <th>date_of_last_rech_data_8</th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <th>count_rech_3g_8</th>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <th>av_rech_amt_data_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <th>arpu_3g_7</th>\n",
       "      <th>arpu_3g_8</th>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <th>night_pck_user_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>31.277</td>\n",
       "      <td>87.009</td>\n",
       "      <td>7.527</td>\n",
       "      <td>48.58</td>\n",
       "      <td>124.38</td>\n",
       "      <td>1.29</td>\n",
       "      <td>32.24</td>\n",
       "      <td>96.68</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.29</td>\n",
       "      <td>16.04</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.53</td>\n",
       "      <td>16.04</td>\n",
       "      <td>2.61</td>\n",
       "      <td>46.34</td>\n",
       "      <td>124.38</td>\n",
       "      <td>1.01</td>\n",
       "      <td>18.75</td>\n",
       "      <td>80.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.09</td>\n",
       "      <td>204.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.21</td>\n",
       "      <td>221.68</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.68</td>\n",
       "      <td>7.79</td>\n",
       "      <td>0.83</td>\n",
       "      <td>21.08</td>\n",
       "      <td>16.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.26</td>\n",
       "      <td>24.76</td>\n",
       "      <td>24.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>7.46</td>\n",
       "      <td>19.96</td>\n",
       "      <td>14.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.46</td>\n",
       "      <td>27.58</td>\n",
       "      <td>15.18</td>\n",
       "      <td>11.84</td>\n",
       "      <td>53.04</td>\n",
       "      <td>40.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>6/22/2014</td>\n",
       "      <td>7/10/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>122.787</td>\n",
       "      <td>42.953</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.99</td>\n",
       "      <td>30.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.01</td>\n",
       "      <td>29.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.73</td>\n",
       "      <td>31.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.73</td>\n",
       "      <td>31.66</td>\n",
       "      <td>1.68</td>\n",
       "      <td>19.09</td>\n",
       "      <td>10.53</td>\n",
       "      <td>1.41</td>\n",
       "      <td>18.68</td>\n",
       "      <td>11.09</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.44</td>\n",
       "      <td>39.44</td>\n",
       "      <td>25.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.44</td>\n",
       "      <td>39.44</td>\n",
       "      <td>25.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>50</td>\n",
       "      <td>6/12/2014</td>\n",
       "      <td>7/10/2014</td>\n",
       "      <td>8/26/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/8/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>352.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>60.806</td>\n",
       "      <td>103.176</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.53</td>\n",
       "      <td>15.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53.99</td>\n",
       "      <td>82.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>12.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.64</td>\n",
       "      <td>12.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.94</td>\n",
       "      <td>82.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.94</td>\n",
       "      <td>84.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.49</td>\n",
       "      <td>99.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.51</td>\n",
       "      <td>6.16</td>\n",
       "      <td>6.49</td>\n",
       "      <td>89.86</td>\n",
       "      <td>25.18</td>\n",
       "      <td>23.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94.38</td>\n",
       "      <td>31.34</td>\n",
       "      <td>30.01</td>\n",
       "      <td>11.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.21</td>\n",
       "      <td>2.48</td>\n",
       "      <td>6.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>6.38</td>\n",
       "      <td>124.29</td>\n",
       "      <td>33.83</td>\n",
       "      <td>36.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>6/11/2014</td>\n",
       "      <td>7/22/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>156.362</td>\n",
       "      <td>205.260</td>\n",
       "      <td>111.095</td>\n",
       "      <td>7.26</td>\n",
       "      <td>16.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68.76</td>\n",
       "      <td>78.48</td>\n",
       "      <td>50.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>6.99</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.91</td>\n",
       "      <td>44.89</td>\n",
       "      <td>23.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.03</td>\n",
       "      <td>44.91</td>\n",
       "      <td>48.84</td>\n",
       "      <td>23.63</td>\n",
       "      <td>0.26</td>\n",
       "      <td>12.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.33</td>\n",
       "      <td>25.93</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.16</td>\n",
       "      <td>37.99</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.95</td>\n",
       "      <td>9.13</td>\n",
       "      <td>25.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.03</td>\n",
       "      <td>95.98</td>\n",
       "      <td>53.84</td>\n",
       "      <td>24.98</td>\n",
       "      <td>4.84</td>\n",
       "      <td>23.88</td>\n",
       "      <td>53.99</td>\n",
       "      <td>44.23</td>\n",
       "      <td>57.14</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86.21</td>\n",
       "      <td>49.89</td>\n",
       "      <td>81.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.81</td>\n",
       "      <td>95.11</td>\n",
       "      <td>50.18</td>\n",
       "      <td>83.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>240</td>\n",
       "      <td>130</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>6/15/2014</td>\n",
       "      <td>7/21/2014</td>\n",
       "      <td>8/25/2014</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>240.708</td>\n",
       "      <td>128.191</td>\n",
       "      <td>101.565</td>\n",
       "      <td>21.28</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.13</td>\n",
       "      <td>56.99</td>\n",
       "      <td>38.11</td>\n",
       "      <td>9.63</td>\n",
       "      <td>53.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.16</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.13</td>\n",
       "      <td>36.74</td>\n",
       "      <td>19.88</td>\n",
       "      <td>4.61</td>\n",
       "      <td>11.99</td>\n",
       "      <td>1.23</td>\n",
       "      <td>5.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58.91</td>\n",
       "      <td>25.94</td>\n",
       "      <td>15.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.26</td>\n",
       "      <td>42.94</td>\n",
       "      <td>15.76</td>\n",
       "      <td>5.44</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.66</td>\n",
       "      <td>10.58</td>\n",
       "      <td>4.33</td>\n",
       "      <td>19.49</td>\n",
       "      <td>5.51</td>\n",
       "      <td>3.63</td>\n",
       "      <td>6.14</td>\n",
       "      <td>21.54</td>\n",
       "      <td>9.36</td>\n",
       "      <td>28.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.54</td>\n",
       "      <td>9.36</td>\n",
       "      <td>28.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>290</td>\n",
       "      <td>136</td>\n",
       "      <td>122</td>\n",
       "      <td>50</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/26/2014</td>\n",
       "      <td>8/30/2014</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/23/2014</td>\n",
       "      <td>8/20/2014</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>390.8</td>\n",
       "      <td>308.89</td>\n",
       "      <td>213.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0   0        109             0.0             0.0             0.0   \n",
       "1   1        109             0.0             0.0             0.0   \n",
       "2   2        109             0.0             0.0             0.0   \n",
       "3   3        109             0.0             0.0             0.0   \n",
       "4   4        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8   arpu_6  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   31.277   \n",
       "1            6/30/2014            7/31/2014            8/31/2014    0.000   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   60.806   \n",
       "3            6/30/2014            7/31/2014            8/31/2014  156.362   \n",
       "4            6/30/2014            7/31/2014            8/31/2014  240.708   \n",
       "\n",
       "    arpu_7   arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  offnet_mou_6  \\\n",
       "0   87.009    7.527        48.58       124.38         1.29         32.24   \n",
       "1  122.787   42.953         0.00         0.00         0.00          0.00   \n",
       "2  103.176    0.000         0.53        15.93         0.00         53.99   \n",
       "3  205.260  111.095         7.26        16.01         0.00         68.76   \n",
       "4  128.191  101.565        21.28         4.83         6.13         56.99   \n",
       "\n",
       "   offnet_mou_7  offnet_mou_8  roam_ic_mou_6  roam_ic_mou_7  roam_ic_mou_8  \\\n",
       "0         96.68          2.33           0.00            0.0            0.0   \n",
       "1         25.99         30.89           0.00            0.0            0.0   \n",
       "2         82.05          0.00           0.00            0.0            0.0   \n",
       "3         78.48         50.23           0.00            0.0            0.0   \n",
       "4         38.11          9.63          53.64            0.0            0.0   \n",
       "\n",
       "   roam_og_mou_6  roam_og_mou_7  roam_og_mou_8  loc_og_t2t_mou_6  \\\n",
       "0           0.00            0.0           0.00              2.23   \n",
       "1           0.00            0.0           0.00              0.00   \n",
       "2           0.00            0.0           0.00              0.53   \n",
       "3           0.00            0.0           1.63              6.99   \n",
       "4          15.73            0.0           0.00             10.16   \n",
       "\n",
       "   loc_og_t2t_mou_7  loc_og_t2t_mou_8  loc_og_t2m_mou_6  loc_og_t2m_mou_7  \\\n",
       "0              0.00              0.28              5.29             16.04   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2             12.98              0.00             24.11              0.00   \n",
       "3              3.94              0.00             37.91             44.89   \n",
       "4              4.83              6.13             36.74             19.88   \n",
       "\n",
       "   loc_og_t2m_mou_8  loc_og_t2f_mou_6  loc_og_t2f_mou_7  loc_og_t2f_mou_8  \\\n",
       "0              2.33              0.00              0.00              0.00   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3             23.63              0.00              0.00              0.00   \n",
       "4              4.61             11.99              1.23              5.01   \n",
       "\n",
       "   loc_og_t2c_mou_6  loc_og_t2c_mou_7  loc_og_t2c_mou_8  loc_og_mou_6  \\\n",
       "0              0.00              0.00              0.00          7.53   \n",
       "1              0.00             22.01             29.79          0.00   \n",
       "2              2.14              0.00              0.00         24.64   \n",
       "3              0.00              0.00              8.03         44.91   \n",
       "4              0.00              9.85              0.00         58.91   \n",
       "\n",
       "   loc_og_mou_7  loc_og_mou_8  std_og_t2t_mou_6  std_og_t2t_mou_7  \\\n",
       "0         16.04          2.61             46.34            124.38   \n",
       "1          0.00          0.00              0.00              0.00   \n",
       "2         12.98          0.00              0.00              2.94   \n",
       "3         48.84         23.63              0.26             12.06   \n",
       "4         25.94         15.76              0.00              0.00   \n",
       "\n",
       "   std_og_t2t_mou_8  std_og_t2m_mou_6  std_og_t2m_mou_7  std_og_t2m_mou_8  \\\n",
       "0              1.01             18.75             80.61               0.0   \n",
       "1              0.00              0.00              0.00               0.0   \n",
       "2              0.00             28.94             82.05               0.0   \n",
       "3              0.00             15.33             25.93               4.6   \n",
       "4              0.00              4.35              0.00               0.0   \n",
       "\n",
       "   std_og_t2f_mou_6  std_og_t2f_mou_7  std_og_t2f_mou_8  std_og_t2c_mou_6  \\\n",
       "0              0.00               0.0               0.0               0.0   \n",
       "1              0.00               0.0               0.0               0.0   \n",
       "2              0.00               0.0               0.0               0.0   \n",
       "3              0.56               0.0               0.0               0.0   \n",
       "4              0.00               0.0               0.0               0.0   \n",
       "\n",
       "   std_og_t2c_mou_7  std_og_t2c_mou_8  std_og_mou_6  std_og_mou_7  \\\n",
       "0               0.0               0.0         65.09        204.99   \n",
       "1               0.0               0.0          0.00          0.00   \n",
       "2               0.0               0.0         28.94         84.99   \n",
       "3               0.0               0.0         16.16         37.99   \n",
       "4               0.0               0.0          4.35          0.00   \n",
       "\n",
       "   std_og_mou_8  isd_og_mou_6  isd_og_mou_7  isd_og_mou_8  spl_og_mou_6  \\\n",
       "0          1.01           0.0           0.0           0.0          8.20   \n",
       "1          0.00           0.0           0.0           0.0          0.00   \n",
       "2          0.00           0.0           0.0           0.0          2.89   \n",
       "3          4.60           0.0           0.0           0.0         14.95   \n",
       "4          0.00           0.0           0.0           0.0          0.00   \n",
       "\n",
       "   spl_og_mou_7  spl_og_mou_8  og_others_6  og_others_7  og_others_8  \\\n",
       "0          0.63          0.00         0.38          0.0          0.0   \n",
       "1         30.73         31.66         0.00          0.0          0.0   \n",
       "2          1.38          0.00         0.00          0.0          0.0   \n",
       "3          9.13         25.61         0.00          0.0          0.0   \n",
       "4         17.00          0.00         0.00          0.0          0.0   \n",
       "\n",
       "   total_og_mou_6  total_og_mou_7  total_og_mou_8  loc_ic_t2t_mou_6  \\\n",
       "0           81.21          221.68            3.63              2.43   \n",
       "1            0.00           30.73           31.66              1.68   \n",
       "2           56.49           99.36            0.00              4.51   \n",
       "3           76.03           95.98           53.84             24.98   \n",
       "4           63.26           42.94           15.76              5.44   \n",
       "\n",
       "   loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  \\\n",
       "0              3.68              7.79              0.83             21.08   \n",
       "1             19.09             10.53              1.41             18.68   \n",
       "2              6.16              6.49             89.86             25.18   \n",
       "3              4.84             23.88             53.99             44.23   \n",
       "4              1.39              2.66             10.58              4.33   \n",
       "\n",
       "   loc_ic_t2m_mou_8  loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  \\\n",
       "0             16.91              0.00              0.00              0.00   \n",
       "1             11.09              0.35              1.66              3.40   \n",
       "2             23.51              0.00              0.00              0.00   \n",
       "3             57.14              7.23              0.81              0.00   \n",
       "4             19.49              5.51              3.63              6.14   \n",
       "\n",
       "   loc_ic_mou_6  loc_ic_mou_7  loc_ic_mou_8  std_ic_t2t_mou_6  \\\n",
       "0          3.26         24.76         24.71              0.00   \n",
       "1          3.44         39.44         25.03              0.00   \n",
       "2         94.38         31.34         30.01             11.69   \n",
       "3         86.21         49.89         81.03              0.00   \n",
       "4         21.54          9.36         28.31              0.00   \n",
       "\n",
       "   std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2m_mou_6  std_ic_t2m_mou_7  \\\n",
       "0              7.61              0.21              7.46             19.96   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2              0.00              0.00             18.21              2.48   \n",
       "3              0.00              0.00              8.89              0.28   \n",
       "4              0.00              0.00              0.00              0.00   \n",
       "\n",
       "   std_ic_t2m_mou_8  std_ic_t2f_mou_6  std_ic_t2f_mou_7  std_ic_t2f_mou_8  \\\n",
       "0             14.96               0.0               0.0               0.0   \n",
       "1              0.00               0.0               0.0               0.0   \n",
       "2              6.38               0.0               0.0               0.0   \n",
       "3              2.81               0.0               0.0               0.0   \n",
       "4              0.00               0.0               0.0               0.0   \n",
       "\n",
       "   std_ic_t2o_mou_6  std_ic_t2o_mou_7  std_ic_t2o_mou_8  std_ic_mou_6  \\\n",
       "0               0.0               0.0               0.0          7.46   \n",
       "1               0.0               0.0               0.0          0.00   \n",
       "2               0.0               0.0               0.0         29.91   \n",
       "3               0.0               0.0               0.0          8.89   \n",
       "4               0.0               0.0               0.0          0.00   \n",
       "\n",
       "   std_ic_mou_7  std_ic_mou_8  total_ic_mou_6  total_ic_mou_7  total_ic_mou_8  \\\n",
       "0         27.58         15.18           11.84           53.04           40.56   \n",
       "1          0.00          0.00            3.44           39.44           25.04   \n",
       "2          2.48          6.38          124.29           33.83           36.64   \n",
       "3          0.28          2.81           95.11           50.18           83.84   \n",
       "4          0.00          0.00           21.54            9.36           28.31   \n",
       "\n",
       "   spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  isd_ic_mou_6  isd_ic_mou_7  \\\n",
       "0           0.0           0.0          0.66           0.0           0.0   \n",
       "1           0.0           0.0          0.01           0.0           0.0   \n",
       "2           0.0           0.0          0.00           0.0           0.0   \n",
       "3           0.0           0.0          0.00           0.0           0.0   \n",
       "4           0.0           0.0          0.00           0.0           0.0   \n",
       "\n",
       "   isd_ic_mou_8  ic_others_6  ic_others_7  ic_others_8  total_rech_num_6  \\\n",
       "0           0.0         1.11         0.69         0.00                 3   \n",
       "1           0.0         0.00         0.00         0.00                 3   \n",
       "2           0.0         0.00         0.00         0.25                 2   \n",
       "3           0.0         0.00         0.00         0.00                 2   \n",
       "4           0.0         0.00         0.00         0.00                13   \n",
       "\n",
       "   total_rech_num_7  total_rech_num_8  total_rech_amt_6  total_rech_amt_7  \\\n",
       "0                 2                 2                77                65   \n",
       "1                 4                 5                 0               145   \n",
       "2                 4                 2                70               120   \n",
       "3                 4                 3               160               240   \n",
       "4                10                 8               290               136   \n",
       "\n",
       "   total_rech_amt_8  max_rech_amt_6  max_rech_amt_7  max_rech_amt_8  \\\n",
       "0                10              65              65              10   \n",
       "1                50               0             145              50   \n",
       "2                 0              70              70               0   \n",
       "3               130             110             110              50   \n",
       "4               122              50              41              30   \n",
       "\n",
       "  date_of_last_rech_6 date_of_last_rech_7 date_of_last_rech_8  \\\n",
       "0           6/22/2014           7/10/2014           8/24/2014   \n",
       "1           6/12/2014           7/10/2014           8/26/2014   \n",
       "2           6/11/2014           7/22/2014           8/24/2014   \n",
       "3           6/15/2014           7/21/2014           8/25/2014   \n",
       "4           6/25/2014           7/26/2014           8/30/2014   \n",
       "\n",
       "   last_day_rch_amt_6  last_day_rch_amt_7  last_day_rch_amt_8  \\\n",
       "0                  65                  65                   0   \n",
       "1                   0                   0                   0   \n",
       "2                  70                  50                   0   \n",
       "3                 110                 110                  50   \n",
       "4                  25                  10                  30   \n",
       "\n",
       "  date_of_last_rech_data_6 date_of_last_rech_data_7 date_of_last_rech_data_8  \\\n",
       "0                      NaN                      NaN                      NaN   \n",
       "1                      NaN                 7/8/2014                      NaN   \n",
       "2                      NaN                      NaN                      NaN   \n",
       "3                      NaN                      NaN                      NaN   \n",
       "4                6/25/2014                7/23/2014                8/20/2014   \n",
       "\n",
       "   total_rech_data_6  total_rech_data_7  total_rech_data_8  max_rech_data_6  \\\n",
       "0                NaN                NaN                NaN              NaN   \n",
       "1                NaN                1.0                NaN              NaN   \n",
       "2                NaN                NaN                NaN              NaN   \n",
       "3                NaN                NaN                NaN              NaN   \n",
       "4                7.0                7.0                6.0             25.0   \n",
       "\n",
       "   max_rech_data_7  max_rech_data_8  count_rech_2g_6  count_rech_2g_7  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1            145.0              NaN              NaN              0.0   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4             41.0             25.0              7.0              6.0   \n",
       "\n",
       "   count_rech_2g_8  count_rech_3g_6  count_rech_3g_7  count_rech_3g_8  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              1.0              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              6.0              0.0              1.0              0.0   \n",
       "\n",
       "   av_rech_amt_data_6  av_rech_amt_data_7  av_rech_amt_data_8  vol_2g_mb_6  \\\n",
       "0                 NaN                 NaN                 NaN          0.0   \n",
       "1                 NaN               145.0                 NaN          0.0   \n",
       "2                 NaN                 NaN                 NaN          0.0   \n",
       "3                 NaN                 NaN                 NaN          0.0   \n",
       "4               175.0               191.0               142.0        390.8   \n",
       "\n",
       "   vol_2g_mb_7  vol_2g_mb_8  vol_3g_mb_6  vol_3g_mb_7  vol_3g_mb_8  arpu_3g_6  \\\n",
       "0         0.00         0.00          0.0         0.00          0.0        NaN   \n",
       "1       352.91         0.00          0.0         3.96          0.0        NaN   \n",
       "2         0.00         0.00          0.0         0.00          0.0        NaN   \n",
       "3         0.00         0.00          0.0         0.00          0.0        NaN   \n",
       "4       308.89       213.47          0.0         0.00          0.0        0.0   \n",
       "\n",
       "   arpu_3g_7  arpu_3g_8  arpu_2g_6  arpu_2g_7  arpu_2g_8  night_pck_user_6  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "1     122.07        NaN        NaN     122.08        NaN               NaN   \n",
       "2        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "3        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "4      35.00        0.0        0.0      35.12        0.0               0.0   \n",
       "\n",
       "   night_pck_user_7  night_pck_user_8  monthly_2g_6  monthly_2g_7  \\\n",
       "0               NaN               NaN             0             0   \n",
       "1               0.0               NaN             0             0   \n",
       "2               NaN               NaN             0             0   \n",
       "3               NaN               NaN             0             0   \n",
       "4               0.0               0.0             0             0   \n",
       "\n",
       "   monthly_2g_8  sachet_2g_6  sachet_2g_7  sachet_2g_8  monthly_3g_6  \\\n",
       "0             0            0            0            0             0   \n",
       "1             0            0            0            0             0   \n",
       "2             0            0            0            0             0   \n",
       "3             0            0            0            0             0   \n",
       "4             0            7            6            6             0   \n",
       "\n",
       "   monthly_3g_7  monthly_3g_8  sachet_3g_6  sachet_3g_7  sachet_3g_8  \\\n",
       "0             0             0            0            0            0   \n",
       "1             1             0            0            0            0   \n",
       "2             0             0            0            0            0   \n",
       "3             0             0            0            0            0   \n",
       "4             0             0            0            1            0   \n",
       "\n",
       "   fb_user_6  fb_user_7  fb_user_8   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \\\n",
       "0        NaN        NaN        NaN  1958         0.0         0.0         0.0   \n",
       "1        NaN        1.0        NaN   710         0.0         0.0         0.0   \n",
       "2        NaN        NaN        NaN   882         0.0         0.0         0.0   \n",
       "3        NaN        NaN        NaN   982         0.0         0.0         0.0   \n",
       "4        1.0        1.0        1.0   647         0.0         0.0         0.0   \n",
       "\n",
       "   churn_probability  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "print('Dataframe Shape: ', data.shape); print('-'*80, '\\n');\n",
    "print(\"Dataframe Info: \\n\"); data.info(verbose=True); print('-'*80, '\\n')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8fcf2b",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799b40a3",
   "metadata": {},
   "source": [
    "### Identify columns that have no variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcdbfef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(how='all',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f91e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with all same entries\n",
    "data_unique_count_is_one=data.columns[data.nunique()==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f71f843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['circle_id', 'loc_og_t2o_mou', 'std_og_t2o_mou', 'loc_ic_t2o_mou',\n",
       "       'last_date_of_month_6', 'last_date_of_month_7', 'last_date_of_month_8',\n",
       "       'std_og_t2c_mou_6', 'std_og_t2c_mou_7', 'std_og_t2c_mou_8',\n",
       "       'std_ic_t2o_mou_6', 'std_ic_t2o_mou_7', 'std_ic_t2o_mou_8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unique_count_is_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79461707",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data_unique_count_is_one,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "998cc665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 159)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5c851d",
   "metadata": {},
   "source": [
    "### Check for Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44a43f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with all NULL values = 0\n"
     ]
    }
   ],
   "source": [
    "# Check how many rows have all missing values\n",
    "print(\"Rows with all NULL values =\",  data.isnull().all(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2e99d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMissingValues(missingCutoff):\n",
    "    # Function to retun the columns with more than missingCutoff% missing values.\n",
    "    missing = round(100*(data.isnull().sum()/data.shape[0]))\n",
    "    print(\"There are {} features having more than {}% missing values/entries\".format(len(missing.loc[missing > missingCutoff]),missingCutoff))\n",
    "    return missing.loc[missing > missingCutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b7eed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeNan(data, imputeColList=False, missingColList=False):\n",
    "    # Function impute the nan with 0\n",
    "    if imputeColList:\n",
    "        for col in [y + s for s in ['_6','_7','_8'] for y in imputeColList]:\n",
    "            data[col].fillna(0, inplace=True)\n",
    "    else:    \n",
    "        for col in missingColList:\n",
    "            data[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7efe61d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 30 features having more than 50% missing values/entries\n"
     ]
    }
   ],
   "source": [
    "# Missing values per column expressed as % of total number of values\n",
    "high_missing_cols=getMissingValues(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54775200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_of_last_rech_data_6', 'date_of_last_rech_data_7',\n",
       "       'date_of_last_rech_data_8', 'total_rech_data_6', 'total_rech_data_7',\n",
       "       'total_rech_data_8', 'max_rech_data_6', 'max_rech_data_7',\n",
       "       'max_rech_data_8', 'count_rech_2g_6', 'count_rech_2g_7',\n",
       "       'count_rech_2g_8', 'count_rech_3g_6', 'count_rech_3g_7',\n",
       "       'count_rech_3g_8', 'av_rech_amt_data_6', 'av_rech_amt_data_7',\n",
       "       'av_rech_amt_data_8', 'arpu_3g_6', 'arpu_3g_7', 'arpu_3g_8',\n",
       "       'arpu_2g_6', 'arpu_2g_7', 'arpu_2g_8', 'night_pck_user_6',\n",
       "       'night_pck_user_7', 'night_pck_user_8', 'fb_user_6', 'fb_user_7',\n",
       "       'fb_user_8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_missing_cols.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "772a0c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.drop(high_missing_cols.index,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4f7a4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 159)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfff5eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 159)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b7c582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#date_vars = [\"date_of_last_rech_6\", \"date_of_last_rech_7\", \"date_of_last_rech_8\"]\n",
    "date_vars=[\"date_of_last_rech_data_6\", 'date_of_last_rech_data_7','date_of_last_rech_data_8',\"date_of_last_rech_6\", \"date_of_last_rech_7\", \"date_of_last_rech_8\"]\n",
    "\n",
    "data.drop(date_vars, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4556287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['night_pck_user_6', 'night_pck_user_7', 'night_pck_user_8', 'fb_user_6',\n",
       "       'fb_user_7', 'fb_user_8', 'churn_probability'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[data.nunique()==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbb6cfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 153)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67bdb83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b5e2370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 152)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "522844dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 108 features having more than 0% missing values/entries\n"
     ]
    }
   ],
   "source": [
    "missing_val_all=getMissingValues(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68e520f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_val_all.index[(missing_val_all<50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3a6da02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['onnet_mou_6', 'onnet_mou_7', 'onnet_mou_8', 'offnet_mou_6',\n",
       "       'offnet_mou_7', 'offnet_mou_8', 'roam_ic_mou_6', 'roam_ic_mou_7',\n",
       "       'roam_ic_mou_8', 'roam_og_mou_6', 'roam_og_mou_7', 'roam_og_mou_8',\n",
       "       'loc_og_t2t_mou_6', 'loc_og_t2t_mou_7', 'loc_og_t2t_mou_8',\n",
       "       'loc_og_t2m_mou_6', 'loc_og_t2m_mou_7', 'loc_og_t2m_mou_8',\n",
       "       'loc_og_t2f_mou_6', 'loc_og_t2f_mou_7', 'loc_og_t2f_mou_8',\n",
       "       'loc_og_t2c_mou_6', 'loc_og_t2c_mou_7', 'loc_og_t2c_mou_8',\n",
       "       'loc_og_mou_6', 'loc_og_mou_7', 'loc_og_mou_8', 'std_og_t2t_mou_6',\n",
       "       'std_og_t2t_mou_7', 'std_og_t2t_mou_8', 'std_og_t2m_mou_6',\n",
       "       'std_og_t2m_mou_7', 'std_og_t2m_mou_8', 'std_og_t2f_mou_6',\n",
       "       'std_og_t2f_mou_7', 'std_og_t2f_mou_8', 'std_og_mou_6', 'std_og_mou_7',\n",
       "       'std_og_mou_8', 'isd_og_mou_6', 'isd_og_mou_7', 'isd_og_mou_8',\n",
       "       'spl_og_mou_6', 'spl_og_mou_7', 'spl_og_mou_8', 'og_others_6',\n",
       "       'og_others_7', 'og_others_8', 'loc_ic_t2t_mou_6', 'loc_ic_t2t_mou_7',\n",
       "       'loc_ic_t2t_mou_8', 'loc_ic_t2m_mou_6', 'loc_ic_t2m_mou_7',\n",
       "       'loc_ic_t2m_mou_8', 'loc_ic_t2f_mou_6', 'loc_ic_t2f_mou_7',\n",
       "       'loc_ic_t2f_mou_8', 'loc_ic_mou_6', 'loc_ic_mou_7', 'loc_ic_mou_8',\n",
       "       'std_ic_t2t_mou_6', 'std_ic_t2t_mou_7', 'std_ic_t2t_mou_8',\n",
       "       'std_ic_t2m_mou_6', 'std_ic_t2m_mou_7', 'std_ic_t2m_mou_8',\n",
       "       'std_ic_t2f_mou_6', 'std_ic_t2f_mou_7', 'std_ic_t2f_mou_8',\n",
       "       'std_ic_mou_6', 'std_ic_mou_7', 'std_ic_mou_8', 'spl_ic_mou_6',\n",
       "       'spl_ic_mou_7', 'spl_ic_mou_8', 'isd_ic_mou_6', 'isd_ic_mou_7',\n",
       "       'isd_ic_mou_8', 'ic_others_6', 'ic_others_7', 'ic_others_8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_cols_low=missing_val_all.index[(missing_val_all<50)]\n",
    "missing_cols_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f34877a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_rech_data_6', 'total_rech_data_7', 'total_rech_data_8',\n",
       "       'max_rech_data_6', 'max_rech_data_7', 'max_rech_data_8',\n",
       "       'count_rech_2g_6', 'count_rech_2g_7', 'count_rech_2g_8',\n",
       "       'count_rech_3g_6', 'count_rech_3g_7', 'count_rech_3g_8',\n",
       "       'av_rech_amt_data_6', 'av_rech_amt_data_7', 'av_rech_amt_data_8',\n",
       "       'arpu_3g_6', 'arpu_3g_7', 'arpu_3g_8', 'arpu_2g_6', 'arpu_2g_7',\n",
       "       'arpu_2g_8', 'night_pck_user_6', 'night_pck_user_7', 'night_pck_user_8',\n",
       "       'fb_user_6', 'fb_user_7', 'fb_user_8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_cols_high=missing_val_all.index[(missing_val_all>=50)]\n",
    "missing_cols_high"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ed8c30",
   "metadata": {},
   "source": [
    "## Modelling Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec7e171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[data.columns[~data.columns.isin(['churn_probability'])]]\n",
    "Y = data['churn_probability']\n",
    "numeric_cols=X.columns[X.nunique()!=2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cbccad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_impute=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dacbbd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_cols=X.columns\n",
    "if zero_impute==0:\n",
    "    orig_cols=X.columns    \n",
    "    simple_imtr = SimpleImputer(strategy='median')\n",
    "    #simple_imtr = KNNImputer(n_neighbors=5)\n",
    "    X = pd.DataFrame(simple_imtr.fit_transform(X))\n",
    "    X.columns=orig_cols\n",
    "else :\n",
    "    X=X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1342f085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 151)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_columns=X.columns\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "X_std= pd.DataFrame(X_std)\n",
    "X_std.columns=orig_columns\n",
    "X_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f8707f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std,Y, train_size=0.7,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f66e6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['arpu_6', 'arpu_7', 'arpu_8', 'onnet_mou_6', 'onnet_mou_7',\n",
       "       'onnet_mou_8', 'offnet_mou_6', 'offnet_mou_7', 'offnet_mou_8',\n",
       "       'roam_ic_mou_6',\n",
       "       ...\n",
       "       'sachet_3g_6', 'sachet_3g_7', 'sachet_3g_8', 'fb_user_6', 'fb_user_7',\n",
       "       'fb_user_8', 'aon', 'aug_vbc_3g', 'jul_vbc_3g', 'jun_vbc_3g'],\n",
       "      dtype='object', length=151)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7e10ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size (48999, 151)\n",
      "Training dataset target size (48999,)\n",
      "Test dataset size (21000, 151)\n",
      "Test dataset target size (21000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training dataset size\",X_train.shape)\n",
    "print(\"Training dataset target size\",y_train.shape)\n",
    "print(\"Test dataset size\",X_test.shape)\n",
    "print(\"Test dataset target size\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4972160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imbalance, counts of label '1': 4977\n",
      "Data imbalance, counts of label '0': 44022 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Data imbalance, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Data imbalance, counts of label '0': {} \\n\".format(sum(y_train==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46aa758",
   "metadata": {},
   "source": [
    "### Using SMOTE to correct data imbalance\n",
    "## class weights giving better results - using class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe793161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48999, 151)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ea0e80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of label '1': 4977\n",
      "Counts of label '0': 44022\n",
      "8.845087402049428\n"
     ]
    }
   ],
   "source": [
    "#sm = SMOTE(random_state=42)\n",
    "#X_train_smote, y_train_smote= sm.fit_resample(X_train, y_train)\n",
    "\n",
    "#over = SMOTE(sampling_strategy=1,random_state=42)\n",
    "#under = RandomUnderSampler(sampling_strategy=1,random_state=42)\n",
    "\n",
    "#steps = [('o', over), ('u', under)]\n",
    "#pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "#X_train_smote, y_train_smote = pipeline.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "count_class_1 = y_train.value_counts()[0]\n",
    "count_class_2 = y_train.value_counts()[1]\n",
    "ratio = count_class_1/count_class_2\n",
    "\n",
    "\n",
    "print(\"Counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Counts of label '0': {}\".format(sum(y_train==0)))\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0082f4",
   "metadata": {},
   "source": [
    "## PCA Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ee8f080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA object with default parameter\n",
    "pca = PCA(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f122369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(random_state=42)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Doing PCA on the train data\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a8d419e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.44571589e-01  1.49149414e-01  1.42842994e-01 ...  1.13772229e-01\n",
      "   1.12413117e-01  1.08354382e-01]\n",
      " [-9.30100964e-02 -9.78321366e-02 -9.14667889e-02 ...  8.70320799e-02\n",
      "   8.88432527e-02  8.69537836e-02]\n",
      " [-4.93399031e-02 -6.41907129e-02 -5.57599281e-02 ...  4.70210603e-03\n",
      "   4.64914522e-03  5.41413945e-03]\n",
      " ...\n",
      " [-0.00000000e+00  1.59679783e-16 -2.70948812e-16 ...  3.35397544e-17\n",
      "   6.81040029e-18  2.86944773e-17]\n",
      " [-0.00000000e+00 -7.84696217e-17 -5.82074081e-17 ...  1.87690083e-17\n",
      "  -1.21073278e-17 -7.28609474e-18]\n",
      " [ 0.00000000e+00  1.19490215e-16  4.66255895e-17 ...  6.13140384e-17\n",
      "  -1.10393565e-16  4.97007597e-17]]\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "[1.25103373e-01 9.36493029e-02 6.32634418e-02 5.01445589e-02\n",
      " 3.72755761e-02 2.99437970e-02 2.71103102e-02 2.45392950e-02\n",
      " 2.20554678e-02 2.12574294e-02 2.07470455e-02 2.03350538e-02\n",
      " 1.97295880e-02 1.71930469e-02 1.66911323e-02 1.60831003e-02\n",
      " 1.48939201e-02 1.46644380e-02 1.43027306e-02 1.37770926e-02\n",
      " 1.27410912e-02 1.19552540e-02 1.14322982e-02 1.06112196e-02\n",
      " 1.05184065e-02 1.01452294e-02 9.78639146e-03 8.70079590e-03\n",
      " 8.48831353e-03 8.20613372e-03 7.83386562e-03 7.54667262e-03\n",
      " 7.28952306e-03 6.96740979e-03 6.79266823e-03 6.74067094e-03\n",
      " 6.63137394e-03 6.46801167e-03 6.12375976e-03 5.85196850e-03\n",
      " 5.69242781e-03 5.58759782e-03 5.46409939e-03 5.31908175e-03\n",
      " 5.04516229e-03 4.98719111e-03 4.84742561e-03 4.66062294e-03\n",
      " 4.47097126e-03 4.26995534e-03 4.14284155e-03 3.80656460e-03\n",
      " 3.79340011e-03 3.68283669e-03 3.51820309e-03 3.28814602e-03\n",
      " 3.20823992e-03 3.19686213e-03 3.13940817e-03 3.11791421e-03\n",
      " 3.00852567e-03 2.93541714e-03 2.88253171e-03 2.79385837e-03\n",
      " 2.57920899e-03 2.50294039e-03 2.44506471e-03 2.40633055e-03\n",
      " 2.32392999e-03 2.26922648e-03 2.20827449e-03 2.16890551e-03\n",
      " 2.13314449e-03 2.09676657e-03 2.07962695e-03 1.98148933e-03\n",
      " 1.95295507e-03 1.90205167e-03 1.83237101e-03 1.82418840e-03\n",
      " 1.80749323e-03 1.77802756e-03 1.73082311e-03 1.66288020e-03\n",
      " 1.59637504e-03 1.57324243e-03 1.55855292e-03 1.49362759e-03\n",
      " 1.43957157e-03 1.39792081e-03 1.29106092e-03 1.28138134e-03\n",
      " 1.22251147e-03 1.17633209e-03 1.13203879e-03 1.06788503e-03\n",
      " 9.92030975e-04 9.74153478e-04 9.36692872e-04 9.03241801e-04\n",
      " 8.16627872e-04 7.53184195e-04 7.00856038e-04 6.44994641e-04\n",
      " 6.06141241e-04 5.77382785e-04 5.17355502e-04 5.00143539e-04\n",
      " 4.37453791e-04 3.64723650e-04 3.15468206e-04 2.94858988e-04\n",
      " 2.80417310e-04 2.42084325e-04 1.95905410e-04 1.89893571e-04\n",
      " 1.60480609e-04 1.43654939e-04 4.94261465e-05 2.24224661e-05\n",
      " 1.01061430e-05 2.67665530e-06 7.93456858e-07 5.87874501e-07\n",
      " 1.18455892e-11 5.37784216e-12 5.20857229e-12 4.38273907e-12\n",
      " 2.74117162e-12 2.57591854e-12 2.32008332e-12 1.80227500e-12\n",
      " 1.72335031e-12 1.66228810e-12 1.10180852e-12 1.06293379e-12\n",
      " 1.01595167e-12 6.44135411e-13 5.53578265e-13 3.60617605e-13\n",
      " 2.58898515e-13 2.40521468e-13 2.46722901e-32 1.79106607e-32\n",
      " 1.54830530e-33 1.52173564e-33 1.49361649e-33 1.45036777e-33\n",
      " 1.41957428e-33 1.40543331e-33 1.20810274e-33]\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "[0.12510337 0.21875268 0.28201612 0.33216068 0.36943625 0.39938005\n",
      " 0.42649036 0.45102966 0.47308512 0.49434255 0.5150896  0.53542465\n",
      " 0.55515424 0.57234729 0.58903842 0.60512152 0.62001544 0.63467988\n",
      " 0.64898261 0.6627597  0.67550079 0.68745605 0.69888834 0.70949956\n",
      " 0.72001797 0.7301632  0.73994959 0.74865039 0.7571387  0.76534483\n",
      " 0.7731787  0.78072537 0.7880149  0.79498231 0.80177497 0.80851564\n",
      " 0.81514702 0.82161503 0.82773879 0.83359076 0.83928319 0.84487078\n",
      " 0.85033488 0.85565396 0.86069913 0.86568632 0.87053374 0.87519437\n",
      " 0.87966534 0.88393529 0.88807813 0.8918847  0.8956781  0.89936094\n",
      " 0.90287914 0.90616729 0.90937553 0.91257239 0.9157118  0.91882971\n",
      " 0.92183824 0.92477365 0.92765618 0.93045004 0.93302925 0.93553219\n",
      " 0.93797726 0.94038359 0.94270752 0.94497674 0.94718502 0.94935392\n",
      " 0.95148707 0.95358383 0.95566346 0.95764495 0.95959791 0.96149996\n",
      " 0.96333233 0.96515652 0.96696401 0.96874204 0.97047286 0.97213574\n",
      " 0.97373212 0.97530536 0.97686391 0.97835754 0.97979711 0.98119503\n",
      " 0.98248609 0.98376747 0.98498999 0.98616632 0.98729836 0.98836624\n",
      " 0.98935827 0.99033243 0.99126912 0.99217236 0.99298899 0.99374217\n",
      " 0.99444303 0.99508802 0.99569416 0.99627155 0.9967889  0.99728905\n",
      " 0.9977265  0.99809122 0.99840669 0.99870155 0.99898197 0.99922405\n",
      " 0.99941996 0.99960985 0.99977033 0.99991399 0.99996341 0.99998584\n",
      " 0.99999594 0.99999862 0.99999941 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(pca.components_)\n",
    "print('-'*80, '\\n');\n",
    "print(pca.explained_variance_ratio_)\n",
    "print('-'*80, '\\n');\n",
    "print(pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c21f92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Making the screeplot - plotting the cumulative variance against the number of components\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e699f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48999, 70)\n",
      "(21000, 70)\n"
     ]
    }
   ],
   "source": [
    "#pick the number of components explaining max variance\n",
    "pca_X= IncrementalPCA(n_components=70)\n",
    "\n",
    "df_train_pca_X = pca_X.fit_transform(X_train)\n",
    "print(df_train_pca_X.shape)\n",
    "df_test_pca_X = pca_X.transform(X_test)\n",
    "print(df_test_pca_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a54018",
   "metadata": {},
   "source": [
    "## Logistic Regression with PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e25b3d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run the model using the selected variables\n",
    "LR = LogisticRegression(class_weight='balanced')\n",
    "LR.fit(df_train_pca_X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b045285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Accuracy Score: 0.7851792893732525\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87     44022\n",
      "           1       0.30      0.85      0.45      4977\n",
      "\n",
      "    accuracy                           0.79     48999\n",
      "   macro avg       0.64      0.81      0.66     48999\n",
      "weighted avg       0.91      0.79      0.82     48999\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Confusion Matrix:\n",
      "[[34241  9781]\n",
      " [  745  4232]]\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "roc_auc_score: 0.81\n"
     ]
    }
   ],
   "source": [
    "#Predicted probabilities\n",
    "y_pred_train = LR.predict(df_train_pca_X)\n",
    "\n",
    "#Printing results\n",
    "print(\"Train data results\")\n",
    "print('-'*80, '\\n');\n",
    "print(\"Accuracy Score:\",accuracy_score(y_train,y_pred_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train,y_pred_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"roc_auc_score: {:2.2}\".format(metrics.roc_auc_score(y_train, y_pred_train)))\n",
    "y_pred_train_prob = LR.predict_proba(df_train_pca_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5429545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Accuracy Score: 0.7881904761904762\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87     18845\n",
      "           1       0.31      0.87      0.46      2155\n",
      "\n",
      "    accuracy                           0.79     21000\n",
      "   macro avg       0.65      0.83      0.66     21000\n",
      "weighted avg       0.91      0.79      0.83     21000\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Confusion Matrix:\n",
      "[[14670  4175]\n",
      " [  273  1882]]\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "roc_auc_score: 0.83\n"
     ]
    }
   ],
   "source": [
    "#Predicted probabilities\n",
    "y_pred_test = LR.predict(df_test_pca_X)\n",
    "\n",
    "#Printing results\n",
    "print(\"Test data results\");\n",
    "print('-'*80, '\\n');\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test,y_pred_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,y_pred_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"roc_auc_score: {:2.2}\".format(metrics.roc_auc_score(y_test, y_pred_test)))\n",
    "y_pred_test_prob = LR.predict_proba(df_test_pca_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9505f9",
   "metadata": {},
   "source": [
    "## Trying Random Forest without PCA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cdafc98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, n_jobs=-1,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, n_jobs=-1,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced_subsample', n_jobs=-1,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the random forest with default parameters.\n",
    "rfc = RandomForestClassifier( random_state=42,n_jobs=-1,\n",
    "                             class_weight='balanced_subsample',                             \n",
    "                            )\n",
    "\n",
    "#fit\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfe900d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Accuracy Score: 0.9999795914202331\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     44022\n",
      "           1       1.00      1.00      1.00      4977\n",
      "\n",
      "    accuracy                           1.00     48999\n",
      "   macro avg       1.00      1.00      1.00     48999\n",
      "weighted avg       1.00      1.00      1.00     48999\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Confusion Matrix:\n",
      "[[44022     0]\n",
      " [    1  4976]]\n"
     ]
    }
   ],
   "source": [
    "predictions_train = rfc.predict(X_train)\n",
    "print (\"Train data results\")\n",
    "print('-'*80, '\\n');\n",
    "print(\"Accuracy Score:\", accuracy_score(y_train, predictions_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, predictions_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cbeba904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Accuracy Score: 0.9408095238095238\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97     18845\n",
      "           1       0.79      0.57      0.67      2155\n",
      "\n",
      "    accuracy                           0.94     21000\n",
      "   macro avg       0.87      0.78      0.82     21000\n",
      "weighted avg       0.94      0.94      0.94     21000\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Confusion Matrix:\n",
      "[[18521   324]\n",
      " [  919  1236]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Test data results\")\n",
    "print('-'*80, '\\n');\n",
    "predictions_test = rfc.predict(X_test)\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, predictions_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a875ae74",
   "metadata": {},
   "source": [
    "### Random forest hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "236831f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;,\n",
       "                                              random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [10, 20, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 5, 10],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;,\n",
       "                                              random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [10, 20, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 5, 10],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestClassifier(class_weight='balanced_subsample',\n",
       "                                              random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': [10, 20, 30],\n",
       "                         'min_samples_leaf': [1, 2, 5, 10],\n",
       "                         'min_samples_split': [2, 5, 10]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': [10,20,30],\n",
    "    'min_samples_leaf': [1,2,5,10],\n",
    "    'min_samples_split': [2,5,10]\n",
    "}\n",
    "\n",
    "strat_cv = StratifiedKFold( n_splits=4, shuffle=True, random_state=42 )\n",
    "\n",
    "grid_search_rfc = GridSearchCV(\n",
    "                    estimator = RandomForestClassifier(class_weight='balanced_subsample', random_state=42),\n",
    "                    param_grid = params,\n",
    "                    scoring = 'accuracy',\n",
    "                    cv = strat_cv,\n",
    "                    n_jobs=-1, verbose=3\n",
    "                    )\n",
    "grid_search_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2fd3184a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=30,\n",
      "                       min_samples_leaf=2, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_rfc.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3bae54f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([17.22715604, 17.1388213 , 18.01765615, 18.51703471, 18.79124284,\n",
       "        18.23699522, 18.38741863, 18.61168754, 18.50608677, 18.93359143,\n",
       "        18.95743775, 18.83990574, 27.99906456, 28.19475245, 27.68229818,\n",
       "        28.49815291, 28.32124013, 28.12363917, 27.52687562, 27.86014563,\n",
       "        27.93362635, 27.29369777, 27.87387121, 28.0827865 , 30.93727493,\n",
       "        30.9539181 , 31.8207466 , 30.44875538, 30.70458239, 31.09217286,\n",
       "        29.56544501, 29.66168815, 29.70056349, 28.40527749, 28.22828692,\n",
       "        27.26944476]),\n",
       " 'std_fit_time': array([0.17789684, 0.15561313, 0.28644869, 0.30190462, 0.14014596,\n",
       "        0.11311484, 0.23338908, 0.32648203, 0.30443929, 0.24247561,\n",
       "        0.36625512, 0.19346684, 0.35380849, 0.4145956 , 0.49396442,\n",
       "        0.46390256, 0.34566864, 0.55100721, 0.1292802 , 0.25622568,\n",
       "        0.20598551, 0.49066099, 0.68600833, 0.71677832, 0.03791028,\n",
       "        0.4957785 , 0.68914813, 0.20519264, 0.44721941, 0.57622017,\n",
       "        0.33952694, 0.16420843, 0.20849638, 0.09432651, 0.4051927 ,\n",
       "        0.41980521]),\n",
       " 'mean_score_time': array([0.29487276, 0.29136407, 0.29550618, 0.28066641, 0.29648334,\n",
       "        0.28964204, 0.28533745, 0.29037863, 0.29192066, 0.28404021,\n",
       "        0.30662394, 0.28774357, 0.40679693, 0.4346711 , 0.40149325,\n",
       "        0.41302633, 0.42366868, 0.42726624, 0.40127003, 0.41902375,\n",
       "        0.3995533 , 0.41095209, 0.40104026, 0.40584964, 0.46207792,\n",
       "        0.45060301, 0.43455613, 0.44825774, 0.44435579, 0.4300127 ,\n",
       "        0.42235637, 0.4281767 , 0.41507512, 0.38729805, 0.29995507,\n",
       "        0.18668038]),\n",
       " 'std_score_time': array([0.00852709, 0.0055037 , 0.00427973, 0.00497856, 0.00413776,\n",
       "        0.00867314, 0.00265963, 0.01265415, 0.00263449, 0.01271903,\n",
       "        0.00890667, 0.00699668, 0.01103552, 0.01415919, 0.01209076,\n",
       "        0.00945642, 0.00556647, 0.00857163, 0.01438107, 0.0073291 ,\n",
       "        0.00366255, 0.01117378, 0.00626718, 0.01106124, 0.01142985,\n",
       "        0.01463727, 0.00280607, 0.00943091, 0.01430308, 0.00918525,\n",
       "        0.01189629, 0.0129808 , 0.00719318, 0.01741454, 0.04547042,\n",
       "        0.02863477]),\n",
       " 'param_max_depth': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 30, 30, 30, 30,\n",
       "                    30, 30, 30, 30, 30, 30, 30, 30],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 2, 2, 2, 5, 5, 5, 10, 10, 10, 1, 1, 1, 2, 2,\n",
       "                    2, 5, 5, 5, 10, 10, 10, 1, 1, 1, 2, 2, 2, 5, 5, 5, 10,\n",
       "                    10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5,\n",
       "                    10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10,\n",
       "                    2, 5, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 2},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 5},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 10},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 10, 'min_samples_split': 2},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 10, 'min_samples_split': 5},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 10, 'min_samples_split': 10},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 5, 'min_samples_split': 2},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 5, 'min_samples_split': 5},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 5, 'min_samples_split': 10},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 10, 'min_samples_split': 2},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 10, 'min_samples_split': 5},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 10, 'min_samples_split': 10},\n",
       "  {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2},\n",
       "  {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5},\n",
       "  {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10},\n",
       "  {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2},\n",
       "  {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5},\n",
       "  {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 10},\n",
       "  {'max_depth': 30, 'min_samples_leaf': 5, 'min_samples_split': 2},\n",
       "  {'max_depth': 30, 'min_samples_leaf': 5, 'min_samples_split': 5},\n",
       "  {'max_depth': 30, 'min_samples_leaf': 5, 'min_samples_split': 10},\n",
       "  {'max_depth': 30, 'min_samples_leaf': 10, 'min_samples_split': 2},\n",
       "  {'max_depth': 30, 'min_samples_leaf': 10, 'min_samples_split': 5},\n",
       "  {'max_depth': 30, 'min_samples_leaf': 10, 'min_samples_split': 10}],\n",
       " 'split0_test_score': array([0.92987755, 0.92922449, 0.92873469, 0.92914286, 0.92857143,\n",
       "        0.92963265, 0.92808163, 0.92808163, 0.92808163, 0.92530612,\n",
       "        0.92530612, 0.92530612, 0.9397551 , 0.93991837, 0.93869388,\n",
       "        0.94040816, 0.93934694, 0.93828571, 0.93632653, 0.93632653,\n",
       "        0.93632653, 0.93036735, 0.93036735, 0.93036735, 0.93942857,\n",
       "        0.93926531, 0.93959184, 0.93983673, 0.9395102 , 0.93853061,\n",
       "        0.936     , 0.936     , 0.936     , 0.93012245, 0.93012245,\n",
       "        0.93012245]),\n",
       " 'split1_test_score': array([0.93763265, 0.93697959, 0.9362449 , 0.93689796, 0.93657143,\n",
       "        0.93502041, 0.9355102 , 0.9355102 , 0.9355102 , 0.9315102 ,\n",
       "        0.9315102 , 0.9315102 , 0.9435102 , 0.94383673, 0.94293878,\n",
       "        0.9435102 , 0.944     , 0.94285714, 0.94179592, 0.94179592,\n",
       "        0.94179592, 0.93853061, 0.93853061, 0.93853061, 0.94220408,\n",
       "        0.94326531, 0.94334694, 0.94359184, 0.94367347, 0.944     ,\n",
       "        0.94269388, 0.94269388, 0.94269388, 0.93877551, 0.93877551,\n",
       "        0.93877551]),\n",
       " 'split2_test_score': array([0.93387755, 0.93289796, 0.93273469, 0.93404082, 0.932     ,\n",
       "        0.93232653, 0.93208163, 0.93208163, 0.93208163, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.93893878, 0.93983673, 0.93844898,\n",
       "        0.93893878, 0.9395102 , 0.93885714, 0.93697959, 0.93697959,\n",
       "        0.93697959, 0.93436735, 0.93436735, 0.93436735, 0.93902041,\n",
       "        0.93991837, 0.93918367, 0.93983673, 0.93991837, 0.93861224,\n",
       "        0.93771429, 0.93771429, 0.93771429, 0.93404082, 0.93404082,\n",
       "        0.93404082]),\n",
       " 'split3_test_score': array([0.93966854, 0.94048494, 0.93868887, 0.93983182, 0.93844395,\n",
       "        0.93926035, 0.93803576, 0.93803576, 0.93803576, 0.93591314,\n",
       "        0.93591314, 0.93591314, 0.94481182, 0.94440362, 0.94407707,\n",
       "        0.9445669 , 0.9445669 , 0.94375051, 0.94407707, 0.94407707,\n",
       "        0.94407707, 0.93966854, 0.93966854, 0.93966854, 0.9449751 ,\n",
       "        0.94448526, 0.94424035, 0.94505674, 0.9449751 , 0.94448526,\n",
       "        0.94342395, 0.94342395, 0.94342395, 0.93975018, 0.93975018,\n",
       "        0.93975018]),\n",
       " 'mean_test_score': array([0.93526407, 0.93489674, 0.93410079, 0.93497836, 0.9338967 ,\n",
       "        0.93405998, 0.93342731, 0.93342731, 0.93342731, 0.93032522,\n",
       "        0.93032522, 0.93032522, 0.94175398, 0.94199887, 0.94103968,\n",
       "        0.94185601, 0.94185601, 0.94093763, 0.93979478, 0.93979478,\n",
       "        0.93979478, 0.93573346, 0.93573346, 0.93573346, 0.94140704,\n",
       "        0.94173356, 0.9415907 , 0.94208051, 0.94201929, 0.94140703,\n",
       "        0.93995803, 0.93995803, 0.93995803, 0.93567224, 0.93567224,\n",
       "        0.93567224]),\n",
       " 'std_test_score': array([0.00373987, 0.00423485, 0.00375196, 0.00394249, 0.00386612,\n",
       "        0.00355571, 0.00374043, 0.00374043, 0.00374043, 0.0039018 ,\n",
       "        0.0039018 , 0.0039018 , 0.00246757, 0.00213096, 0.00250234,\n",
       "        0.00227441, 0.00243638, 0.00239572, 0.00325179, 0.00325179,\n",
       "        0.00325179, 0.00367323, 0.00367323, 0.00367323, 0.0023967 ,\n",
       "        0.00219689, 0.00223015, 0.00230278, 0.00235492, 0.00284093,\n",
       "        0.00317009, 0.00317009, 0.00317009, 0.00386399, 0.00386399,\n",
       "        0.00386399]),\n",
       " 'rank_test_score': array([25, 27, 28, 26, 30, 29, 31, 31, 31, 34, 34, 34,  6,  3, 11,  4,  4,\n",
       "        12, 16, 16, 16, 19, 19, 19,  9,  7,  8,  1,  2, 10, 13, 13, 13, 22,\n",
       "        22, 22])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rfc.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5905b291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.942080511362027"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rfc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e9f34ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "deaf9612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, max_depth=30,\n",
       "                       min_samples_leaf=2, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, max_depth=30,\n",
       "                       min_samples_leaf=2, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced_subsample', max_depth=30,\n",
       "                       min_samples_leaf=2, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_best = RandomForestClassifier( random_state=42,n_jobs=-1 ,\n",
    "                                  max_depth=30 ,\n",
    "                                  min_samples_leaf=2,\n",
    "                                  min_samples_split=2,\n",
    "                                  class_weight='balanced_subsample'                           \n",
    "                           )\n",
    "rfc_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8c81fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Accuracy Score: 0.9893875385211943\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     44022\n",
      "           1       0.91      1.00      0.95      4977\n",
      "\n",
      "    accuracy                           0.99     48999\n",
      "   macro avg       0.95      0.99      0.97     48999\n",
      "weighted avg       0.99      0.99      0.99     48999\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Confusion Matrix:\n",
      "[[43504   518]\n",
      " [    2  4975]]\n"
     ]
    }
   ],
   "source": [
    "predictions_rfc_train = rfc_best.predict(X_train)\n",
    "print (\"Train data results\")\n",
    "print('-'*80, '\\n');\n",
    "print(\"Accuracy Score:\", accuracy_score(y_train, predictions_rfc_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, predictions_rfc_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, predictions_rfc_train))\n",
    "predictions_rfc_train_prob = rfc_best.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "db467eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Accuracy Score: 0.9418571428571428\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     18845\n",
      "           1       0.76      0.63      0.69      2155\n",
      "\n",
      "    accuracy                           0.94     21000\n",
      "   macro avg       0.86      0.80      0.83     21000\n",
      "weighted avg       0.94      0.94      0.94     21000\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Confusion Matrix:\n",
      "[[18422   423]\n",
      " [  798  1357]]\n",
      "roc_auc_score: 0.8\n"
     ]
    }
   ],
   "source": [
    "print (\"Test data results\")\n",
    "print('-'*80, '\\n');\n",
    "predictions_rfc_test = rfc_best.predict(X_test)\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, predictions_rfc_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions_rfc_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_rfc_test))\n",
    "print(\"roc_auc_score: {:2.2}\".format(metrics.roc_auc_score(y_test, predictions_rfc_test)))\n",
    "predictions_rfc_test_prob = rfc_best.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f80b8691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colName</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067259</td>\n",
       "      <td>loc_ic_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061166</td>\n",
       "      <td>total_ic_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058301</td>\n",
       "      <td>loc_ic_t2m_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.047044</td>\n",
       "      <td>loc_og_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044673</td>\n",
       "      <td>loc_ic_t2t_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.041051</td>\n",
       "      <td>total_og_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.033508</td>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.032652</td>\n",
       "      <td>loc_og_t2m_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.027360</td>\n",
       "      <td>loc_og_t2t_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.027324</td>\n",
       "      <td>roam_og_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.027105</td>\n",
       "      <td>total_rech_amt_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.022763</td>\n",
       "      <td>arpu_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.020419</td>\n",
       "      <td>roam_ic_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.020200</td>\n",
       "      <td>max_rech_amt_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.020045</td>\n",
       "      <td>std_ic_mou_8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     colName               value\n",
       "0   0.067259        loc_ic_mou_8\n",
       "1   0.061166      total_ic_mou_8\n",
       "2   0.058301    loc_ic_t2m_mou_8\n",
       "3   0.047044        loc_og_mou_8\n",
       "4   0.044673    loc_ic_t2t_mou_8\n",
       "5   0.041051      total_og_mou_8\n",
       "6   0.033508  last_day_rch_amt_8\n",
       "7   0.032652    loc_og_t2m_mou_8\n",
       "8   0.027360    loc_og_t2t_mou_8\n",
       "9   0.027324       roam_og_mou_8\n",
       "10  0.027105    total_rech_amt_8\n",
       "11  0.022763              arpu_8\n",
       "12  0.020419       roam_ic_mou_8\n",
       "13  0.020200      max_rech_amt_8\n",
       "14  0.020045        std_ic_mou_8"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = rfc_best.feature_importances_\n",
    "col_names =  X.columns\n",
    "\n",
    "RF_feature_importance = pd.DataFrame(sorted(zip(importances, list(col_names)), reverse=True),columns=['colName','value'])\n",
    "RF_feature_importance.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c6ecda",
   "metadata": {},
   "source": [
    "## Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "76124e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada=AdaBoostClassifier()\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a32f06ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Accuracy Score: 0.9399375497459131\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     44022\n",
      "           1       0.75      0.61      0.67      4977\n",
      "\n",
      "    accuracy                           0.94     48999\n",
      "   macro avg       0.86      0.79      0.82     48999\n",
      "weighted avg       0.94      0.94      0.94     48999\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Confusion Matrix:\n",
      "[[43039   983]\n",
      " [ 1960  3017]]\n"
     ]
    }
   ],
   "source": [
    "predictions_ada_train = ada.predict(X_train)\n",
    "print (\"Train data results\")\n",
    "print('-'*80, '\\n');\n",
    "print(\"Accuracy Score:\", accuracy_score(y_train, predictions_ada_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, predictions_ada_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, predictions_ada_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f891aa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Accuracy Score: 0.939047619047619\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     18845\n",
      "           1       0.75      0.61      0.67      2155\n",
      "\n",
      "    accuracy                           0.94     21000\n",
      "   macro avg       0.85      0.79      0.82     21000\n",
      "weighted avg       0.94      0.94      0.94     21000\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Confusion Matrix:\n",
      "[[18402   443]\n",
      " [  837  1318]]\n",
      "roc_auc_score: 0.79\n"
     ]
    }
   ],
   "source": [
    "print (\"Test data results\")\n",
    "print('-'*80, '\\n');\n",
    "predictions_ada_test = ada.predict(X_test)\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, predictions_ada_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions_ada_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_ada_test))\n",
    "print(\"roc_auc_score: {:2.2}\".format(metrics.roc_auc_score(y_test, predictions_ada_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc4acf",
   "metadata": {},
   "source": [
    "## GBM Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "05a14726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\sukum\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: wheel in c:\\users\\sukum\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\sukum\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (1.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\sukum\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (1.23.3)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\sukum\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (1.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sukum\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\sukum\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5010cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5329b718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4, estimator=LGBMClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [5, 10, 15, 20, 25, 30],\n",
       "                         &#x27;n_estimators&#x27;: [10, 15, 20, 25, 30]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4, estimator=LGBMClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [5, 10, 15, 20, 25, 30],\n",
       "                         &#x27;n_estimators&#x27;: [10, 15, 20, 25, 30]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4, estimator=LGBMClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_depth': [5, 10, 15, 20, 25, 30],\n",
       "                         'n_estimators': [10, 15, 20, 25, 30]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': [5,10,15,20,25,30],\n",
    "   'n_estimators':[10,15,20,25,30]\n",
    "}\n",
    "\n",
    "gbmc =  lgb.LGBMClassifier(random_state=42)\n",
    "grid_search_gbm = GridSearchCV(estimator=gbmc,\n",
    "                           param_grid=params,\n",
    "                           cv = 4,\n",
    "                           n_jobs=-1, verbose=3, scoring=\"accuracy\")\n",
    "grid_search_gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "60a0126d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'n_estimators': 30}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_gbm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cdcf2158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(max_depth=10, n_estimators=30, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(max_depth=10, n_estimators=30, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(max_depth=10, n_estimators=30, random_state=42)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm=lgb.LGBMClassifier(random_state=42,max_depth=10,n_estimators=30)\n",
    "gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fea7a89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Accuracy Score: 0.9426666666666667\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     18845\n",
      "           1       0.76      0.65      0.70      2155\n",
      "\n",
      "    accuracy                           0.94     21000\n",
      "   macro avg       0.86      0.81      0.83     21000\n",
      "weighted avg       0.94      0.94      0.94     21000\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Confusion Matrix:\n",
      "[[18406   439]\n",
      " [  765  1390]]\n",
      "roc_auc_score: 0.81\n"
     ]
    }
   ],
   "source": [
    "print (\"Test data results\")\n",
    "print('-'*80, '\\n');\n",
    "predictions_gbm_test = gbm.predict(X_test)\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, predictions_gbm_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions_gbm_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_gbm_test))\n",
    "print(\"roc_auc_score: {:2.2}\".format(metrics.roc_auc_score(y_test, predictions_gbm_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "28c658fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colName</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>loc_ic_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>aon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>roam_og_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>spl_ic_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>total_ic_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>total_rech_num_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26</td>\n",
       "      <td>total_ic_mou_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>total_rech_amt_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23</td>\n",
       "      <td>loc_ic_mou_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>std_og_mou_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>av_rech_amt_data_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>arpu_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18</td>\n",
       "      <td>total_rech_num_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17</td>\n",
       "      <td>total_ic_mou_6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    colName               value\n",
       "0        52  last_day_rch_amt_8\n",
       "1        45        loc_ic_mou_8\n",
       "2        40                 aon\n",
       "3        36       roam_og_mou_8\n",
       "4        35        spl_ic_mou_8\n",
       "5        30      total_ic_mou_8\n",
       "6        26    total_rech_num_7\n",
       "7        26      total_ic_mou_7\n",
       "8        23    total_rech_amt_8\n",
       "9        23        loc_ic_mou_7\n",
       "10       20        std_og_mou_7\n",
       "11       20  av_rech_amt_data_8\n",
       "12       20              arpu_7\n",
       "13       18    total_rech_num_8\n",
       "14       17      total_ic_mou_6"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = gbm.feature_importances_\n",
    "col_names =  X.columns\n",
    "\n",
    "RF_feature_importance = pd.DataFrame(sorted(zip(importances, list(col_names)), reverse=True),columns=['colName','value'])\n",
    "RF_feature_importance.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36720e77",
   "metadata": {},
   "source": [
    "## Trying with XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d8e7e530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Running the random forest with default parameters.\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "#fit\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "330e21ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "accuracy score: 0.9781628196493806\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     44022\n",
      "           1       0.91      0.87      0.89      4977\n",
      "\n",
      "    accuracy                           0.98     48999\n",
      "   macro avg       0.95      0.93      0.94     48999\n",
      "weighted avg       0.98      0.98      0.98     48999\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "confusion matrix:\n",
      "[[43599   423]\n",
      " [  647  4330]]\n"
     ]
    }
   ],
   "source": [
    "predictions_train = xgb.predict(X_train)\n",
    "print (\"Train data results\")\n",
    "print('-'*80, '\\n');\n",
    "print(\"accuracy score:\", accuracy_score(y_train, predictions_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"classification report:\")\n",
    "print(classification_report(y_train, predictions_train))\n",
    "print('-'*80, '\\n');\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_train, predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3112b3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "accuracy score: 0.9407142857142857\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     18845\n",
      "           1       0.75      0.64      0.69      2155\n",
      "\n",
      "    accuracy                           0.94     21000\n",
      "   macro avg       0.85      0.81      0.83     21000\n",
      "weighted avg       0.94      0.94      0.94     21000\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "confusion matrix:\n",
      "[[18382   463]\n",
      " [  782  1373]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Test data results\")\n",
    "print('-'*80, '\\n');\n",
    "predictions_test = xgb.predict(X_test)\n",
    "print(\"accuracy score:\", accuracy_score(y_test, predictions_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"classification report:\")\n",
    "print(classification_report(y_test, predictions_test))\n",
    "print('-'*80, '\\n');\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e1d5de6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 9 candidates, totalling 36 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=42, reg_alpha=None,\n",
       "                                     reg_lambda=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 150]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=42, reg_alpha=None,\n",
       "                                     reg_lambda=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 150]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=42,\n",
       "              reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=42,\n",
       "              reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=42, reg_alpha=None,\n",
       "                                     reg_lambda=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': [3, 4, 5],\n",
       "                         'n_estimators': [50, 100, 150]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': [3,4,5],\n",
    "   'n_estimators':[50,100,150]\n",
    "}\n",
    "\n",
    "xgbc =  XGBClassifier(random_state=42,scale_pos_weight=1)\n",
    "grid_search_xgb = GridSearchCV(estimator=xgbc,\n",
    "                           param_grid=params,\n",
    "                           cv = 4,\n",
    "                           n_jobs=-1, verbose=3, scoring=\"accuracy\")\n",
    "grid_search_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "742530d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'n_estimators': 50}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ac1efbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=50,\n",
       "              n_jobs=-1, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=50,\n",
       "              n_jobs=-1, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=50,\n",
       "              n_jobs=-1, num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Running the random forest with default parameters.\n",
    "xgb_best = XGBClassifier(random_state=42,max_depth = 3,n_estimators=50,n_jobs=-1)\n",
    "\n",
    "#fit\n",
    "xgb_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6e43d669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colName</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.400400</td>\n",
       "      <td>total_ic_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094469</td>\n",
       "      <td>loc_ic_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060382</td>\n",
       "      <td>fb_user_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022077</td>\n",
       "      <td>roam_og_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019224</td>\n",
       "      <td>arpu_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.016366</td>\n",
       "      <td>offnet_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.013953</td>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.013541</td>\n",
       "      <td>loc_ic_mou_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.012933</td>\n",
       "      <td>loc_og_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.012478</td>\n",
       "      <td>av_rech_amt_data_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.010959</td>\n",
       "      <td>std_og_mou_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010674</td>\n",
       "      <td>max_rech_amt_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.010412</td>\n",
       "      <td>spl_ic_mou_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010231</td>\n",
       "      <td>loc_ic_t2f_mou_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.010032</td>\n",
       "      <td>total_ic_mou_6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     colName               value\n",
       "0   0.400400      total_ic_mou_8\n",
       "1   0.094469        loc_ic_mou_8\n",
       "2   0.060382           fb_user_8\n",
       "3   0.022077       roam_og_mou_8\n",
       "4   0.019224              arpu_8\n",
       "5   0.016366        offnet_mou_8\n",
       "6   0.013953  last_day_rch_amt_8\n",
       "7   0.013541        loc_ic_mou_7\n",
       "8   0.012933        loc_og_mou_8\n",
       "9   0.012478  av_rech_amt_data_8\n",
       "10  0.010959        std_og_mou_7\n",
       "11  0.010674      max_rech_amt_7\n",
       "12  0.010412        spl_ic_mou_8\n",
       "13  0.010231    loc_ic_t2f_mou_6\n",
       "14  0.010032      total_ic_mou_6"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = xgb_best.feature_importances_\n",
    "col_names =  X.columns\n",
    "\n",
    "RF_feature_importance = pd.DataFrame(sorted(zip(importances, list(col_names)), reverse=True),columns=['colName','value'])\n",
    "RF_feature_importance.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "24d1e49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "accuracy score: 0.9438968142206984\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     44022\n",
      "           1       0.77      0.64      0.70      4977\n",
      "\n",
      "    accuracy                           0.94     48999\n",
      "   macro avg       0.86      0.81      0.83     48999\n",
      "weighted avg       0.94      0.94      0.94     48999\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "confusion matrix:\n",
      "[[43047   975]\n",
      " [ 1774  3203]]\n"
     ]
    }
   ],
   "source": [
    "predictions_train_xgb = xgb_best.predict(X_train)\n",
    "print (\"Train data results\")\n",
    "print('-'*80, '\\n');\n",
    "print(\"accuracy score:\", accuracy_score(y_train, predictions_train_xgb))\n",
    "print('-'*80, '\\n');\n",
    "print(\"classification report:\")\n",
    "print(classification_report(y_train, predictions_train_xgb))\n",
    "print('-'*80, '\\n');\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_train, predictions_train_xgb))\n",
    "predictions_train_xgb_prob=xgb_best.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9b7aaa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data results\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "accuracy score: 0.9428095238095238\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     18845\n",
      "           1       0.76      0.64      0.70      2155\n",
      "\n",
      "    accuracy                           0.94     21000\n",
      "   macro avg       0.86      0.81      0.83     21000\n",
      "weighted avg       0.94      0.94      0.94     21000\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "confusion matrix:\n",
      "[[18412   433]\n",
      " [  768  1387]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Test data results\")\n",
    "print('-'*80, '\\n');\n",
    "predictions_test_xgb = xgb_best.predict(X_test)\n",
    "print(\"accuracy score:\", accuracy_score(y_test, predictions_test_xgb))\n",
    "print('-'*80, '\\n');\n",
    "print(\"classification report:\")\n",
    "print(classification_report(y_test, predictions_test_xgb))\n",
    "print('-'*80, '\\n');\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_test_xgb))\n",
    "predictions_test_xgb_prob=xgb_best.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d19a55",
   "metadata": {},
   "source": [
    "### Evaluating Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6d279656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000, 151)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3f36e125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Shape:  (30000, 171)\n",
      "-------------------------------------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>date_of_last_rech_data_6</th>\n",
       "      <th>date_of_last_rech_data_7</th>\n",
       "      <th>date_of_last_rech_data_8</th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <th>count_rech_3g_8</th>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <th>av_rech_amt_data_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <th>arpu_3g_7</th>\n",
       "      <th>arpu_3g_8</th>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <th>night_pck_user_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69999</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>91.882</td>\n",
       "      <td>65.330</td>\n",
       "      <td>64.445</td>\n",
       "      <td>31.78</td>\n",
       "      <td>20.23</td>\n",
       "      <td>23.11</td>\n",
       "      <td>60.16</td>\n",
       "      <td>32.16</td>\n",
       "      <td>34.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.88</td>\n",
       "      <td>20.23</td>\n",
       "      <td>21.06</td>\n",
       "      <td>18.13</td>\n",
       "      <td>10.89</td>\n",
       "      <td>8.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>43.01</td>\n",
       "      <td>44.71</td>\n",
       "      <td>29.43</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.05</td>\n",
       "      <td>42.03</td>\n",
       "      <td>7.68</td>\n",
       "      <td>26.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.93</td>\n",
       "      <td>7.68</td>\n",
       "      <td>28.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.94</td>\n",
       "      <td>52.39</td>\n",
       "      <td>57.94</td>\n",
       "      <td>30.33</td>\n",
       "      <td>37.56</td>\n",
       "      <td>21.98</td>\n",
       "      <td>10.21</td>\n",
       "      <td>4.59</td>\n",
       "      <td>9.53</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.81</td>\n",
       "      <td>42.16</td>\n",
       "      <td>31.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.04</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.04</td>\n",
       "      <td>4.34</td>\n",
       "      <td>41.73</td>\n",
       "      <td>43.56</td>\n",
       "      <td>36.26</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>6/21/2014</td>\n",
       "      <td>7/26/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1692</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70000</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>414.168</td>\n",
       "      <td>515.568</td>\n",
       "      <td>360.868</td>\n",
       "      <td>75.51</td>\n",
       "      <td>41.21</td>\n",
       "      <td>19.84</td>\n",
       "      <td>474.34</td>\n",
       "      <td>621.84</td>\n",
       "      <td>394.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75.51</td>\n",
       "      <td>41.21</td>\n",
       "      <td>19.84</td>\n",
       "      <td>473.61</td>\n",
       "      <td>598.08</td>\n",
       "      <td>377.26</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>549.86</td>\n",
       "      <td>639.29</td>\n",
       "      <td>397.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.76</td>\n",
       "      <td>17.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.76</td>\n",
       "      <td>17.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>549.86</td>\n",
       "      <td>663.06</td>\n",
       "      <td>415.59</td>\n",
       "      <td>19.99</td>\n",
       "      <td>26.95</td>\n",
       "      <td>2.61</td>\n",
       "      <td>160.19</td>\n",
       "      <td>122.29</td>\n",
       "      <td>184.81</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>181.69</td>\n",
       "      <td>149.24</td>\n",
       "      <td>187.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>296.33</td>\n",
       "      <td>339.64</td>\n",
       "      <td>281.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>114.63</td>\n",
       "      <td>177.88</td>\n",
       "      <td>94.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>6/19/2014</td>\n",
       "      <td>7/16/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2533</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70001</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>329.844</td>\n",
       "      <td>434.884</td>\n",
       "      <td>746.239</td>\n",
       "      <td>7.54</td>\n",
       "      <td>7.86</td>\n",
       "      <td>8.40</td>\n",
       "      <td>16.98</td>\n",
       "      <td>45.81</td>\n",
       "      <td>45.04</td>\n",
       "      <td>22.81</td>\n",
       "      <td>103.38</td>\n",
       "      <td>26.08</td>\n",
       "      <td>24.53</td>\n",
       "      <td>53.68</td>\n",
       "      <td>54.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>6/29/2014</td>\n",
       "      <td>7/27/2014</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277</td>\n",
       "      <td>525.61</td>\n",
       "      <td>758.41</td>\n",
       "      <td>241.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70002</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>43.550</td>\n",
       "      <td>171.390</td>\n",
       "      <td>24.400</td>\n",
       "      <td>5.31</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.04</td>\n",
       "      <td>205.01</td>\n",
       "      <td>24.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.94</td>\n",
       "      <td>98.61</td>\n",
       "      <td>20.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.26</td>\n",
       "      <td>98.61</td>\n",
       "      <td>22.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.09</td>\n",
       "      <td>94.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.09</td>\n",
       "      <td>96.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.03</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.36</td>\n",
       "      <td>207.18</td>\n",
       "      <td>24.01</td>\n",
       "      <td>58.11</td>\n",
       "      <td>54.64</td>\n",
       "      <td>23.04</td>\n",
       "      <td>487.94</td>\n",
       "      <td>449.83</td>\n",
       "      <td>506.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.64</td>\n",
       "      <td>546.06</td>\n",
       "      <td>504.86</td>\n",
       "      <td>531.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.63</td>\n",
       "      <td>11.88</td>\n",
       "      <td>8.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.63</td>\n",
       "      <td>16.14</td>\n",
       "      <td>8.83</td>\n",
       "      <td>555.69</td>\n",
       "      <td>522.44</td>\n",
       "      <td>549.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.43</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/30/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70003</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>306.854</td>\n",
       "      <td>406.289</td>\n",
       "      <td>413.329</td>\n",
       "      <td>450.93</td>\n",
       "      <td>609.03</td>\n",
       "      <td>700.68</td>\n",
       "      <td>60.94</td>\n",
       "      <td>23.84</td>\n",
       "      <td>74.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.78</td>\n",
       "      <td>14.56</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.66</td>\n",
       "      <td>10.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.84</td>\n",
       "      <td>3.44</td>\n",
       "      <td>25.51</td>\n",
       "      <td>450.48</td>\n",
       "      <td>608.24</td>\n",
       "      <td>686.11</td>\n",
       "      <td>58.54</td>\n",
       "      <td>21.18</td>\n",
       "      <td>63.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>509.03</td>\n",
       "      <td>629.43</td>\n",
       "      <td>749.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>5.39</td>\n",
       "      <td>4.96</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>514.79</td>\n",
       "      <td>638.28</td>\n",
       "      <td>779.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>9.91</td>\n",
       "      <td>10.13</td>\n",
       "      <td>9.23</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.13</td>\n",
       "      <td>9.59</td>\n",
       "      <td>17.61</td>\n",
       "      <td>29.71</td>\n",
       "      <td>92.36</td>\n",
       "      <td>107.39</td>\n",
       "      <td>13.88</td>\n",
       "      <td>13.96</td>\n",
       "      <td>32.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.59</td>\n",
       "      <td>106.33</td>\n",
       "      <td>141.48</td>\n",
       "      <td>53.73</td>\n",
       "      <td>115.93</td>\n",
       "      <td>159.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>356</td>\n",
       "      <td>490</td>\n",
       "      <td>546</td>\n",
       "      <td>90</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>6/29/2014</td>\n",
       "      <td>7/29/2014</td>\n",
       "      <td>8/30/2014</td>\n",
       "      <td>50</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>462</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0  69999        109             0.0             0.0             0.0   \n",
       "1  70000        109             0.0             0.0             0.0   \n",
       "2  70001        109             0.0             0.0             0.0   \n",
       "3  70002        109             0.0             0.0             0.0   \n",
       "4  70003        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8   arpu_6  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   91.882   \n",
       "1            6/30/2014            7/31/2014            8/31/2014  414.168   \n",
       "2            6/30/2014            7/31/2014            8/31/2014  329.844   \n",
       "3            6/30/2014            7/31/2014            8/31/2014   43.550   \n",
       "4            6/30/2014            7/31/2014            8/31/2014  306.854   \n",
       "\n",
       "    arpu_7   arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  offnet_mou_6  \\\n",
       "0   65.330   64.445        31.78        20.23        23.11         60.16   \n",
       "1  515.568  360.868        75.51        41.21        19.84        474.34   \n",
       "2  434.884  746.239         7.54         7.86         8.40         16.98   \n",
       "3  171.390   24.400         5.31         2.16         0.00         40.04   \n",
       "4  406.289  413.329       450.93       609.03       700.68         60.94   \n",
       "\n",
       "   offnet_mou_7  offnet_mou_8  roam_ic_mou_6  roam_ic_mou_7  roam_ic_mou_8  \\\n",
       "0         32.16         34.83           0.00           0.00           0.00   \n",
       "1        621.84        394.94           0.00           0.00           0.00   \n",
       "2         45.81         45.04          22.81         103.38          26.08   \n",
       "3        205.01         24.01           0.00           0.00           0.00   \n",
       "4         23.84         74.16           0.00           0.00           0.00   \n",
       "\n",
       "   roam_og_mou_6  roam_og_mou_7  roam_og_mou_8  loc_og_t2t_mou_6  \\\n",
       "0           0.00           0.00           0.00             24.88   \n",
       "1           0.00           0.00           0.00             75.51   \n",
       "2          24.53          53.68          54.44              0.00   \n",
       "3           0.00           0.00           0.00              5.31   \n",
       "4           0.00           0.00           0.00              0.45   \n",
       "\n",
       "   loc_og_t2t_mou_7  loc_og_t2t_mou_8  loc_og_t2m_mou_6  loc_og_t2m_mou_7  \\\n",
       "0             20.23             21.06             18.13             10.89   \n",
       "1             41.21             19.84            473.61            598.08   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3              0.00              0.00              2.94             98.61   \n",
       "4              0.78             14.56              2.39              2.66   \n",
       "\n",
       "   loc_og_t2m_mou_8  loc_og_t2f_mou_6  loc_og_t2f_mou_7  loc_og_t2f_mou_8  \\\n",
       "0              8.36              0.00             13.58              0.00   \n",
       "1            377.26              0.73              0.00              0.00   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3             20.51              0.00              0.00              2.35   \n",
       "4             10.94              0.00              0.00              0.00   \n",
       "\n",
       "   loc_og_t2c_mou_6  loc_og_t2c_mou_7  loc_og_t2c_mou_8  loc_og_mou_6  \\\n",
       "0               0.0              0.00              0.03         43.01   \n",
       "1               0.0              0.00              0.00        549.86   \n",
       "2               0.0              0.00              0.00          0.00   \n",
       "3               0.0              6.18              0.00          8.26   \n",
       "4               0.0              0.00              0.00          2.84   \n",
       "\n",
       "   loc_og_mou_7  loc_og_mou_8  std_og_t2t_mou_6  std_og_t2t_mou_7  \\\n",
       "0         44.71         29.43              6.90              0.00   \n",
       "1        639.29        397.11              0.00              0.00   \n",
       "2          0.00          0.00              0.00              0.00   \n",
       "3         98.61         22.86              0.00              2.16   \n",
       "4          3.44         25.51            450.48            608.24   \n",
       "\n",
       "   std_og_t2t_mou_8  std_og_t2m_mou_6  std_og_t2m_mou_7  std_og_t2m_mou_8  \\\n",
       "0              2.05             42.03              7.68             26.43   \n",
       "1              0.00              0.00             23.76             17.68   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3              0.00             37.09             94.36              0.00   \n",
       "4            686.11             58.54             21.18             63.18   \n",
       "\n",
       "   std_og_t2f_mou_6  std_og_t2f_mou_7  std_og_t2f_mou_8  std_og_t2c_mou_6  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   std_og_t2c_mou_7  std_og_t2c_mou_8  std_og_mou_6  std_og_mou_7  \\\n",
       "0               0.0               0.0         48.93          7.68   \n",
       "1               0.0               0.0          0.00         23.76   \n",
       "2               0.0               0.0          0.00          0.00   \n",
       "3               0.0               0.0         37.09         96.53   \n",
       "4               0.0               0.0        509.03        629.43   \n",
       "\n",
       "   std_og_mou_8  isd_og_mou_6  isd_og_mou_7  isd_og_mou_8  spl_og_mou_6  \\\n",
       "0         28.48           0.0           0.0           0.0          0.00   \n",
       "1         17.68           0.0           0.0           0.8          0.00   \n",
       "2          0.00           0.0           0.0           0.0          0.00   \n",
       "3          0.00           0.0           0.0           0.0          0.00   \n",
       "4        749.29           0.0           0.0           0.0          0.71   \n",
       "\n",
       "   spl_og_mou_7  spl_og_mou_8  og_others_6  og_others_7  og_others_8  \\\n",
       "0          0.00          0.03          0.0          0.0          0.0   \n",
       "1          0.00          0.00          0.0          0.0          0.0   \n",
       "2          0.00          0.00          0.0          0.0          0.0   \n",
       "3         12.03          1.15          0.0          0.0          0.0   \n",
       "4          5.39          4.96          2.2          0.0          0.0   \n",
       "\n",
       "   total_og_mou_6  total_og_mou_7  total_og_mou_8  loc_ic_t2t_mou_6  \\\n",
       "0           91.94           52.39           57.94             30.33   \n",
       "1          549.86          663.06          415.59             19.99   \n",
       "2            0.00            0.00            0.00              0.00   \n",
       "3           45.36          207.18           24.01             58.11   \n",
       "4          514.79          638.28          779.78              0.00   \n",
       "\n",
       "   loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  \\\n",
       "0             37.56             21.98             10.21              4.59   \n",
       "1             26.95              2.61            160.19            122.29   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3             54.64             23.04            487.94            449.83   \n",
       "4              0.36              9.91             10.13              9.23   \n",
       "\n",
       "   loc_ic_t2m_mou_8  loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  \\\n",
       "0              9.53              0.26              0.00              0.00   \n",
       "1            184.81              1.49              0.00              0.00   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3            506.94              0.00              0.38              1.64   \n",
       "4              7.69              0.00              0.00              0.00   \n",
       "\n",
       "   loc_ic_mou_6  loc_ic_mou_7  loc_ic_mou_8  std_ic_t2t_mou_6  \\\n",
       "0         40.81         42.16         31.51              0.00   \n",
       "1        181.69        149.24        187.43              0.00   \n",
       "2          0.00          0.00          0.00              0.00   \n",
       "3        546.06        504.86        531.64              0.00   \n",
       "4         10.13          9.59         17.61             29.71   \n",
       "\n",
       "   std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2m_mou_6  std_ic_t2m_mou_7  \\\n",
       "0              0.00              0.00              0.36              1.04   \n",
       "1              0.00              0.00              0.00             12.51   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3              4.26              0.00              9.63             11.88   \n",
       "4             92.36            107.39             13.88             13.96   \n",
       "\n",
       "   std_ic_t2m_mou_8  std_ic_t2f_mou_6  std_ic_t2f_mou_7  std_ic_t2f_mou_8  \\\n",
       "0              4.34               0.0               0.0              0.00   \n",
       "1              0.00               0.0               0.0              0.00   \n",
       "2              0.00               0.0               0.0              0.00   \n",
       "3              8.83               0.0               0.0              0.00   \n",
       "4             32.46               0.0               0.0              1.61   \n",
       "\n",
       "   std_ic_t2o_mou_6  std_ic_t2o_mou_7  std_ic_t2o_mou_8  std_ic_mou_6  \\\n",
       "0               0.0               0.0               0.0          0.36   \n",
       "1               0.0               0.0               0.0          0.00   \n",
       "2               0.0               0.0               0.0          0.00   \n",
       "3               0.0               0.0               0.0          9.63   \n",
       "4               0.0               0.0               0.0         43.59   \n",
       "\n",
       "   std_ic_mou_7  std_ic_mou_8  total_ic_mou_6  total_ic_mou_7  total_ic_mou_8  \\\n",
       "0          1.04          4.34           41.73           43.56           36.26   \n",
       "1         12.51          0.00          296.33          339.64          281.66   \n",
       "2          0.00          0.00            0.00            0.00            0.00   \n",
       "3         16.14          8.83          555.69          522.44          549.13   \n",
       "4        106.33        141.48           53.73          115.93          159.26   \n",
       "\n",
       "   spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  isd_ic_mou_6  isd_ic_mou_7  \\\n",
       "0          0.54          0.34          0.39          0.00          0.00   \n",
       "1          0.00          0.00          0.00        114.63        177.88   \n",
       "2          0.00          0.00          0.00          0.00          0.00   \n",
       "3          0.00          0.00          0.00          0.00          1.43   \n",
       "4          0.00          0.00          0.00          0.00          0.00   \n",
       "\n",
       "   isd_ic_mou_8  ic_others_6  ic_others_7  ic_others_8  total_rech_num_6  \\\n",
       "0          0.00          0.0          0.0         0.00                 5   \n",
       "1         94.23          0.0          0.0         0.00                 5   \n",
       "2          0.00          0.0          0.0         0.00                 6   \n",
       "3          8.65          0.0          0.0         0.00                 3   \n",
       "4          0.00          0.0          0.0         0.16                11   \n",
       "\n",
       "   total_rech_num_7  total_rech_num_8  total_rech_amt_6  total_rech_amt_7  \\\n",
       "0                 5                 4               103                90   \n",
       "1                 4                 5               500               500   \n",
       "2                 9                 5               500              1000   \n",
       "3                 5                 2               110               260   \n",
       "4                 7                 8               356               490   \n",
       "\n",
       "   total_rech_amt_8  max_rech_amt_6  max_rech_amt_7  max_rech_amt_8  \\\n",
       "0                60              50              30              30   \n",
       "1               500             250             250             250   \n",
       "2              1000             300             500             500   \n",
       "3                 0             110             150               0   \n",
       "4               546              90             130             130   \n",
       "\n",
       "  date_of_last_rech_6 date_of_last_rech_7 date_of_last_rech_8  \\\n",
       "0           6/21/2014           7/26/2014           8/24/2014   \n",
       "1           6/19/2014           7/16/2014           8/24/2014   \n",
       "2           6/29/2014           7/27/2014           8/28/2014   \n",
       "3           6/25/2014           7/30/2014           8/24/2014   \n",
       "4           6/29/2014           7/29/2014           8/30/2014   \n",
       "\n",
       "   last_day_rch_amt_6  last_day_rch_amt_7  last_day_rch_amt_8  \\\n",
       "0                  30                  30                   0   \n",
       "1                 250                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                 110                 150                   0   \n",
       "4                  50                 130                 130   \n",
       "\n",
       "  date_of_last_rech_data_6 date_of_last_rech_data_7 date_of_last_rech_data_8  \\\n",
       "0                      NaN                      NaN                      NaN   \n",
       "1                      NaN                      NaN                      NaN   \n",
       "2                      NaN                      NaN                      NaN   \n",
       "3                      NaN                      NaN                      NaN   \n",
       "4                      NaN                      NaN                      NaN   \n",
       "\n",
       "   total_rech_data_6  total_rech_data_7  total_rech_data_8  max_rech_data_6  \\\n",
       "0                NaN                NaN                NaN              NaN   \n",
       "1                NaN                NaN                NaN              NaN   \n",
       "2                NaN                NaN                NaN              NaN   \n",
       "3                NaN                NaN                NaN              NaN   \n",
       "4                NaN                NaN                NaN              NaN   \n",
       "\n",
       "   max_rech_data_7  max_rech_data_8  count_rech_2g_6  count_rech_2g_7  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   count_rech_2g_8  count_rech_3g_6  count_rech_3g_7  count_rech_3g_8  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   av_rech_amt_data_6  av_rech_amt_data_7  av_rech_amt_data_8  vol_2g_mb_6  \\\n",
       "0                 NaN                 NaN                 NaN          0.0   \n",
       "1                 NaN                 NaN                 NaN          0.0   \n",
       "2                 NaN                 NaN                 NaN          0.0   \n",
       "3                 NaN                 NaN                 NaN          0.0   \n",
       "4                 NaN                 NaN                 NaN          0.0   \n",
       "\n",
       "   vol_2g_mb_7  vol_2g_mb_8  vol_3g_mb_6  vol_3g_mb_7  vol_3g_mb_8  arpu_3g_6  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0        NaN   \n",
       "1          0.0          0.0          0.0          0.0          0.0        NaN   \n",
       "2          0.0          0.0          0.0          0.0          0.0        NaN   \n",
       "3          0.0          0.0          0.0          0.0          0.0        NaN   \n",
       "4          0.0          0.0          0.0          0.0          0.0        NaN   \n",
       "\n",
       "   arpu_3g_7  arpu_3g_8  arpu_2g_6  arpu_2g_7  arpu_2g_8  night_pck_user_6  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "1        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "2        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "3        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "4        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "\n",
       "   night_pck_user_7  night_pck_user_8  monthly_2g_6  monthly_2g_7  \\\n",
       "0               NaN               NaN             0             0   \n",
       "1               NaN               NaN             0             0   \n",
       "2               NaN               NaN             0             0   \n",
       "3               NaN               NaN             0             0   \n",
       "4               NaN               NaN             0             0   \n",
       "\n",
       "   monthly_2g_8  sachet_2g_6  sachet_2g_7  sachet_2g_8  monthly_3g_6  \\\n",
       "0             0            0            0            0             0   \n",
       "1             0            0            0            0             0   \n",
       "2             0            0            0            0             0   \n",
       "3             0            0            0            0             0   \n",
       "4             0            0            0            0             0   \n",
       "\n",
       "   monthly_3g_7  monthly_3g_8  sachet_3g_6  sachet_3g_7  sachet_3g_8  \\\n",
       "0             0             0            0            0            0   \n",
       "1             0             0            0            0            0   \n",
       "2             0             0            0            0            0   \n",
       "3             0             0            0            0            0   \n",
       "4             0             0            0            0            0   \n",
       "\n",
       "   fb_user_6  fb_user_7  fb_user_8   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \n",
       "0        NaN        NaN        NaN  1692        0.00        0.00        0.00  \n",
       "1        NaN        NaN        NaN  2533        0.00        0.00        0.00  \n",
       "2        NaN        NaN        NaN   277      525.61      758.41      241.84  \n",
       "3        NaN        NaN        NaN  1244        0.00        0.00        0.00  \n",
       "4        NaN        NaN        NaN   462        0.00        0.00        0.00  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print('Dataframe Shape: ', test_data.shape); print('-'*80, '\\n');\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "67cec423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 158)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_data.drop(data_unique_count_is_one, axis=1, inplace=True)\n",
    "\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "17fc4228",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test_data.drop(high_missing_cols.index, axis=1, inplace=True)\n",
    "#test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4129be40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 152)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.drop(date_vars, axis=1, inplace=True)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2a885d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "id=test_data.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2475b7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 151)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.drop(\"id\", axis=1, inplace=True)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "07c09d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Missing%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>arpu_3g_6</td>\n",
       "      <td>74.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>arpu_2g_6</td>\n",
       "      <td>74.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>fb_user_6</td>\n",
       "      <td>74.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>total_rech_data_6</td>\n",
       "      <td>74.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>night_pck_user_6</td>\n",
       "      <td>74.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>max_rech_data_6</td>\n",
       "      <td>74.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>count_rech_2g_6</td>\n",
       "      <td>74.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>av_rech_amt_data_6</td>\n",
       "      <td>74.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>count_rech_3g_6</td>\n",
       "      <td>74.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>count_rech_3g_7</td>\n",
       "      <td>74.313333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature   Missing%\n",
       "123           arpu_3g_6  74.716667\n",
       "126           arpu_2g_6  74.716667\n",
       "144           fb_user_6  74.716667\n",
       "102   total_rech_data_6  74.716667\n",
       "129    night_pck_user_6  74.716667\n",
       "105     max_rech_data_6  74.716667\n",
       "108     count_rech_2g_6  74.716667\n",
       "114  av_rech_amt_data_6  74.716667\n",
       "111     count_rech_3g_6  74.716667\n",
       "112     count_rech_3g_7  74.313333"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = pd.DataFrame((test_data.isnull().sum()/len(test_data))*100).reset_index().rename(columns = {'index': 'feature', 0: 'Missing%'}).sort_values('Missing%',ascending = False)\n",
    "missing_values.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9e3bd349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 151)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3026540c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <th>count_rech_3g_8</th>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <th>av_rech_amt_data_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <th>arpu_3g_7</th>\n",
       "      <th>arpu_3g_8</th>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <th>night_pck_user_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.882</td>\n",
       "      <td>65.330</td>\n",
       "      <td>64.445</td>\n",
       "      <td>31.78</td>\n",
       "      <td>20.23</td>\n",
       "      <td>23.11</td>\n",
       "      <td>60.16</td>\n",
       "      <td>32.16</td>\n",
       "      <td>34.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.88</td>\n",
       "      <td>20.23</td>\n",
       "      <td>21.06</td>\n",
       "      <td>18.13</td>\n",
       "      <td>10.89</td>\n",
       "      <td>8.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>43.01</td>\n",
       "      <td>44.71</td>\n",
       "      <td>29.43</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.05</td>\n",
       "      <td>42.03</td>\n",
       "      <td>7.68</td>\n",
       "      <td>26.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.93</td>\n",
       "      <td>7.68</td>\n",
       "      <td>28.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.94</td>\n",
       "      <td>52.39</td>\n",
       "      <td>57.94</td>\n",
       "      <td>30.33</td>\n",
       "      <td>37.56</td>\n",
       "      <td>21.98</td>\n",
       "      <td>10.21</td>\n",
       "      <td>4.59</td>\n",
       "      <td>9.53</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.81</td>\n",
       "      <td>42.16</td>\n",
       "      <td>31.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.04</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.04</td>\n",
       "      <td>4.34</td>\n",
       "      <td>41.73</td>\n",
       "      <td>43.56</td>\n",
       "      <td>36.26</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1692</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>414.168</td>\n",
       "      <td>515.568</td>\n",
       "      <td>360.868</td>\n",
       "      <td>75.51</td>\n",
       "      <td>41.21</td>\n",
       "      <td>19.84</td>\n",
       "      <td>474.34</td>\n",
       "      <td>621.84</td>\n",
       "      <td>394.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75.51</td>\n",
       "      <td>41.21</td>\n",
       "      <td>19.84</td>\n",
       "      <td>473.61</td>\n",
       "      <td>598.08</td>\n",
       "      <td>377.26</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>549.86</td>\n",
       "      <td>639.29</td>\n",
       "      <td>397.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.76</td>\n",
       "      <td>17.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.76</td>\n",
       "      <td>17.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>549.86</td>\n",
       "      <td>663.06</td>\n",
       "      <td>415.59</td>\n",
       "      <td>19.99</td>\n",
       "      <td>26.95</td>\n",
       "      <td>2.61</td>\n",
       "      <td>160.19</td>\n",
       "      <td>122.29</td>\n",
       "      <td>184.81</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>181.69</td>\n",
       "      <td>149.24</td>\n",
       "      <td>187.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>296.33</td>\n",
       "      <td>339.64</td>\n",
       "      <td>281.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>114.63</td>\n",
       "      <td>177.88</td>\n",
       "      <td>94.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2533</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>329.844</td>\n",
       "      <td>434.884</td>\n",
       "      <td>746.239</td>\n",
       "      <td>7.54</td>\n",
       "      <td>7.86</td>\n",
       "      <td>8.40</td>\n",
       "      <td>16.98</td>\n",
       "      <td>45.81</td>\n",
       "      <td>45.04</td>\n",
       "      <td>22.81</td>\n",
       "      <td>103.38</td>\n",
       "      <td>26.08</td>\n",
       "      <td>24.53</td>\n",
       "      <td>53.68</td>\n",
       "      <td>54.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277</td>\n",
       "      <td>525.61</td>\n",
       "      <td>758.41</td>\n",
       "      <td>241.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.550</td>\n",
       "      <td>171.390</td>\n",
       "      <td>24.400</td>\n",
       "      <td>5.31</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.04</td>\n",
       "      <td>205.01</td>\n",
       "      <td>24.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.94</td>\n",
       "      <td>98.61</td>\n",
       "      <td>20.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.26</td>\n",
       "      <td>98.61</td>\n",
       "      <td>22.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.09</td>\n",
       "      <td>94.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.09</td>\n",
       "      <td>96.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.03</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.36</td>\n",
       "      <td>207.18</td>\n",
       "      <td>24.01</td>\n",
       "      <td>58.11</td>\n",
       "      <td>54.64</td>\n",
       "      <td>23.04</td>\n",
       "      <td>487.94</td>\n",
       "      <td>449.83</td>\n",
       "      <td>506.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.64</td>\n",
       "      <td>546.06</td>\n",
       "      <td>504.86</td>\n",
       "      <td>531.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.63</td>\n",
       "      <td>11.88</td>\n",
       "      <td>8.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.63</td>\n",
       "      <td>16.14</td>\n",
       "      <td>8.83</td>\n",
       "      <td>555.69</td>\n",
       "      <td>522.44</td>\n",
       "      <td>549.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.43</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306.854</td>\n",
       "      <td>406.289</td>\n",
       "      <td>413.329</td>\n",
       "      <td>450.93</td>\n",
       "      <td>609.03</td>\n",
       "      <td>700.68</td>\n",
       "      <td>60.94</td>\n",
       "      <td>23.84</td>\n",
       "      <td>74.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.78</td>\n",
       "      <td>14.56</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.66</td>\n",
       "      <td>10.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.84</td>\n",
       "      <td>3.44</td>\n",
       "      <td>25.51</td>\n",
       "      <td>450.48</td>\n",
       "      <td>608.24</td>\n",
       "      <td>686.11</td>\n",
       "      <td>58.54</td>\n",
       "      <td>21.18</td>\n",
       "      <td>63.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>509.03</td>\n",
       "      <td>629.43</td>\n",
       "      <td>749.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>5.39</td>\n",
       "      <td>4.96</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>514.79</td>\n",
       "      <td>638.28</td>\n",
       "      <td>779.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>9.91</td>\n",
       "      <td>10.13</td>\n",
       "      <td>9.23</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.13</td>\n",
       "      <td>9.59</td>\n",
       "      <td>17.61</td>\n",
       "      <td>29.71</td>\n",
       "      <td>92.36</td>\n",
       "      <td>107.39</td>\n",
       "      <td>13.88</td>\n",
       "      <td>13.96</td>\n",
       "      <td>32.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>43.59</td>\n",
       "      <td>106.33</td>\n",
       "      <td>141.48</td>\n",
       "      <td>53.73</td>\n",
       "      <td>115.93</td>\n",
       "      <td>159.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>356</td>\n",
       "      <td>490</td>\n",
       "      <td>546</td>\n",
       "      <td>90</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>50</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>462</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    arpu_6   arpu_7   arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  \\\n",
       "0   91.882   65.330   64.445        31.78        20.23        23.11   \n",
       "1  414.168  515.568  360.868        75.51        41.21        19.84   \n",
       "2  329.844  434.884  746.239         7.54         7.86         8.40   \n",
       "3   43.550  171.390   24.400         5.31         2.16         0.00   \n",
       "4  306.854  406.289  413.329       450.93       609.03       700.68   \n",
       "\n",
       "   offnet_mou_6  offnet_mou_7  offnet_mou_8  roam_ic_mou_6  roam_ic_mou_7  \\\n",
       "0         60.16         32.16         34.83           0.00           0.00   \n",
       "1        474.34        621.84        394.94           0.00           0.00   \n",
       "2         16.98         45.81         45.04          22.81         103.38   \n",
       "3         40.04        205.01         24.01           0.00           0.00   \n",
       "4         60.94         23.84         74.16           0.00           0.00   \n",
       "\n",
       "   roam_ic_mou_8  roam_og_mou_6  roam_og_mou_7  roam_og_mou_8  \\\n",
       "0           0.00           0.00           0.00           0.00   \n",
       "1           0.00           0.00           0.00           0.00   \n",
       "2          26.08          24.53          53.68          54.44   \n",
       "3           0.00           0.00           0.00           0.00   \n",
       "4           0.00           0.00           0.00           0.00   \n",
       "\n",
       "   loc_og_t2t_mou_6  loc_og_t2t_mou_7  loc_og_t2t_mou_8  loc_og_t2m_mou_6  \\\n",
       "0             24.88             20.23             21.06             18.13   \n",
       "1             75.51             41.21             19.84            473.61   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3              5.31              0.00              0.00              2.94   \n",
       "4              0.45              0.78             14.56              2.39   \n",
       "\n",
       "   loc_og_t2m_mou_7  loc_og_t2m_mou_8  loc_og_t2f_mou_6  loc_og_t2f_mou_7  \\\n",
       "0             10.89              8.36              0.00             13.58   \n",
       "1            598.08            377.26              0.73              0.00   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3             98.61             20.51              0.00              0.00   \n",
       "4              2.66             10.94              0.00              0.00   \n",
       "\n",
       "   loc_og_t2f_mou_8  loc_og_t2c_mou_6  loc_og_t2c_mou_7  loc_og_t2c_mou_8  \\\n",
       "0              0.00               0.0              0.00              0.03   \n",
       "1              0.00               0.0              0.00              0.00   \n",
       "2              0.00               0.0              0.00              0.00   \n",
       "3              2.35               0.0              6.18              0.00   \n",
       "4              0.00               0.0              0.00              0.00   \n",
       "\n",
       "   loc_og_mou_6  loc_og_mou_7  loc_og_mou_8  std_og_t2t_mou_6  \\\n",
       "0         43.01         44.71         29.43              6.90   \n",
       "1        549.86        639.29        397.11              0.00   \n",
       "2          0.00          0.00          0.00              0.00   \n",
       "3          8.26         98.61         22.86              0.00   \n",
       "4          2.84          3.44         25.51            450.48   \n",
       "\n",
       "   std_og_t2t_mou_7  std_og_t2t_mou_8  std_og_t2m_mou_6  std_og_t2m_mou_7  \\\n",
       "0              0.00              2.05             42.03              7.68   \n",
       "1              0.00              0.00              0.00             23.76   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3              2.16              0.00             37.09             94.36   \n",
       "4            608.24            686.11             58.54             21.18   \n",
       "\n",
       "   std_og_t2m_mou_8  std_og_t2f_mou_6  std_og_t2f_mou_7  std_og_t2f_mou_8  \\\n",
       "0             26.43               0.0               0.0               0.0   \n",
       "1             17.68               0.0               0.0               0.0   \n",
       "2              0.00               0.0               0.0               0.0   \n",
       "3              0.00               0.0               0.0               0.0   \n",
       "4             63.18               0.0               0.0               0.0   \n",
       "\n",
       "   std_og_mou_6  std_og_mou_7  std_og_mou_8  isd_og_mou_6  isd_og_mou_7  \\\n",
       "0         48.93          7.68         28.48           0.0           0.0   \n",
       "1          0.00         23.76         17.68           0.0           0.0   \n",
       "2          0.00          0.00          0.00           0.0           0.0   \n",
       "3         37.09         96.53          0.00           0.0           0.0   \n",
       "4        509.03        629.43        749.29           0.0           0.0   \n",
       "\n",
       "   isd_og_mou_8  spl_og_mou_6  spl_og_mou_7  spl_og_mou_8  og_others_6  \\\n",
       "0           0.0          0.00          0.00          0.03          0.0   \n",
       "1           0.8          0.00          0.00          0.00          0.0   \n",
       "2           0.0          0.00          0.00          0.00          0.0   \n",
       "3           0.0          0.00         12.03          1.15          0.0   \n",
       "4           0.0          0.71          5.39          4.96          2.2   \n",
       "\n",
       "   og_others_7  og_others_8  total_og_mou_6  total_og_mou_7  total_og_mou_8  \\\n",
       "0          0.0          0.0           91.94           52.39           57.94   \n",
       "1          0.0          0.0          549.86          663.06          415.59   \n",
       "2          0.0          0.0            0.00            0.00            0.00   \n",
       "3          0.0          0.0           45.36          207.18           24.01   \n",
       "4          0.0          0.0          514.79          638.28          779.78   \n",
       "\n",
       "   loc_ic_t2t_mou_6  loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  loc_ic_t2m_mou_6  \\\n",
       "0             30.33             37.56             21.98             10.21   \n",
       "1             19.99             26.95              2.61            160.19   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3             58.11             54.64             23.04            487.94   \n",
       "4              0.00              0.36              9.91             10.13   \n",
       "\n",
       "   loc_ic_t2m_mou_7  loc_ic_t2m_mou_8  loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  \\\n",
       "0              4.59              9.53              0.26              0.00   \n",
       "1            122.29            184.81              1.49              0.00   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3            449.83            506.94              0.00              0.38   \n",
       "4              9.23              7.69              0.00              0.00   \n",
       "\n",
       "   loc_ic_t2f_mou_8  loc_ic_mou_6  loc_ic_mou_7  loc_ic_mou_8  \\\n",
       "0              0.00         40.81         42.16         31.51   \n",
       "1              0.00        181.69        149.24        187.43   \n",
       "2              0.00          0.00          0.00          0.00   \n",
       "3              1.64        546.06        504.86        531.64   \n",
       "4              0.00         10.13          9.59         17.61   \n",
       "\n",
       "   std_ic_t2t_mou_6  std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2m_mou_6  \\\n",
       "0              0.00              0.00              0.00              0.36   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3              0.00              4.26              0.00              9.63   \n",
       "4             29.71             92.36            107.39             13.88   \n",
       "\n",
       "   std_ic_t2m_mou_7  std_ic_t2m_mou_8  std_ic_t2f_mou_6  std_ic_t2f_mou_7  \\\n",
       "0              1.04              4.34               0.0               0.0   \n",
       "1             12.51              0.00               0.0               0.0   \n",
       "2              0.00              0.00               0.0               0.0   \n",
       "3             11.88              8.83               0.0               0.0   \n",
       "4             13.96             32.46               0.0               0.0   \n",
       "\n",
       "   std_ic_t2f_mou_8  std_ic_mou_6  std_ic_mou_7  std_ic_mou_8  total_ic_mou_6  \\\n",
       "0              0.00          0.36          1.04          4.34           41.73   \n",
       "1              0.00          0.00         12.51          0.00          296.33   \n",
       "2              0.00          0.00          0.00          0.00            0.00   \n",
       "3              0.00          9.63         16.14          8.83          555.69   \n",
       "4              1.61         43.59        106.33        141.48           53.73   \n",
       "\n",
       "   total_ic_mou_7  total_ic_mou_8  spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  \\\n",
       "0           43.56           36.26          0.54          0.34          0.39   \n",
       "1          339.64          281.66          0.00          0.00          0.00   \n",
       "2            0.00            0.00          0.00          0.00          0.00   \n",
       "3          522.44          549.13          0.00          0.00          0.00   \n",
       "4          115.93          159.26          0.00          0.00          0.00   \n",
       "\n",
       "   isd_ic_mou_6  isd_ic_mou_7  isd_ic_mou_8  ic_others_6  ic_others_7  \\\n",
       "0          0.00          0.00          0.00          0.0          0.0   \n",
       "1        114.63        177.88         94.23          0.0          0.0   \n",
       "2          0.00          0.00          0.00          0.0          0.0   \n",
       "3          0.00          1.43          8.65          0.0          0.0   \n",
       "4          0.00          0.00          0.00          0.0          0.0   \n",
       "\n",
       "   ic_others_8  total_rech_num_6  total_rech_num_7  total_rech_num_8  \\\n",
       "0         0.00                 5                 5                 4   \n",
       "1         0.00                 5                 4                 5   \n",
       "2         0.00                 6                 9                 5   \n",
       "3         0.00                 3                 5                 2   \n",
       "4         0.16                11                 7                 8   \n",
       "\n",
       "   total_rech_amt_6  total_rech_amt_7  total_rech_amt_8  max_rech_amt_6  \\\n",
       "0               103                90                60              50   \n",
       "1               500               500               500             250   \n",
       "2               500              1000              1000             300   \n",
       "3               110               260                 0             110   \n",
       "4               356               490               546              90   \n",
       "\n",
       "   max_rech_amt_7  max_rech_amt_8  last_day_rch_amt_6  last_day_rch_amt_7  \\\n",
       "0              30              30                  30                  30   \n",
       "1             250             250                 250                   0   \n",
       "2             500             500                   0                   0   \n",
       "3             150               0                 110                 150   \n",
       "4             130             130                  50                 130   \n",
       "\n",
       "   last_day_rch_amt_8  total_rech_data_6  total_rech_data_7  \\\n",
       "0                   0                NaN                NaN   \n",
       "1                   0                NaN                NaN   \n",
       "2                   0                NaN                NaN   \n",
       "3                   0                NaN                NaN   \n",
       "4                 130                NaN                NaN   \n",
       "\n",
       "   total_rech_data_8  max_rech_data_6  max_rech_data_7  max_rech_data_8  \\\n",
       "0                NaN              NaN              NaN              NaN   \n",
       "1                NaN              NaN              NaN              NaN   \n",
       "2                NaN              NaN              NaN              NaN   \n",
       "3                NaN              NaN              NaN              NaN   \n",
       "4                NaN              NaN              NaN              NaN   \n",
       "\n",
       "   count_rech_2g_6  count_rech_2g_7  count_rech_2g_8  count_rech_3g_6  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   count_rech_3g_7  count_rech_3g_8  av_rech_amt_data_6  av_rech_amt_data_7  \\\n",
       "0              NaN              NaN                 NaN                 NaN   \n",
       "1              NaN              NaN                 NaN                 NaN   \n",
       "2              NaN              NaN                 NaN                 NaN   \n",
       "3              NaN              NaN                 NaN                 NaN   \n",
       "4              NaN              NaN                 NaN                 NaN   \n",
       "\n",
       "   av_rech_amt_data_8  vol_2g_mb_6  vol_2g_mb_7  vol_2g_mb_8  vol_3g_mb_6  \\\n",
       "0                 NaN          0.0          0.0          0.0          0.0   \n",
       "1                 NaN          0.0          0.0          0.0          0.0   \n",
       "2                 NaN          0.0          0.0          0.0          0.0   \n",
       "3                 NaN          0.0          0.0          0.0          0.0   \n",
       "4                 NaN          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   vol_3g_mb_7  vol_3g_mb_8  arpu_3g_6  arpu_3g_7  arpu_3g_8  arpu_2g_6  \\\n",
       "0          0.0          0.0        NaN        NaN        NaN        NaN   \n",
       "1          0.0          0.0        NaN        NaN        NaN        NaN   \n",
       "2          0.0          0.0        NaN        NaN        NaN        NaN   \n",
       "3          0.0          0.0        NaN        NaN        NaN        NaN   \n",
       "4          0.0          0.0        NaN        NaN        NaN        NaN   \n",
       "\n",
       "   arpu_2g_7  arpu_2g_8  night_pck_user_6  night_pck_user_7  night_pck_user_8  \\\n",
       "0        NaN        NaN               NaN               NaN               NaN   \n",
       "1        NaN        NaN               NaN               NaN               NaN   \n",
       "2        NaN        NaN               NaN               NaN               NaN   \n",
       "3        NaN        NaN               NaN               NaN               NaN   \n",
       "4        NaN        NaN               NaN               NaN               NaN   \n",
       "\n",
       "   monthly_2g_6  monthly_2g_7  monthly_2g_8  sachet_2g_6  sachet_2g_7  \\\n",
       "0             0             0             0            0            0   \n",
       "1             0             0             0            0            0   \n",
       "2             0             0             0            0            0   \n",
       "3             0             0             0            0            0   \n",
       "4             0             0             0            0            0   \n",
       "\n",
       "   sachet_2g_8  monthly_3g_6  monthly_3g_7  monthly_3g_8  sachet_3g_6  \\\n",
       "0            0             0             0             0            0   \n",
       "1            0             0             0             0            0   \n",
       "2            0             0             0             0            0   \n",
       "3            0             0             0             0            0   \n",
       "4            0             0             0             0            0   \n",
       "\n",
       "   sachet_3g_7  sachet_3g_8  fb_user_6  fb_user_7  fb_user_8   aon  \\\n",
       "0            0            0        NaN        NaN        NaN  1692   \n",
       "1            0            0        NaN        NaN        NaN  2533   \n",
       "2            0            0        NaN        NaN        NaN   277   \n",
       "3            0            0        NaN        NaN        NaN  1244   \n",
       "4            0            0        NaN        NaN        NaN   462   \n",
       "\n",
       "   aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \n",
       "0        0.00        0.00        0.00  \n",
       "1        0.00        0.00        0.00  \n",
       "2      525.61      758.41      241.84  \n",
       "3        0.00        0.00        0.00  \n",
       "4        0.00        0.00        0.00  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ef056606",
   "metadata": {},
   "outputs": [],
   "source": [
    "if zero_impute==0:\n",
    "    orig_cols=test_data.columns\n",
    "    test_data = pd.DataFrame(simple_imtr.transform(test_data))\n",
    "    test_data.columns=orig_cols\n",
    "else :\n",
    "    test_data=test_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d462749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=test_data.columns\n",
    "test_data = pd.DataFrame(scaler.transform(test_data))\n",
    "test_data.columns=cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f3149427",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test=rfc_best.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "21402576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total occurences of \"1\" in array:  2516\n",
      "Total occurences of \"0\" in array:  27484\n"
     ]
    }
   ],
   "source": [
    "count_arr = np.bincount(predictions_test)\n",
    "# Count occurrence of element '1' in numpy array\n",
    "print('Total occurences of \"1\" in array: ', count_arr[1])\n",
    "# Count occurrence of element '0' in numpy array\n",
    "print('Total occurences of \"0\" in array: ', count_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0d773040",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_xgb=xgb_best.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d5e3e82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total occurences of \"1\" in array:  2618\n",
      "Total occurences of \"0\" in array:  27382\n"
     ]
    }
   ],
   "source": [
    "count_arr = np.bincount(predictions_test_xgb)\n",
    "# Count occurrence of element '1' in numpy array\n",
    "print('Total occurences of \"1\" in array: ', count_arr[1])\n",
    "# Count occurrence of element '0' in numpy array\n",
    "print('Total occurences of \"0\" in array: ', count_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "adab6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_df=pd.DataFrame({'id':id,'churn_probability':predictions_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "41c2c5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  churn_probability\n",
       "0  69999                  0\n",
       "1  70000                  0\n",
       "2  70001                  1\n",
       "3  70002                  0\n",
       "4  70003                  0\n",
       "5  70004                  1\n",
       "6  70005                  0\n",
       "7  70006                  0\n",
       "8  70007                  0\n",
       "9  70008                  0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "770059e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_df.to_csv('solution_rfc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "deb0fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_df_xgb=pd.DataFrame({'id':id,'churn_probability':predictions_test_xgb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0f46153d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  churn_probability\n",
       "0  69999                  0\n",
       "1  70000                  0\n",
       "2  70001                  1\n",
       "3  70002                  0\n",
       "4  70003                  0\n",
       "5  70004                  1\n",
       "6  70005                  0\n",
       "7  70006                  0\n",
       "8  70007                  0\n",
       "9  70008                  1"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution_df_xgb.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2cae7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_df_xgb.to_csv('solution_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2eddd152",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_orig=pd.read_csv(\"solution.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "648c945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_actual=solution_orig.churn_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0f892e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total occurences of \"1\" in array:  3059\n",
      "Total occurences of \"0\" in array:  26941\n"
     ]
    }
   ],
   "source": [
    "count_arr = np.bincount(Y_actual)\n",
    "# Count occurrence of element '1' in numpy array\n",
    "print('Total occurences of \"1\" in array: ', count_arr[1])\n",
    "# Count occurrence of element '0' in numpy array\n",
    "print('Total occurences of \"0\" in array: ', count_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3c8a06b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9447"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_actual,predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4cd311b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9439666666666666"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_actual,predictions_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cc9fb118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26383   558]\n",
      " [ 1101  1958]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_actual, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5e7ded8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26321   620]\n",
      " [ 1061  1998]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_actual, predictions_test_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7182e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_df.to_csv('Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_ada=ada.predict(test_data)\n",
    "accuracy_score(Y_actual,predictions_test_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f1ac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_gbm=gbm.predict(test_data)\n",
    "accuracy_score(Y_actual,predictions_test_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6172e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_df_gbm=pd.DataFrame({'id':id,'churn_probability':predictions_test_gbm})\n",
    "solution_df_gbm.to_csv('Submission_gbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e3b941bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'solution_df_gbm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [112], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msolution_df_gbm\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubmission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'solution_df_gbm' is not defined"
     ]
    }
   ],
   "source": [
    "solution_df_gbm.to_csv('Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfd5c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
